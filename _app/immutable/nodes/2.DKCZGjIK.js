import{t as _,a as M,n as Re,d as Z}from"../chunks/DeQyGRAF.js";import{i as pe}from"../chunks/BUKhciG0.js";import{a7 as Pe,a3 as ie,Y as A,$ as _e,_ as Oe,a2 as me,Q as We,g as Q,J as ge,ak as Ie,al as ce,ab as K,Z as j,ae as Ne,am as fe,V as ve,an as Ae,ai as be,B as Ce,K as De,q as ue,at as ne,y as le,au as ze,av as Te,aw as Be,ah as Fe,ax as Ee,X as Ye,ay as qe,az as Ue,aa as Ge,A as $e,aA as He,aB as Ze,p as ye,t as X,j as Se,k as b,m as v,s as c,aC as z,aD as je,i as te}from"../chunks/DX9BjxLj.js";import{i as Je,c as Qe,d as Ke,n as Ve,a as Xe,s as ae,b as ea}from"../chunks/BvO99789.js";import{l as aa,p as E,r as ia}from"../chunks/BIriWe9Q.js";function na(e,a){if(a){const i=document.body;e.autofocus=!0,Pe(()=>{document.activeElement===i&&e.focus()})}}function ta(e,a){return a}function oa(e,a,i,n){for(var t=[],o=a.length,s=0;s<o;s++)Be(a[s].e,t,!0);var p=o>0&&t.length===0&&i!==null;if(p){var d=i.parentNode;Fe(d),d.append(i),n.clear(),B(e,a[0].prev,a[o-1].next)}Ee(t,()=>{for(var k=0;k<o;k++){var r=a[k];p||(n.delete(r.k),B(e,r.prev,r.next)),Ye(r.e,!p)}})}function ra(e,a,i,n,t,o=null){var s=e,p={items:new Map,first:null};{var d=e;s=A?ie(_e(d)):d.appendChild(Oe())}A&&me();var k=null,r=!1,x=ge(()=>{var u=i();return Ce(u)?u:u==null?[]:be(u)});We(()=>{var u=Q(x),y=u.length;if(r&&y===0)return;r=y===0;let g=!1;if(A){var I=s.data===Ie;I!==(y===0)&&(s=ce(),ie(s),K(!1),g=!0)}if(A){for(var w=null,f,l=0;l<y;l++){if(j.nodeType===8&&j.data===Ne){s=j,g=!0,K(!1);break}var S=u[l],L=n(S,l);f=ke(j,p,w,null,S,L,l,t,a,i),p.items.set(L,f),w=f}y>0&&ie(ce())}A||sa(u,p,s,t,a,n,i),o!==null&&(y===0?k?fe(k):k=ve(()=>o(s)):k!==null&&Ae(k,()=>{k=null})),g&&K(!0),Q(x)}),A&&(s=j)}function sa(e,a,i,n,t,o,s){var p=e.length,d=a.items,k=a.first,r=k,x,u=null,y=[],g=[],I,w,f,l;for(l=0;l<p;l+=1){if(I=e[l],w=o(I,l),f=d.get(w),f===void 0){var S=r?r.e.nodes_start:i;u=ke(S,a,u,u===null?a.first:u.next,I,w,l,n,t,s),d.set(w,u),y=[],g=[],r=u.next;continue}if(ca(f,I,l),f.e.f&ne&&fe(f.e),f!==r){if(x!==void 0&&x.has(f)){if(y.length<g.length){var L=g[0],P;u=L.prev;var O=y[0],T=y[y.length-1];for(P=0;P<y.length;P+=1)de(y[P],L,i);for(P=0;P<g.length;P+=1)x.delete(g[P]);B(a,O.prev,T.next),B(a,u,O),B(a,T,L),r=L,u=T,l-=1,y=[],g=[]}else x.delete(f),de(f,r,i),B(a,f.prev,f.next),B(a,f,u===null?a.first:u.next),B(a,u,f),u=f;continue}for(y=[],g=[];r!==null&&r.k!==w;)r.e.f&ne||(x??(x=new Set)).add(r),g.push(r),r=r.next;if(r===null)continue;f=r}y.push(f),u=f,r=f.next}if(r!==null||x!==void 0){for(var F=x===void 0?[]:be(x);r!==null;)r.e.f&ne||F.push(r),r=r.next;var m=F.length;if(m>0){var W=p===0?i:null;oa(a,F,W,d)}}le.first=a.first&&a.first.e,le.last=u&&u.e}function ca(e,a,i,n){Te(e.v,a),e.i=i}function ke(e,a,i,n,t,o,s,p,d,k){var r=(d&qe)!==0,x=(d&Ue)===0,u=r?x?De(t):ue(t):t,y=d&ze?ue(s):s,g={i:y,v:u,k:o,a:null,e:null,prev:i,next:n};try{return g.e=ve(()=>p(e,u,y,k),A),g.e.prev=i&&i.e,g.e.next=n&&n.e,i===null?a.first=g:(i.next=g,i.e.next=g.e),n!==null&&(n.prev=g,n.e.prev=g.e),g}finally{}}function de(e,a,i){for(var n=e.next?e.next.e.nodes_start:i,t=a?a.e.nodes_start:i,o=e.e.nodes_start;o!==n;){var s=Ge(o);t.before(o),o=s}}function B(e,a,i){a===null?e.first=i:(a.next=i,a.e.next=i&&i.e),i!==null&&(i.prev=a,i.e.prev=a&&a.e)}function we(e,a,i,n,t){var p;A&&me();var o=(p=a.$$slots)==null?void 0:p[i],s=!1;o===!0&&(o=a.children,s=!0),o===void 0||o(e,s?()=>n:n)}function xe(e){var a,i,n="";if(typeof e=="string"||typeof e=="number")n+=e;else if(typeof e=="object")if(Array.isArray(e)){var t=e.length;for(a=0;a<t;a++)e[a]&&(i=xe(e[a]))&&(n&&(n+=" "),n+=i)}else for(i in e)e[i]&&(n&&(n+=" "),n+=i);return n}function ua(){for(var e,a,i=0,n="",t=arguments.length;i<t;i++)(e=arguments[i])&&(a=xe(e))&&(n&&(n+=" "),n+=a);return n}function la(e){return typeof e=="object"?ua(e):e??""}function da(e,a){a?e.hasAttribute("selected")||e.setAttribute("selected",""):e.removeAttribute("selected")}function V(e,a,i,n){var t=e.__attributes??(e.__attributes={});A&&(t[a]=e.getAttribute(a),a==="src"||a==="srcset"||a==="href"&&e.nodeName==="LINK")||t[a]!==(t[a]=i)&&(a==="style"&&"__styles"in e&&(e.__styles={}),a==="loading"&&(e[He]=i),i==null?e.removeAttribute(a):typeof i!="string"&&Me(e).includes(a)?e[a]=i:e.setAttribute(a,i))}function ha(e,a,i,n,t=!1,o=!1,s=!1){let p=A&&o;p&&K(!1);var d=a||{},k=e.tagName==="OPTION";for(var r in a)r in i||(i[r]=null);i.class&&(i.class=la(i.class));var x=Me(e),u=e.__attributes??(e.__attributes={});for(const l in i){let S=i[l];if(k&&l==="value"&&S==null){e.value=e.__value="",d[l]=S;continue}var y=d[l];if(S!==y){d[l]=S;var g=l[0]+l[1];if(g!=="$$"){if(g==="on"){const L={},P="$$"+l;let O=l.slice(2);var I=Xe(O);if(Je(O)&&(O=O.slice(0,-7),L.capture=!0),!I&&y){if(S!=null)continue;e.removeEventListener(O,d[P],L),d[P]=null}if(S!=null)if(I)e[`__${O}`]=S,Ke([O]);else{let T=function(F){d[l].call(this,F)};d[P]=Qe(O,e,T,L)}else I&&(e[`__${O}`]=void 0)}else if(l==="style"&&S!=null)e.style.cssText=S+"";else if(l==="autofocus")na(e,!!S);else if(!o&&(l==="__value"||l==="value"&&S!=null))e.value=e.__value=S;else if(l==="selected"&&k)da(e,S);else{var w=l;t||(w=Ve(w));var f=w==="defaultValue"||w==="defaultChecked";if(S==null&&!o&&!f)if(u[l]=null,w==="value"||w==="checked"){let L=e;if(w==="value"){let P=L.defaultValue;L.removeAttribute(w),L.defaultValue=P}else{let P=L.defaultChecked;L.removeAttribute(w),L.defaultChecked=P}}else e.removeAttribute(l);else f||x.includes(w)&&(o||typeof S!="string")?e[w]=S:typeof S!="function"&&V(e,w,S)}l==="style"&&"__styles"in e&&(e.__styles={})}}}return p&&K(!0),d}var he=new Map;function Me(e){var a=he.get(e.nodeName);if(a)return a;he.set(e.nodeName,a=[]);for(var i,n=e,t=Element.prototype;t!==n;){i=Ze(n);for(var o in i)i[o].set&&a.push(o);n=$e(n)}return a}function pa(e,a,i){var n=e.__className,t=ma(a);A&&e.className===t?e.__className=t:(n!==t||A&&e.className!==t)&&(a==null?e.removeAttribute("class"):e.className=t,e.__className=t)}function ma(e,a){return(e??"")+""}var ga=_('<div class="flex justify-center font-serif text-lg"><div><!></div></div>');function D(e,a){const i=aa(a,["children","$$slots","$$events","$$legacy"]);ye(a,!1);let n=E(a,"size",8,"max-w-2xl"),t=E(a,"padding",8,"pb-12");pe();var o=ga(),s=b(o),p=b(s);we(p,a,"default",{}),v(s),v(o),X(()=>pa(s,`mx-8 ${n()??""} w-full ${t()??""} ${i.class??""}`)),M(e,o),Se()}var fa=Re('<svg><path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path></svg>');function va(e,a){const i=ia(a,["$$slots","$$events","$$legacy"]);var n=fa();let t;X(()=>t=ha(n,t,{viewBox:"0 0 24 24",width:"1.2em",height:"1.2em",...i},void 0,!0)),M(e,n)}var ba=_('<a target="_blank" rel="noreferrer" class="inline-block"><div class="flex cursor-pointer flex-col items-center justify-center px-4 py-4"><div class="h-32 w-32 rounded-full border border-gray-300 bg-cover bg-center"></div> <div class="mt-2 mb-2 max-w-34 border-gray-300 text-center text-xl underline decoration-gray-300 underline-offset-6 transition hover:decoration-gray-500"> </div> <div class="max-w-34 text-center text-base text-gray-600"> </div></div></a>');function R(e,a){let i=E(a,"name",8,"John Doe"),n=E(a,"affiliation",8,"Software Engineer"),t=E(a,"image",8,""),o=E(a,"link",8,"");var s=ba(),p=b(s),d=b(p),k=c(d,2),r=b(k,!0);v(k);var x=c(k,2),u=b(x,!0);v(x),v(p),v(s),X(()=>{V(s,"href",o()),V(d,"style",`background-image: url(${t()??""})`),ae(r,i()),ae(u,n())}),M(e,s)}var ya=_('<a><div class="my-2 cursor-pointer font-mono text-xs text-gray-600 uppercase underline underline-offset-4 transition hover:bg-gray-600 hover:text-white"><!></div></a>');function J(e,a){let i=E(a,"href",8,"");var n=ya(),t=b(n),o=b(t);we(o,a,"default",{}),v(t),v(n),X(()=>V(n,"href",i())),M(e,n)}var Sa=_('<p>Submissions are limited to at most 4 pages of main body, in the NeurIPS conference proceedings format (please see <a href="https://neurips.cc/Conferences/2025/CallForPapers" rel="nofollow"><u>https://neurips.cc/Conferences/2025/CallForPapers</u></a>). In addition to these 4 pages, references of an unlimited length are allowed.</p> <p>Submissions are <strong>non-anonymous</strong> and <strong>non-archival</strong>. We welcome submissions based on preliminary working progress, work under review, or work that has already been published in prior venues. In particular, papers based on work under review or prior publication are allowed and encouraged.</p> <p>For papers based on preliminary working progress, submission to the workshop will not preclude future journal or conference publication. Moreover, these papers will have the option to be considered for fast-track submission of the full-length version to <em>Stochastic Systems</em>, the flagship journal of INFORMS Applied Probability Society.</p> <p>All accepted papers will be presented in an elaborate poster session at the workshop. In addition, several selected papers will be chosen as “spotlight” for oral presentations.</p> <p>Submissions should be made via OpenReview:<br> <a href="https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/MLxOR" rel="nofollow"><u>https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/MLxOR</u></a></p> <p><em>Note</em>: Please be aware of OpenReview’s moderation policy. New profiles created without an institutional email will go through a moderation process that can take up to two weeks. On the other hand, new profiles created with an institutional email will be activated automatically.</p> <p><strong>Additional Clarifications about Submission Policy:</strong></p> <ul><li>Supplemental materials (of reasonable length) may also be included, but they are optional and reviewers are not required to review these materials.</li> <li>When using the NeurIPS conference paper template, please adopt the single-blind format since submissions to our workshop are non-anonymous.</li> <li>You may drop the NeurIPS Paper Checklist expected for main conference submissions. This checklist is not required for our workshop’s submissions.</li> <li>Dual submissions are allowed for our workshop. That is, we do not forbid making a similar or identical submission to other NeurIPS workshops. However, please keep in mind that these workshops may overlap in time that disallows you from making presentations simultaneously.</li></ul> <p><strong>Important Dates:</strong></p> <ul><li>Submission Deadline: September 5, 2025 (Anywhere on Earth)</li> <li>Author Notification: September 22, 2025</li> <li>Workshop Date: December 6, 2025</li></ul> <p><strong>Theme and Submission Topics</strong>:</p> <p>Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of OR, has evolved through decades of advancements in stochastic modeling, computational simulation, and optimization. A key strength of the OR approach is its model-based orientation, which facilitates methodological rigor, explicit uncertainty encoding, and interpretability, making it a natural engineering approach for reliable decision-making. On the other hand, recent advances in the AI/ML space have eschewed the model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. In essence, the model-based rigor and assumptions of traditional OR are not yet designed to take full advantage of massive data and rapid computational advances in AI/ML.</p> <p>This workshop aspires to present recent developments, discuss challenges, and publicize emerging research opportunities to accelerate ML-OR synergization. By integrating ML into established OR methodologies, we have the opportunity to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of “optimality” across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around “black box” systems, and provide paths to enhance interpretability, trust, and performance analysis.</p> <p>We welcome all submissions in the interface between ML and OR, broadly defined, including contributions that are methodological or theoretical, application-oriented, and conceptually focused. The following four sub-topics will be of high interest to the workshop, but other topics broadly in the ML-OR intersection are greatly welcome as well.</p> <p><em>Embedding OR modeling insights into ML</em>: The rich problem domains conventionally tackled by OR, such as queueing control, supply chain and revenue management, present challenges from high dimensionality, variability and stability that are often addressed via structural models and domain-specific knowledge. Recent advances have shown practical benefits in OR-embedded ML techniques, including differentiable simulators and domain-informed policy parameterizations. To this end, imminent questions include the design of generic frameworks to integrate operational domain knowledge into ML algorithms, the balance between model-based insights and data-driven flexibility, validation and stress-testing of hybrid OR+ML policies, and the use of digital twins for operational data that combine AI and OR simulation.</p> <p><em>Uncertainty mitigation at the interface of data, model, and decision</em>: An important challenge in converting data into reliable decisions lies in the dissection and mitigation of errors, not only arising from data prediction, but also their interactions with the system and propagation into operational decisions. These issues can be complicated by computational and modeling limitations for complex models, optimistic bias, stochastic behaviors in decision optimization, and distribution shifts. Key questions to explore include uncertainty quantification techniques that are mindful of model computation overhead, approaches to assess performance of prescriptive decisions, and hedging of downside risks from noises and shifts via robustification or goal-driven regularization.</p> <p><em>Sequential decision-making and online learning from an OR perspective</em>: Many modern data-driven operations are intrinsically sequential, namely, the system state evolves after every action, fresh information arrives online, and decisions adapt in real time. Despite sustained efforts on theoretical research, key questions remain in achieving balance among statistical efficiency, robustness, and practical implementability, especially when facing non-stationarity, risk-sensitive, and multi-objective criteria that appear in many operational settings. These challenges present opportunities to leverage the analytic arsenal of OR, including stochastic processes, convex and non-convex optimization, optimal control, and distributionally robust techniques, that can play pivotal roles in tightening theoretical bounds, guiding exploration, and yielding computationally tractable policies.</p> <p><em>Generative AI for decision-making</em>: Generative AI has recently emerged as a transformative technology that, based on sampling and statistical modeling power, offers enhanced decision-making capabilities across multiple domains. At the same time, some of the cores in generative modeling are rooted in Monte Carlo simulation methodology and stochastic analysis, which have a rich literature in OR. Key questions to explore include the efficient utilization of generative models to capture uncertainties in complex operational problems, how to build generative frameworks to recognize guarantees on robustness or safety needed for decision-making, and how to tackle these issues via the vast theoretical and computational literature on stochastic analysis, including diffusion and flow-based models.</p> <p><strong>Contact Information</strong></p> <p>If you have any questions or would like additional information, please feel free to reach out to us via: <a href="mailto:neurips.mlxor.workshop@gmail.com"><u>neurips.mlxor.workshop@gmail.com</u></a></p>',1);function ka(e){var a=Sa();z(38),M(e,a)}var wa=_("<p>This interdisciplinary workshop explores the growing synergy between <strong>Machine Learning (ML)</strong> and <strong>Operations Research (OR)</strong>. As the first NeurIPS workshop explicitly themed on ML-OR synergization, it aims to present recent developments, discuss challenges, and publicize emerging research opportunities in data-centric decision-making that leverage both the rapid advancement of ML and the principled methodological rigor of OR. We welcome a broad range of contributions in the ML-OR intersection.</p> <p>Topics of interest include (but are not limited to):</p> <ul><li>Embedding OR modeling insights into ML</li> <li>Uncertainty mitigation at the interface of data, model, and decision</li> <li>Sequential decision-making and online learning from an OR perspective</li> <li>Generative AI for decision-making</li></ul> <p>We encourage submissions and participation from researchers across ML, OR, applied probability, and statistics, as well as practitioners from industry and public sector organizations. We especially encourage submissions that propose new methodologies, offer theoretical insights, or present real-world applications in areas such as healthcare, logistics, finance, and energy systems.</p> <p>In addition to the poster session and presentation of accepted submissions, the workshop will feature several keynote talks, panel discussions, and plenty of opportunities to interact among participants.</p> <p>We also plan to provide financial support for students and junior researchers who contribute to the workshop, via INFORMS Applied Probability Society and potentially other sponsors. More details on the application procedure will be available soon.</p>",1);function xa(e){var a=wa();z(10),M(e,a)}var Ma=_("<p>Yeganeh Alimohammadi (USC), Alessandro Arlotto (Duke), Baris Ata (Chicago), Santiago Balseiro (Columbia), Mohsen Bayati (Stanford), Amine Bennouna (Northwestern), Sem Borst (Eindhoven Univ. of Technology), Anton Braverman (Northwestern), Ana Busic (École Normale Supérieure), Prakash Chakraborty (Penn State), Vasileios Charisopoulos (Chicago), Minshuo Chen (Northwestern), Xinyun Chen (CUHK Shenzhen), Yi Chen (HKUST), Zaiwei Chen (Purdue), Stephen Chick (INSEAD), Souvik Dhara (Georgia Tech), Ton Dieker (Columbia), Sebastian Engelke (Univ. of Geneva), Lin Fan (Northwestern) Ethan Fang (Duke), Yiding Feng (HKUST), Yifan Feng (NUS), Ayoub Foussoul (Chicago), Daniel Freund (MIT), David Gamarnik (MIT), Rui Gao (UT Austin), Xuefeng Gao (CUHK), Julia Gaudio (Northwestern), Soumyadip Ghosh (IBM), Peter Glynn (Stanford), Varun Gupta (Univ. of Utah), Mert Gurbuzbalaban (Rutgers), Bernd Heidergott (Vrije Universiteit Amsterdam), Xuedong He (CUHK), Jeff Hong (Univ. of Minnesota), Harsha Honnappa (Purdue), Yue Hu (Stanford), Dongyan Huo (HKUST), Sajad Khodadadian (Virginia Tech), Yanwei Jia (CUHK), Jiashuo Jiang (HKUST), Ramesh Johari (Stanford), Gauri Joshi (CMU), Marc Lelarge (INRIA), Andrew Li (CMU), Michael Lingzhi Li (Harvard), Shuangning Li (Chicago), Sheng Liu (Toronto), Yueyang Liu (Rice), Yiping Lu (Northwestern), Thodoris Lykouris (MIT), Mehrdad Moharrami (Univ. of Iowa), Debankur Mukherjee (Georgia Tech), Karthyek Murthy (USC), Raghu Pasupathy (Purdue), Marek Petrik (Univ. of New Hampshire), Chara Podimata (MIT), Meng Qi (Cornell), Pengyu Qian (Boston Univ.), Chao Qin (Stanford), Yanlin Qu (Columbia), Chang-Han Rhee (Northwestern), Luc Rey-Bellet (UMass), Ilya Ryzhov (Maryland), Sujay Sanghavi (UT Austin), Ziv Scully (Cornell), Devavrat Shah (MIT), Sanjay Shakkottai (UT Austin), Pengyi Shi (Purdue), Nian Si (HKUST), Raghav Singal (Dartmouth), Fiona Sloothaak (Eindhoven Univ. of Technology), Emina Soljanin (Rutgers), Rayadurgam Srikant (UIUC), Mark Squillante (IBM), Vijay Subramanian (Michigan), Vasilis Syrgkanis (Stanford), Wenpin Tang (Columbia), Bruno Tuffin (INRIA), Stefan Wager (Stanford), Neil Walton (Durham), Kaizheng Wang (Columbia), Weina Wang (CMU), Zhaoran Wang (Northwestern), Ermin Wei (Northwestern), Ruoyu Wu (Iowa State), Jiaming Xu (Duke), Renyuan Xu (NYU), Yunbei Xu (NUS), Chen Yan (Michigan), Zixian Yang (Michigan), David Yao (Columbia),  Lei Ying (Michigan), Sophie Yu (UPenn), Kelly Zhang (Imperial), Zeyu Zheng (Berkeley), Angela Zhou (USC) Xunyu Zhou (Columbia), Zhengyuan Zhou (NYU), Bert Zwart (CWI)</p>");function La(e){var a=Ma();M(e,a)}const Ra=JSON.parse(`[{"content":{"title":{"value":"DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs"},"authors":{"value":["Wenzhuo Zhu","Zheng Cui","Wenhan Lu","Sheng Liu","Yue Zhao"]},"authorids":{"value":["~Wenzhuo_Zhu2","~Zheng_Cui2","~Wenhan_Lu1","~Sheng_Liu13","~Yue_Zhao8"]},"keywords":{"value":["LLM for operations research","data-driven optimization","optimization under uncertainty","automatic modeling"]},"TLDR":{"value":"LLM for data-driven optimization under uncertainty"},"abstract":{"value":"Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization."},"pdf":{"value":"/pdf/50e20eb019bbc1a6febb96788edc2f830121c403.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhu2025daopt,\\ntitle={{DAO}pt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with {LLM}s},\\nauthor={Wenzhuo Zhu and Zheng Cui and Wenhan Lu and Sheng Liu and Yue Zhao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=T1n3ri92Qk}\\n}"},"paperhash":{"value":"zhu|daopt_modeling_and_evaluation_of_datadriven_optimization_under_uncertainty_with_llms"}},"id":"T1n3ri92Qk","forum":"T1n3ri92Qk","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission241/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission241/Authors"],"number":241,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission241/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757159824867,"cdate":1757159824867,"tmdate":1764510131628,"mdate":1764510131628,"pdate":1764306366803,"odate":1764510131593,"version":2},{"content":{"title":{"value":"k-SVD with Gradient Descent"},"authors":{"value":["Yassir Jedra","Devavrat Shah"]},"authorids":{"value":["~Yassir_Jedra1","~Devavrat_Shah1"]},"keywords":{"value":["SVD; Gradient Descent; Nonconvex Matrix Factorization; Nesterov's Acceleration"]},"abstract":{"value":"The emergence of modern compute infrastructure for iterative optimization has led to great interest in developing optimization-based approaches for a scalable computation of $k$-SVD, i.e., the $k\\\\geq 1$ largest singular values and corresponding vectors of a matrix of rank $d \\\\geq 1$. Despite lots of exciting recent works, \\nall prior works fall short in this pursuit. Specifically, the existing results are either for the exact-parameterized (i.e., $k = d$) and over-parameterized (i.e., $k > d$) settings; or only establish local convergence guarantees; or use a step-size that requires problem-instance-specific oracle-provided information. In this work, we complete this pursuit by providing a gradient-descent method with a simple, universal rule for step-size selection (akin to pre-conditioning), that provably finds $k$-SVD for matrix of any rank $d \\\\geq 1$. We establish that the gradient method with random initialization enjoys global linear convergence for any $k, d \\\\geq 1$. Our convergence analysis reveals that the gradient  method has an attractive region, and within this attractive region, the method behaves like Heron's method (a.k.a. the Babylonian method). Our analytic results about the said attractive region imply that the gradient method can be enhanced by means of Nesterov's momentum-based acceleration technique. The resulting improved convergence rates match those of rather complicated methods typically relying on Lanczos iterations or variants thereof. We provide an empirical study to validate the theoretical results."},"pdf":{"value":"/pdf/823373879282506b941cdb90daf230ad9b512f63.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njedra2025ksvd,\\ntitle={k-{SVD} with Gradient Descent},\\nauthor={Yassir Jedra and Devavrat Shah},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=SFh5wxO2nr}\\n}"},"paperhash":{"value":"jedra|ksvd_with_gradient_descent"}},"id":"SFh5wxO2nr","forum":"SFh5wxO2nr","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission239/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission239/Authors"],"number":239,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission239/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757159486892,"cdate":1757159486892,"tmdate":1764510131498,"mdate":1764510131498,"pdate":1764306366201,"odate":1764510131482,"version":2},{"content":{"title":{"value":"Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios"},"authors":{"value":["Sophia V. Kuhn","Rafael Bischof","Marius Weber","Antoine Binggeli","Michael Kraus","Walter Kaufmann","Fernando Perez-Cruz"]},"authorids":{"value":["~Sophia_V._Kuhn1","~Rafael_Bischof1","weber@ibk.baug.ethz.ch","antoine.binggeli@ibk.baug.ethz.ch","~Michael_Kraus1","kaufmann@ibk.baug.ethz.ch","~Fernando_Perez-Cruz1"]},"keywords":{"value":["Bayesian neural networks","Surrogate modeling","Uncertainty quantification","Structural engineering","Decision support","Infrastructure portfolios","Non-linear finite element analysis"]},"TLDR":{"value":"Bayesian neural network surrogates enable fast, uncertainty-aware assessment of aging bridge portfolios, supporting scalable triage decisions from limited available structural information."},"abstract":{"value":"Aging infrastructure portfolios pose a critical resource allocation challenge: deciding which structures require intervention and which can safely remain in service. \\nToday’s structural assessment approaches do not scale to portfolio level, as they require time-consuming manual digital modeling and computationally expensive simulations for each individual structure.\\nWe propose Bayesian neural network (BNN) surrogates for rapid structural pre-assessment of worldwide common bridge types, such as reinforced concrete frame bridges. Trained on a large-scale database of non-linear finite element analyses generated via a parametric pipeline and developed based on the Swiss Federal Railway's bridge portfolio, the models accurately and efficiently estimate high-fidelity structural analysis results by predicting code compliance factors with calibrated epistemic uncertainty. \\nOur BNN surrogate enables fast, uncertainty-aware triage: flagging likely critical structures and providing guidance where refined analysis is pertinent. \\nWe demonstrate the framework's effectiveness in a real-world case study of a railway underpass, showing its potential to significantly reduce costs and emissions by avoiding unnecessary analyses and physical interventions across entire infrastructure portfolios."},"pdf":{"value":"/pdf/1a2c42166e7327b0ad136ea5e02172471ecba47e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkuhn2025bayesian,\\ntitle={Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios},\\nauthor={Sophia V. Kuhn and Rafael Bischof and Marius Weber and Antoine Binggeli and Michael Kraus and Walter Kaufmann and Fernando Perez-Cruz},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=4Sm5kLCwr8}\\n}"},"paperhash":{"value":"kuhn|bayesian_surrogates_for_riskaware_preassessment_of_aging_bridge_portfolios"}},"id":"4Sm5kLCwr8","forum":"4Sm5kLCwr8","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission238/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission238/Authors"],"number":238,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission238/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757159262576,"cdate":1757159262576,"tmdate":1764510131471,"mdate":1764510131471,"pdate":1764306366201,"odate":1764510131456,"version":2},{"content":{"title":{"value":"Bayesian Optimization using Partially Observable Gaussian Process Network"},"authors":{"value":["Saksham Kiroriwal","Julius Pfrommer","Jürgen Beyerer"]},"authorids":{"value":["~Saksham_Kiroriwal1","~Julius_Pfrommer1","~Jürgen_Beyerer1"]},"keywords":{"value":["Bayesian Optimization","Gaussian process network","Manufacturing optimization"]},"TLDR":{"value":"Bayesian optimization of stochastic process networks with noisy observations"},"abstract":{"value":"Bayesian Optimization (BO) is a highly successful technique for the optimization of noisy functions, but it can be difficult to scale. Gaussian Process Networks (GPN) replace a single black-box approximation with a network of connected noisy functions. This exploits sparsity in the causal links between process variables and improves the sample complexity for approximating the target function. In addition to the GPN setting, in many real-world process networks, we observe not only the final output but also intermediate observations. For example, by adding sensor instrumentation within a \\\\enquote{black-box} process network. These intermediate observations are often incomplete and noisy. We propose Partially Observable Gaussian Process Network (POGPN), and its inference method, which addresses the limitations of GPN by handling noisy observations and uncertainty propagation while incorporating the structural knowledge of the process network. We empirically show superior performance of POGPN for Bayesian Optimization using benchmark functions and an ODE-based Penicillin production process."},"pdf":{"value":"/pdf/07b9387dde12ba98d01496caf07892365f966859.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkiroriwal2025bayesian,\\ntitle={Bayesian Optimization using Partially Observable Gaussian Process Network},\\nauthor={Saksham Kiroriwal and Julius Pfrommer and J{\\\\\\"u}rgen Beyerer},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=4yOonIO4QD}\\n}"},"paperhash":{"value":"kiroriwal|bayesian_optimization_using_partially_observable_gaussian_process_network"}},"id":"4yOonIO4QD","forum":"4yOonIO4QD","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission237/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission237/Authors"],"number":237,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission237/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757159210378,"cdate":1757159210378,"tmdate":1764510131445,"mdate":1764510131445,"pdate":1764306365951,"odate":1764510131429,"version":2},{"content":{"title":{"value":"Optimization-Driven XGBoost-PINN Framework for Building Temperature Prediction"},"authors":{"value":["Tushar Shinde","Rohan Saha"]},"authorids":{"value":["~Tushar_Shinde1","~Rohan_Saha2"]},"keywords":{"value":["Physics-Informed Neural Networks","Uncertainty-Aware Forecasting","Multi-Stage Optimization","Energy-Efficient Building Control","Smart Cities","Operations Research Integration","Spatio-Temporal Prediction"]},"abstract":{"value":"Building temperature prediction is critical for energy-efficient control in smart cities. We propose a novel hybrid framework that synergizes machine learning (ML) with operations research (OR) principles, combining XGBoost with physics-informed neural networks (PINNs) in a multi-stage optimization-driven approach. Starting from single-zone, single-day forecasts, we scale to multi-zone, multi-year predictions using Google’s Smart Building Simulator data. Our method optimizes physics-enhanced features, temporal encodings, and inter-zone interactions to mitigate uncertainty from noisy sensor data, achieving mean absolute errors (MAE) as low as 0.169°F for weekly multi-zone predictions. For long-term horizons, we employ OR-inspired ensemble strategies, maintaining robust performance up to 2.5 years. This work advances by enabling uncertainty-aware, energy-efficient building control for sustainable smart cities."},"pdf":{"value":"/pdf/9b9e52ccb6980bec00e4927a5ca743365bd87ce5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nshinde2025optimizationdriven,\\ntitle={Optimization-Driven {XGB}oost-{PINN} Framework for Building Temperature Prediction},\\nauthor={Tushar Shinde and Rohan Saha},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=VI8Ec3dVr4}\\n}"},"paperhash":{"value":"shinde|optimizationdriven_xgboostpinn_framework_for_building_temperature_prediction"}},"id":"VI8Ec3dVr4","forum":"VI8Ec3dVr4","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission235/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission235/Authors"],"number":235,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission235/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757157786342,"cdate":1757157786342,"tmdate":1764510131375,"mdate":1764510131375,"pdate":1764306365802,"odate":1764510131354,"version":2},{"content":{"title":{"value":"Decision Focused Scenario Generation for Contextual Two-Stage Stochastic Linear Programming"},"authors":{"value":["Jonathan Hornewall","Solène Delannoy-Pavy","Vincent Leclère","Tito Homem-De-Mello"]},"authorids":{"value":["~Jonathan_Hornewall1","solene.delannoy-pavy@enpc.fr","vincent.leclere@enpc.fr","tito.hmello@uai.cl"]},"keywords":{"value":["contextual stochastic programming","decision-focused learning","differentiable optimization","log-barrier methods; scenario generation"]},"TLDR":{"value":"We apply decision-focused learning to train a neural network that maps contexts to scenarios in a contextual two-stage stochastic linear program, using log-barrier regularization to enable efficient gradient-based training."},"abstract":{"value":"We introduce a decision-focused scenario generation framework for contextual\\n    two-stage stochastic linear programs that bypasses explicit conditional\\n    distribution modeling.\\n    A neural generator maps a context $x$ to a fixed-size set of scenarios\\n    $\\\\{\\\\xi_s(x)\\\\}_{s=1}^S$.\\n    For each generated collection we compute a first-stage decision by solving a\\n    single log-barrier regularized deterministic equivalent whose KKT system yields\\n    closed-form, efficiently computable derivatives via implicit differentiation.\\n    The network is trained end-to-end to minimize the true (unregularized)\\n    downstream cost evaluated on observed data, avoiding auxiliary value-function\\n    surrogates, bi-level heuristics, or differentiation through generic LP solvers.\\n    Unlike single-scenario methods, our approach natively learns multi-scenario\\n    representations; unlike distribution-learning pipelines, it scales without\\n    requiring density estimation in high dimension. \\n    We detail the barrier formulation, the analytic gradient structure with respect\\n    to second-stage data, and the resulting computational trade-offs.\\n\\n    Preliminary experiments on contextual synthetic instances illustrate that the\\n    method can rival current state-of-the-art methods, even when trained on\\n    small amounts of training data."},"pdf":{"value":"/pdf/eac1d2d1a7a82ec57e097c806ecbff68dd70f0cf.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhornewall2025decision,\\ntitle={Decision Focused Scenario Generation for Contextual Two-Stage Stochastic Linear Programming},\\nauthor={Jonathan Hornewall and Sol{\\\\\`e}ne Delannoy-Pavy and Vincent Lecl{\\\\\`e}re and Tito Homem-De-Mello},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=j8BVbta5lg}\\n}"},"paperhash":{"value":"hornewall|decision_focused_scenario_generation_for_contextual_twostage_stochastic_linear_programming"}},"id":"j8BVbta5lg","forum":"j8BVbta5lg","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission232/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission232/Authors"],"number":232,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission232/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757156963252,"cdate":1757156963252,"tmdate":1764510131230,"mdate":1764510131230,"pdate":1764306365607,"odate":1764510131216,"version":2},{"content":{"title":{"value":"A Dual Perspective on Decision Focused Learning"},"authors":{"value":["Paula Rodriguez-Diaz","Kirk Bansak","Elisabeth Paulson"]},"authorids":{"value":["~Paula_Rodriguez-Diaz1","~Kirk_Bansak1","~Elisabeth_Paulson1"]},"keywords":{"value":["Decision-Focused Learning","Dual Theory","Machine Learning"]},"abstract":{"value":"Predict-then-optimize (PtO) pipelines use predictions as inputs to a downstream optimizer that produces decisions. Decision-Focused Learning (DFL) trains the predictor inside this pipeline to improve the quality of those decisions, not just prediction accuracy. Most DFL approaches do so by differentiating through the optimizer or by designing tight task-specific surrogates—both of which demand frequent solver calls and drive up training cost. We introduce a dual-guided DFL method that preserves decision alignment while sharply reducing solver-in-the-loop cost. The key idea is to solve the downstream problem only periodically to refresh dual variables and, between refreshes, train on dual-adjusted targets using simple surrogate losses. As refreshes become less frequent, the training loop’s cost approaches standard supervised learning while maintaining high-quality decisions."},"pdf":{"value":"/pdf/ae5a1de91e14318e8de90228dd1ff5cadec653a5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nrodriguez-diaz2025a,\\ntitle={A Dual Perspective on Decision Focused Learning},\\nauthor={Paula Rodriguez-Diaz and Kirk Bansak and Elisabeth Paulson},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=7HN84yBixi}\\n}"},"paperhash":{"value":"rodriguezdiaz|a_dual_perspective_on_decision_focused_learning"}},"id":"7HN84yBixi","forum":"7HN84yBixi","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission229/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission229/Authors"],"number":229,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission229/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757154622505,"cdate":1757154622505,"tmdate":1764510131128,"mdate":1764510131128,"pdate":1764306365431,"odate":1764510131110,"version":2},{"content":{"title":{"value":"Who Should Do What? Adaptive Delegation in Human-AI Collaboration"},"authors":{"value":["Wei Gu","Michael Lingzhi Li","Shixiang Zhu"]},"authorids":{"value":["weigu@andrew.cmu.edu","~Michael_Lingzhi_Li1","~Shixiang_Zhu1"]},"keywords":{"value":["Human-AI","Generalized Nash Equilibrium","Agentic AI"]},"abstract":{"value":"As human-AI collaboration becomes increasingly common in real-world decision-making systems, it is essential to develop principled frameworks for deciding who should act and when: the AI, the human, or both. In this paper, we develop optimal delegation strategies for settings where human oversight adds value but comes at a cost. We propose an adaptive delegation framework in which a central coordinator assigns each task to either the AI, the human, or a human-in-the-loop review process. Importantly, we model the human as a cost-sensitive and adaptive agent, whose effort adapts based on the AI’s accuracy. This interaction is formalized using a generalized Nash equilibrium framework, which allows us to characterize stable collaboration strategies under broad conditions. We provide theoretical guarantees that identify when adaptive delegation enables effective cooperation and how human-AI collaboration evolves according to the development of AI technologies. Numerical experiments confirm that our approach improves overall system performance under accuracy and cost constraints. These results offer practical guidance for designing agentic AI systems that balance efficiency with meaningful human involvement."},"pdf":{"value":"/pdf/58177903fc6c75903ae9d2c57caa0877367d42c5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ngu2025who,\\ntitle={Who Should Do What? Adaptive Delegation in Human-{AI} Collaboration},\\nauthor={Wei Gu and Michael Lingzhi Li and Shixiang Zhu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=niwQ5Zd6Mx}\\n}"},"paperhash":{"value":"gu|who_should_do_what_adaptive_delegation_in_humanai_collaboration"}},"id":"niwQ5Zd6Mx","forum":"niwQ5Zd6Mx","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission228/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission228/Authors"],"number":228,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission228/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757152990382,"cdate":1757152990382,"tmdate":1764510131105,"mdate":1764510131105,"pdate":1764306365353,"odate":1764510131086,"version":2},{"content":{"title":{"value":"Exploration via Feature Perturbation in Contextual Bandits"},"authors":{"value":["Seouh-won Yi","Min-hwan Oh"]},"authorids":{"value":["~Seouh-won_Yi1","~Min-hwan_Oh1"]},"keywords":{"value":["Generalized Linear Bandits","Contextual Bandits","Thompson Sampling","Feature Perturbation"]},"TLDR":{"value":"We study the feature-perturbing exploration method applicable to various bandit settings, and prove that our randomized method achieves optimal regret guarantee."},"abstract":{"value":"We propose *feature perturbation*, a simple yet effective exploration strategy for contextual bandits that injects randomness directly into feature inputs, instead of randomizing unknown parameters or adding noise to rewards.\\nRemarkably, this algorithm achieves $\\\\widetilde{\\\\mathcal O}(d\\\\sqrt{T})$ worst-case regret bound for generalized linear contextual bandits, while avoiding the $\\\\widetilde{\\\\mathcal O}(d^{3/2}\\\\sqrt{T})$ regret typical of existing randomized bandit algorithms.\\nBecause our algorithm eschews parameter sampling, it is both computationally efficient and naturally extends to non-parametric or neural network models.\\nWe verify these advantages through empirical evaluations, demonstrating that feature perturbation not only  surpasses existing methods but also unifies strong practical performance with the near-optimal regret guarantees."},"pdf":{"value":"/pdf/e904bcc9e3df2aabfbf0774d925372cc4f39f98f.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyi2025exploration,\\ntitle={Exploration via Feature Perturbation in Contextual Bandits},\\nauthor={Seouh-won Yi and Min-hwan Oh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=rOSOXlwBqO}\\n}"},"paperhash":{"value":"yi|exploration_via_feature_perturbation_in_contextual_bandits"}},"id":"rOSOXlwBqO","forum":"rOSOXlwBqO","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission227/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission227/Authors"],"number":227,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission227/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757151645314,"cdate":1757151645314,"tmdate":1764510131084,"mdate":1764510131084,"pdate":1764306365307,"odate":1764510131066,"version":2},{"content":{"title":{"value":"Blessings of many good arms in multi-objective linear bandits"},"authors":{"value":["Heesang Ann","Min-hwan Oh"]},"authorids":{"value":["~Heesang_Ann1","~Min-hwan_Oh1"]},"keywords":{"value":["multi-objective","free exploration","linear bandit"]},"TLDR":{"value":"We studied free exploration in multi-objective bandits when there are many good arms."},"abstract":{"value":"Multi-objective decision-making is often deemed overly complex in bandit settings, leading to algorithms that are both complicated and frequently impractical. In this paper, we challenge that notion by showing that, \\nunder a novel *goodness of arms* condition, multiple objectives can facilitate learning, enabling simple near-greedy methods to achieve sub-linear Pareto regret.\\nTo our knowledge, this is the first work to demonstrate the effectiveness of near-greedy algorithms for multi-objective bandits and also the first to study the regret of such algorithms for parametric bandits in the absence of context distributional assumptions."},"pdf":{"value":"/pdf/b62b24950e66c945de5a72af386b27cfff56e2d5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nann2025blessings,\\ntitle={Blessings of many good arms in multi-objective linear bandits},\\nauthor={Heesang Ann and Min-hwan Oh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=06tqoOl829}\\n}"},"paperhash":{"value":"ann|blessings_of_many_good_arms_in_multiobjective_linear_bandits"}},"id":"06tqoOl829","forum":"06tqoOl829","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission226/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission226/Authors"],"number":226,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission226/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757151201912,"cdate":1757151201912,"tmdate":1764510130992,"mdate":1764510130992,"pdate":1764306365265,"odate":1764510130978,"version":2},{"content":{"title":{"value":"Statistical Properties of Robust Optimization under Distribution Shifts"},"authors":{"value":["Zhiyi Li","Xiaojie Mao","Yunbei Xu","Ruohan Zhan"]},"authorids":{"value":["~Zhiyi_Li7","~Xiaojie_Mao1","~Yunbei_Xu1","~Ruohan_Zhan1"]},"keywords":{"value":["Distributional Shift","Distributionally Robust Optimization","Robust Satisficing","Generalization Upper Bound"]},"abstract":{"value":"Distributional shifts commonly arise in practice when the target environment differs from the source environment that provides training data.\\nRobust learning frameworks such as Distributionally Robust Optimization (DRO) and Robust Satisficing (RS) have been developed to address this challenge, yet their theoretical behavior under such shifts remains insufficiently understood.\\nThis paper analyzes their performance under distributional shifts measured by the Wasserstein distance, focusing on the generalization error defined as the excess loss in the target environment.\\nWe derive the first generalization error bounds that explicitly characterize how DRO and RS balance improved robustness in the target environment with the regularization cost of robustness, while avoiding the curse of dimensionality.\\nWhen partial shift information such as magnitude or direction is available, we conduct a systematic comparison of both methods and provide theory-based guidelines for selecting between them, supported by simulation results.\\nFinally, we demonstrate the practical relevance of our framework through an application to a network lot-sizing problem.\\nThis work fills theoretical gaps in robust learning under distributional shifts and provides practical guidance for algorithm design."},"pdf":{"value":"/pdf/9225c4f6200b6ca25b0ba1fa5f859ed75427bd5f.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nli2025statistical,\\ntitle={Statistical Properties of Robust Optimization under Distribution Shifts},\\nauthor={Zhiyi Li and Xiaojie Mao and Yunbei Xu and Ruohan Zhan},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=svG94LVjAO}\\n}"},"paperhash":{"value":"li|statistical_properties_of_robust_optimization_under_distribution_shifts"}},"id":"svG94LVjAO","forum":"svG94LVjAO","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission225/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission225/Authors"],"number":225,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission225/-/Camera_Ready_Submission"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757150594349,"cdate":1757150594349,"tmdate":1764510130942,"mdate":1764510130942,"pdate":1764306365191,"odate":1764510130921,"version":2},{"content":{"title":{"value":"Transformer-Based Next-Step Prediction for Queue Length Distribution"},"authors":{"value":["Jieqi Di","Jiecheng Lu","Runhua Wu","Yuwei Zhou"]},"authorids":{"value":["~Jieqi_Di1","~Jiecheng_Lu1","~Runhua_Wu1","~Yuwei_Zhou3"]},"keywords":{"value":["Deep Learning","Autoregressive Model","Queueing Theory"]},"abstract":{"value":"Traditional approaches to model queueing dynamics from real-world setting rely on model selection, parameter estimation, and simulation. These methods struggle with complexities like time-varying arrivals, customer abandonment, and routing interactions, while parameter estimation errors and time-consuming simulations further limit their predictive accuracy and increase their costs.\\nWe propose a data-driven alternative that learns queueing dynamics directly from historical data using decoder-only Transformers. Our approach uses the autoregressive nature of queueing systems, where future states depend causally on past sequences through recursions. We treat queue evolution as a sequence prediction problem: inputting queue length distributions and predicting next-step distributions. Experiments on synthetic data demonstrate that our Transformer-based model successfully reproduces queueing dynamics across different queueing models and outperforms traditional sequence models like Recurrent Neural Networks (RNNs). This model-free approach eliminates the need for explicit model specification and parameter estimation while maintaining accuracy in capturing complex system behaviors. Future work will validate this methodology on real-world ride-hailing datasets."},"pdf":{"value":"/pdf/7b40a2714fbeba073189bc076611b3681690c601.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndi2025transformerbased,\\ntitle={Transformer-Based Next-Step Prediction for Queue Length Distribution},\\nauthor={Jieqi Di and Jiecheng Lu and Runhua Wu and Yuwei Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ErSFgi45jD}\\n}"},"paperhash":{"value":"di|transformerbased_nextstep_prediction_for_queue_length_distribution"}},"id":"ErSFgi45jD","forum":"ErSFgi45jD","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission224/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission224/Authors"],"number":224,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission224/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757150405945,"cdate":1757150405945,"tmdate":1764510130923,"mdate":1764510130923,"pdate":1764306365094,"odate":1764510130903,"version":2},{"content":{"title":{"value":"Safe Start: Configuring Optimization Algorithms for Decision-Making under Extreme Risks"},"authors":{"value":["Wasin Meesena","Henry Lam"]},"authorids":{"value":["~Wasin_Meesena1","~Henry_Lam1"]},"keywords":{"value":["Rare-Event Simulation","Decision-Making Under Extreme Risk","Safe Start","Stochastic Gradient Descent"]},"abstract":{"value":"We consider stochastic optimization where the goal is not only to optimize an average-case objective, but also mitigate the occurrence of rare catastrophic events. This problem is motivated from safety-aware decision-making and AI training. We first argue that, in the presence of a simulation model, natural attempts to integrate variance reduction into optimization, even executed in a reasonable adaptive fashion, encounters fundamental challenges in guaranteeing realistic runtime when using common stochastic gradient descent algorithms. This challenge arises from the extreme sensitivity of tail-based objectives with respect to the decision variables, which renders the failure of traditional Lipschitz-based analyses. We offer remedies based on a new notion of safe start that allows for efficient finite-time error control, and show how the sampling complexity scales favorably under the combination of safe start and variance reduction. We illustrate our methodologies on examples in portfolio Value-at-Risk and extreme-quantile estimation."},"pdf":{"value":"/pdf/fb540cbe4daa62f0848a0c6f66815d7ba19034ed.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmeesena2025safe,\\ntitle={Safe Start: Configuring Optimization Algorithms for Decision-Making under Extreme Risks},\\nauthor={Wasin Meesena and Henry Lam},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=7c0Zu2cyG7}\\n}"},"paperhash":{"value":"meesena|safe_start_configuring_optimization_algorithms_for_decisionmaking_under_extreme_risks"}},"id":"7c0Zu2cyG7","forum":"7c0Zu2cyG7","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission222/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission222/Authors"],"number":222,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission222/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757150248197,"cdate":1757150248197,"tmdate":1764510130830,"mdate":1764510130830,"pdate":1764306365051,"odate":1764510130806,"version":2},{"content":{"title":{"value":"Geometric Data Valuation via Leverage Scores"},"authors":{"value":["Rodrigo Mendoza Smith"]},"authorids":{"value":["~Rodrigo_Mendoza_Smith1"]},"keywords":{"value":["Data valuation","Data Shapley","Leverage scores","Ridge regression","Randomized Numerical Linear Algebra","Active Learning"]},"TLDR":{"value":"We propose a geometric notion of data value based on ridge leverage scores, prove that it satisfies Data Shapley axioms and provides $\\\\mathcal{O}(\\\\varepsilon)$-close guarantees for a specific risk model."},"abstract":{"value":"Shapley data valuation provides a principled, axiomatic framework for assigning importance to individual datapoints, and has gained traction in dataset curation, pruning, and pricing. However, it is a combinatorial measure that requires evaluating marginal utility across all subsets of the data, making it computationally infeasible at scale. We propose a geometric alternative based on statistical leverage scores, which quantify each datapoint's structural influence in the representation space by measuring how much it extends the span of the dataset and contributes to the effective dimensionality of the training problem. We show that our scores satisfy the dummy, efficiency, and symmetry axioms of Shapley valuation and that extending them to \\\\emph{ridge leverage scores} yields strictly positive marginal gains that connect naturally to classical A- and D-optimal design criteria. We further show that training on a leverage-sampled subset produces a model whose parameters and predictive risk are within $O(\\\\varepsilon)$ of the full-data optimum, thereby providing a rigorous link between data valuation and downstream decision quality. Finally, we conduct an active learning experiment in which we empirically demonstrate that ridge-leverage sampling outperforms standard baselines without requiring access gradients or backward passes."},"pdf":{"value":"/pdf/aea851e5d22cd1b0849e313ff6bddb25ff6113cb.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nsmith2025geometric,\\ntitle={Geometric Data Valuation via Leverage Scores},\\nauthor={Rodrigo Mendoza Smith},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=msXDIBipir}\\n}"},"paperhash":{"value":"smith|geometric_data_valuation_via_leverage_scores"}},"id":"msXDIBipir","forum":"msXDIBipir","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission221/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission221/Authors"],"number":221,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission221/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757148961330,"cdate":1757148961330,"tmdate":1764510130790,"mdate":1764510130790,"pdate":1764306364945,"odate":1764510130768,"version":2},{"content":{"title":{"value":"Selective Cost-Aware Random Forests for Unreliable Data"},"authors":{"value":["Sarwesh Rauniyar"]},"authorids":{"value":["~Sarwesh_Rauniyar1"]},"keywords":{"value":["cost-sensitive classification","selective prediction","decision-focused learning","oblique decision forests","distribution shift","covariate shift","label noise","missing data","MCAR missingness"]},"abstract":{"value":"Decision forests are widely used for tabular data due to their efficiency and strong performance, but they typically optimize accuracy under i.i.d. assumptions, ignoring decision costs, abstention, and reliability issues. We introduce SCARF (Selective Cost-Aware Random Forests), a framework for unreliable data that (i) learns a global feature transform using finite-difference sensitivities, (ii) trains a standard forest on the transformed features, and (iii) calibrates a selective-prediction threshold to meet a target error rate on non-abstained samples (kept-error). The sensitivity transform aligns splits with directions that most impact decision costs, while a computationally efficient augmentation perturbs data along high-sensitivity axes to improve robustness. On public credit-risk datasets subjected to covariate shift, Missing Completely At Random (MCAR) patterns, and label noise, SCARF reduces policy cost by 11-15\\\\%, while maintaining 83-88\\\\% coverage at target 10\\\\% kept-error, outperforming strong boosted and oblique baselines. Ablations indicate complementary contributions from the finite-difference-based transform, selective calibration, and sensitivity-guided augmentation. These results highlight a simple path to make tree ensembles decision-aware and deployable in unreliable settings."},"pdf":{"value":"/pdf/31a4ffecb2047af4d5fe27c7c68d143cc2e1c8ce.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nrauniyar2025selective,\\ntitle={Selective Cost-Aware Random Forests for Unreliable Data},\\nauthor={Sarwesh Rauniyar},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=McQ73Hv4Ru}\\n}"},"paperhash":{"value":"rauniyar|selective_costaware_random_forests_for_unreliable_data"}},"id":"McQ73Hv4Ru","forum":"McQ73Hv4Ru","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission220/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission220/Authors"],"number":220,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission220/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757148509932,"cdate":1757148509932,"tmdate":1764510130717,"mdate":1764510130717,"pdate":1764306364942,"odate":1764510130698,"version":2},{"content":{"title":{"value":"A Behavioral Model for Exploration vs. Exploitation: Theoretical Framework and Experimental Evidence"},"authors":{"value":["Jingying Ding","Yifan Feng","Ying Rong"]},"authorids":{"value":["~Jingying_Ding2","~Yifan_Feng2","~Ying_Rong1"]},"keywords":{"value":["multi-armed bandit","Thompson sampling","quantal choice models","exploration-exploitation trade-off"]},"abstract":{"value":"How do people navigate the exploration-exploitation (EE) trade-off when making repeated choices with unknown rewards? We study this question through the lens of multi-armed bandit problems and introduce a novel behavioral model, Quantal Choice with Adaptive Reduction of Exploration (QCARE). It generalizes Thompson Sampling, allowing for a principled way to quantify the EE trade-off and reflect human decision-making patterns. The model adaptively reduces exploration as information accumulates, with the reduction rate serving as a parameter to quantify the EE trade-off dynamics. We theoretically analyze how varying reduction rates influence decision quality, shedding light on the effects of \\"over-exploration\\" and \\"under-exploration.\\" Empirically, we validate QCARE through experiments collecting behavioral data from human participants. QCARE not only captures critical behavioral patterns in the EE trade-off but also outperforms alternative models in predictive power. Our analysis reveals a behavioral tendency toward over-exploration."},"pdf":{"value":"/pdf/482299eb857665d86ea9dd21211596b1d87368a6.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nding2025a,\\ntitle={A Behavioral Model for Exploration vs. Exploitation: Theoretical Framework and Experimental Evidence},\\nauthor={Jingying Ding and Yifan Feng and Ying Rong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=QBRFc2UHT4}\\n}"},"paperhash":{"value":"ding|a_behavioral_model_for_exploration_vs_exploitation_theoretical_framework_and_experimental_evidence"}},"id":"QBRFc2UHT4","forum":"QBRFc2UHT4","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission216/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission216/Authors"],"number":216,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission216/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757144143301,"cdate":1757144143301,"tmdate":1764510130617,"mdate":1764510130617,"pdate":1764306364659,"odate":1764510130602,"version":2},{"content":{"title":{"value":"Plan for the Worst With Advice: Advice-Augmented Robust Markov Decision Processes"},"authors":{"value":["Tinashe Handina","Kishan Panaganti","Eric Mazumdar","Adam Wierman"]},"authorids":{"value":["~Tinashe_Handina1","~Kishan_Panaganti1","~Eric_Mazumdar1","~Adam_Wierman1"]},"keywords":{"value":["Reinforcement Learning","Robustness","Advice-augmented"]},"abstract":{"value":"We consider the integration of advice into Robust Markov Decision Processes (RMDPs). While the RMDP formulation aids in modeling ambiguity with respect to transition dynamics, it is overly conservative due to its focus on worst-case instances. To move beyond the worst-case framework, we propose an advice-augmented setting in which the decision maker has access to advice in the form of a predicted transition kernel they seek to leverage to obtain better guarantees. The decision maker in this setting cares about finding a policy that performs well for both the worst case and advice transition dynamics. Thus, we define \\\\emph{robustness} and \\\\emph{consistency} as metrics the decision maker optimizes and propose a family of optimization problems whose solutions are Pareto-optimal with respect to robustness and consistency. Under standard assumptions on the ambiguity set, the optimal solutions are deterministic, Markovian, and stationary. Given a set of Pareto-optimal policies, we then provide a policy selection algorithm that achieves max-min optimality across robustness and consistency."},"pdf":{"value":"/pdf/6918720b56d9e70420551cf7f11ac7df729968e9.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhandina2025plan,\\ntitle={Plan for the Worst With Advice: Advice-Augmented Robust Markov Decision Processes},\\nauthor={Tinashe Handina and Kishan Panaganti and Eric Mazumdar and Adam Wierman},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=whhiR0vlKR}\\n}"},"paperhash":{"value":"handina|plan_for_the_worst_with_advice_adviceaugmented_robust_markov_decision_processes"}},"id":"whhiR0vlKR","forum":"whhiR0vlKR","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission215/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission215/Authors"],"number":215,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission215/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757143839688,"cdate":1757143839688,"tmdate":1764510130580,"mdate":1764510130580,"pdate":1764306364657,"odate":1764510130566,"version":2},{"content":{"title":{"value":"Admissibility of Completely Randomized Trials: A Large-Deviation Approach"},"authors":{"value":["Guido Imbens","Chao Qin","Stefan Wager"]},"authorids":{"value":["~Guido_Imbens1","~Chao_Qin1","~Stefan_Wager1"]},"keywords":{"value":["Randomized controlled trials","best-arm identification","large deviation principle","dominance and admissibility"]},"TLDR":{"value":"Uniform allocation is inadmissible: there exist adaptive designs that universally outperform it across problem instances."},"abstract":{"value":"When an experimenter has the option of running an adaptive trial, is it admissible to ignore this option and run a non-adaptive trial instead? We provide a negative answer to this question in the best-arm identification problem, where the experimenter aims to allocate measurement efforts judiciously to confidently deploy the most effective treatment arm. We find that, whenever there are at least three treatment arms, there exist simple adaptive designs that universally and strictly dominate non-adaptive completely randomized trials. This dominance is characterized by a notion called efficiency exponent, which quantifies a design's statistical efficiency when the experimental sample is large. Our analysis focuses on the class of batched arm elimination designs, which progressively eliminate underperforming arms at pre-specified batch intervals. We characterize simple sufficient conditions under which these designs universally and strictly dominate completely randomized trials. These results resolve the second open problem posed in Qin [2022]."},"pdf":{"value":"/pdf/06d7a77899a05aacb799ccec1724792e4569f285.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nimbens2025admissibility,\\ntitle={Admissibility of Completely Randomized Trials: A Large-Deviation Approach},\\nauthor={Guido Imbens and Chao Qin and Stefan Wager},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=nqYesbsItX}\\n}"},"paperhash":{"value":"imbens|admissibility_of_completely_randomized_trials_a_largedeviation_approach"}},"id":"nqYesbsItX","forum":"nqYesbsItX","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission214/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission214/Authors"],"number":214,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission214/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757143822468,"cdate":1757143822468,"tmdate":1764510130582,"mdate":1764510130582,"pdate":1764306364591,"odate":1764510130564,"version":2},{"content":{"title":{"value":"Autoregressive Learning under Joint KL Analysis: Horizon-Free Approximation and Computational-Statistical Tradeoffs"},"authors":{"value":["Yunbei Xu","Yuzhe Yuan","Ruohan Zhan"]},"authorids":{"value":["~Yunbei_Xu1","~Yuzhe_Yuan1","~Ruohan_Zhan1"]},"keywords":{"value":["autoregressive modeling","generalization bound","improper learning","computational-statistical tradeoff"]},"abstract":{"value":"We study autoregressive generative modeling under misspecification measured by the joint Kullback–Leibler (KL) divergence. For approximation, we show that joint KL admits a horizon-free barrier independent of the sequence length $H$, unlike prior Hellinger-based analyses that imply an $\\\\Omega(H)$ dependence. \\nFor estimation, we prove a finite-sample lower bound showing that any proper learner, including empirical risk minimization, suffers $\\\\Omega(H^2)$ error.\\nWe then propose an improper Bayesian posterior learner that leverages a lifted policy space for computational efficiency, achieving horizon-free approximation and an $O(H)$ estimation rate. Our results identify divergence choice as the source of horizon dependence in approximation and establish a genuine computational-statistical tradeoff for estimation, motivating new algorithmic designs."},"pdf":{"value":"/pdf/5c86c0cac631fc880f432b6b71ca58607566228e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nxu2025autoregressive,\\ntitle={Autoregressive Learning under Joint {KL} Analysis: Horizon-Free Approximation and Computational-Statistical Tradeoffs},\\nauthor={Yunbei Xu and Yuzhe Yuan and Ruohan Zhan},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=tQgfqyT6If}\\n}"},"paperhash":{"value":"xu|autoregressive_learning_under_joint_kl_analysis_horizonfree_approximation_and_computationalstatistical_tradeoffs"}},"id":"tQgfqyT6If","forum":"tQgfqyT6If","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission213/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission213/Authors"],"number":213,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission213/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757143111648,"cdate":1757143111648,"tmdate":1764510130541,"mdate":1764510130541,"pdate":1764306364513,"odate":1764510130524,"version":2},{"content":{"title":{"value":"Finite-Time Minimax Bounds in Queueing Control"},"authors":{"value":["Yujie Liu","Vincent Y. F. Tan","Yunbei Xu"]},"authorids":{"value":["~Yujie_Liu8","~Vincent_Tan1","~Yunbei_Xu1"]},"keywords":{"value":["queueing control","finite-horizon analysis","minimax bounds","Lyapunov drift methods"]},"abstract":{"value":"We establish the first finite-time minimax lower bounds—and derive new policies that achieve them—for the total queue length in scheduling problems over stochastic processing networks with adversarial arrivals. Prior analyses of MaxWeight guarantee only stability and asymptotic optimality in heavy traffic; we prove that, at finite horizons, MaxWeight can incur strictly larger backlog by problem -dependent factors which we identify. Our main innovations are 1) a minimax framework that pinpoints the precise problem parameters governing any policy’s finite-time performance; 2) a minimax lower bound on total queue length; 3) fundamental limitation of MaxWeight that it is suboptimal in finite time; and 4) a new scheduling rule that minimizes the full Lyapunov drift—including its second-order term—thereby matching the lower bound under certain conditions, up to universal constants. These findings reveal a fundamental limitation on “drift-only” methods and points the way toward principled, non-asymptotic optimality in queueing control."},"pdf":{"value":"/pdf/9021acef807ed0794f99eb23232f7b3374d8a01c.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliu2025finitetime,\\ntitle={Finite-Time Minimax Bounds in Queueing Control},\\nauthor={Yujie Liu and Vincent Y. F. Tan and Yunbei Xu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=SKTSzSI933}\\n}"},"paperhash":{"value":"liu|finitetime_minimax_bounds_in_queueing_control"}},"id":"SKTSzSI933","forum":"SKTSzSI933","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission212/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission212/Authors"],"number":212,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission212/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757142973349,"cdate":1757142973349,"tmdate":1764510130392,"mdate":1764510130392,"pdate":1764306364512,"odate":1764510130371,"version":2},{"content":{"title":{"value":"Prediction-Driven Staffing for Emergency Departments: What to Predict and How to Predict"},"authors":{"value":["Lin Feng","Jing Dong"]},"authorids":{"value":["~Lin_Feng4","~Jing_Dong2"]},"keywords":{"value":["nurse staffing","queueing models","machine learning","prediction-informed decision making","healthcare operations"]},"abstract":{"value":"We conduct a comparative study of prediction-driven strategies for staffing hospital emergency departments (ED). We evaluate three approaches: (i) a machine learning (ML) approach that relies on census forecasts and applies a straightforward patient-to-nurse ratio to determine staffing; (ii) a staffing-level informed machine learning (SIML) approach that models the mapping from staffing levels to congestion outcomes and chooses the staffing plan that minimizes the associated cost; and (iii) a queueing-informed (QI) approach that leverages a calibrated queueing model to guide staffing decisions.\\n\\nWe evaluate the three approaches using real ED arrival patterns. ML, which overlooks the endogeneity of queueing dynamics, can suffer from varying degrees of delayed feedback. SIML performs well when training and evaluation conditions align, but can be sensitive to distribution shifts. QI typically achieves the best results under correct model specification, though it is vulnerable to misspecification, for which we provide a diagnostic tool. Finally, we offer practical guidance to help hospitals select the most suitable approach given their data and modeling expertise."},"pdf":{"value":"/pdf/901237ddc595e918b94d30605d42203ebe526160.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nfeng2025predictiondriven,\\ntitle={Prediction-Driven Staffing for Emergency Departments: What to Predict and How to Predict},\\nauthor={Lin Feng and Jing Dong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=oQCKEY54nX}\\n}"},"paperhash":{"value":"feng|predictiondriven_staffing_for_emergency_departments_what_to_predict_and_how_to_predict"}},"id":"oQCKEY54nX","forum":"oQCKEY54nX","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission211/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission211/Authors"],"number":211,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission211/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757142944148,"cdate":1757142944148,"tmdate":1764510130386,"mdate":1764510130386,"pdate":1764306364454,"odate":1764510130368,"version":2},{"content":{"title":{"value":"Fast Variability Approximation: Speeding up Divergence-Based Distributionally Robust Optimization via Directed Perturbation"},"authors":{"value":["Henry Lam","Mohamed Lakhnichi"]},"authorids":{"value":["~Henry_Lam1","~Mohamed_Lakhnichi1"]},"keywords":{"value":["Distributionally Robust Optimization","Empirical Optimization","Approximation Framework","Computational Efficiency","Hyperparameter Tuning"]},"abstract":{"value":"Distributionally Robust Optimization (DRO) has become a popular paradigm for decision-making under uncertainty, especially when the uncertainty raises from the underlying distributions in stochastic problems. While DRO has been known to enjoy a range of robustness and statistical advantages, it also pays the cost of additional computational overheads. Moreover, this cost can amplify extensively in the phase of hyperparameter tuning. We show that, in the case of $\\\\phi$-divergence uncertainty set, simply perturbing an empirical optimizer (i.e., solution from sample average approximation) in a statistically guided fashion achieves almost the same generalization effect as DRO. Importantly, this perturbation avoids the expensive overheads of DRO as long as the problem is smooth enough, which allows suitable gradient extraction via direct computation or resampling-based methods."},"pdf":{"value":"/pdf/79c84325b6b0d75f517c47d339f75eea983a4fed.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlam2025fast,\\ntitle={Fast Variability Approximation: Speeding up Divergence-Based Distributionally Robust Optimization via Directed Perturbation},\\nauthor={Henry Lam and Mohamed Lakhnichi},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=4QHSIdhJNW}\\n}"},"paperhash":{"value":"lam|fast_variability_approximation_speeding_up_divergencebased_distributionally_robust_optimization_via_directed_perturbation"}},"id":"4QHSIdhJNW","forum":"4QHSIdhJNW","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission210/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission210/Authors"],"number":210,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission210/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757142692517,"cdate":1757142692517,"tmdate":1764510130375,"mdate":1764510130375,"pdate":1764306364338,"odate":1764510130354,"version":2},{"content":{"title":{"value":"Accelerating Diffusion via Compressed Sensing: Applications to Imaging and Finance"},"authors":{"value":["Zhengyi Guo","Jiatu Li","Wenpin Tang","David Yao"]},"authorids":{"value":["zg2525@columbia.edu","~Jiatu_Li1","~Wenpin_Tang1","~David_Yao1"]},"keywords":{"value":["complexity","compressed sensing","diffusion models","inference time","signal recovery","sparsity"]},"TLDR":{"value":"Compressed-Space Diffusion Modeling (CSDM) samples in a low-dimensional sketch and reconstructs via sparse recovery, with theory guiding optimal dimension, achieving major speedups on OCTMNIST and finance while preserving decision-relevant fidelity."},"abstract":{"value":"We integrate compressed sensing with diffusion models to accelerate synthetic data generation. Our pipeline, \\\\emph{Compressed-Space Diffusion Modeling (CSDM)}, first projects data from the ambient space to a latent space and trains a diffusion model in that space, then apply a compressed sensing algorithm to the latent samples to decode them back to the original space, with the goal of improving the efficiency of both training and inference. Under certain sparsity assumptions on the data, our approach achieves provably faster convergence by combining diffusion inference with sparse recovery, and it sheds light on the choice of the latent-space dimension. To illustrate the effectiveness of this approach, we present experiments on medical imaging data and financial time series for stress testing."},"pdf":{"value":"/pdf/53ca8858786436dbbf3f910b11a8bbc435db470a.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nguo2025accelerating,\\ntitle={Accelerating Diffusion via Compressed Sensing: Applications to Imaging and Finance},\\nauthor={Zhengyi Guo and Jiatu Li and Wenpin Tang and David Yao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ToUWDGP0st}\\n}"},"paperhash":{"value":"guo|accelerating_diffusion_via_compressed_sensing_applications_to_imaging_and_finance"}},"id":"ToUWDGP0st","forum":"ToUWDGP0st","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission209/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission209/Authors"],"number":209,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission209/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757141673383,"cdate":1757141673383,"tmdate":1764510130283,"mdate":1764510130283,"pdate":1764306364235,"odate":1764510130262,"version":2},{"content":{"title":{"value":"Measuring Informativeness Gap of (Mis)Calibrated Predictors"},"authors":{"value":["Yiding Feng","Wei Tang"]},"authorids":{"value":["~Yiding_Feng1","~Wei_Tang1"]},"keywords":{"value":["calibration","decision-making"]},"abstract":{"value":"In many applications, decision-makers must choose between multiple predictive\\nmodels that may all be miscalibrated. Which model (i.e., predictor) is more\\n“useful” in downstream decision tasks? To answer this, our first contribution\\nintroduces the notion of the informativeness gap between any two predictors,\\ndefined as the maximum normalized payoff advantage one predictor offers over the\\nother across all decision-making tasks. Our framework strictly generalizes several\\nexisting notions: it subsumes U-Calibration (Kleinberg et al., 2023) and Calibration\\nDecision Loss (Hu and Wu, 2024), which compare a miscalibrated predictor to its\\ncalibrated counterpart, and it recovers Blackwell informativeness (Blackwell, 1951,\\n1953) as a special case when both predictors are perfectly calibrated. Our second\\ncontribution is a dual characterization of the informativeness gap, which gives rise\\nto a natural informativeness measure that can be viewed as a relaxed variant of the\\nearth mover’s distance (EMD) between two prediction distributions. We show that\\nthis measure satisfies natural desiderata: it is complete and sound, and it can be\\nestimated sample-efficiently in the prediction-only access setting. Along the way,\\nwe also obtain novel combinatorial structural results when applying this measure\\nto perfectly calibrated predictors"},"pdf":{"value":"/pdf/1ef67233a3c12b09629a836afeb13db399de08b2.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nfeng2025measuring,\\ntitle={Measuring Informativeness Gap of (Mis)Calibrated Predictors},\\nauthor={Yiding Feng and Wei Tang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ohExiFlNme}\\n}"},"paperhash":{"value":"feng|measuring_informativeness_gap_of_miscalibrated_predictors"}},"id":"ohExiFlNme","forum":"ohExiFlNme","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission206/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission206/Authors"],"number":206,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission206/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757139530871,"cdate":1757139530871,"tmdate":1764510130197,"mdate":1764510130197,"pdate":1764306364054,"odate":1764510130168,"version":2},{"content":{"title":{"value":"A Sharp Comparison of Prescriptive Analytic Frameworks for The Big Data Newsvendor Problem"},"authors":{"value":["Zhen Qiao","Karthyek Murthy"]},"authorids":{"value":["~Zhen_Qiao2","~Karthyek_Murthy1"]},"keywords":{"value":["Prescriptive analytics","Big data Newsvendor","Regret","Integrated-Learning-Optimization","Decision Rule Optimization","CGMT"]},"abstract":{"value":"We study the feature-based newsvendor problem in high dimensions and provide sharp regret characterizations for three widely used prescriptive analytics approaches: the conventional Estimate-Then-Optimize (ETO), and the more recent end-to-end methods of Integrated-Learning-Optimization (ILO) & Direct Policy Optimization (DPO). Under well-specified linear demand model, we derive the regret results using convex Gaussian minmax theorem. Numerical explorations enabled by the results offer robust evidence of the superiority of ETO persisting even in high-dimensional regimes. Further, we highlight substantial performance gains attainable over all 3 methods by utilizing downstream optimization only in\\nthe model selection stage, instead of integrating it directly in training."},"pdf":{"value":"/pdf/4536966143f62c2f6585dac7682d9aa0cc851fb6.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nqiao2025a,\\ntitle={A Sharp Comparison of Prescriptive Analytic Frameworks for The Big Data Newsvendor Problem},\\nauthor={Zhen Qiao and Karthyek Murthy},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=AXfi8qUDE1}\\n}"},"paperhash":{"value":"qiao|a_sharp_comparison_of_prescriptive_analytic_frameworks_for_the_big_data_newsvendor_problem"}},"id":"AXfi8qUDE1","forum":"AXfi8qUDE1","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission203/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission203/Authors"],"number":203,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission203/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757139200275,"cdate":1757139200275,"tmdate":1764510129814,"mdate":1764510129814,"pdate":1764306363729,"odate":1764510129790,"version":2},{"content":{"title":{"value":"Scalable First-order Method for Certifying Optimal k-Sparse GLMs"},"authors":{"value":["Jiachang Liu","Soroosh Shafiee","Andrea Lodi"]},"authorids":{"value":["~Jiachang_Liu1","~Soroosh_Shafiee1","~Andrea_Lodi1"]},"keywords":{"value":["generalized linear models","sparse learning","proximal method","mixed-integer programming"]},"abstract":{"value":"This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\\\\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems. To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework. Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program. Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity. Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems."},"pdf":{"value":"/pdf/90acd7858b6d507b4aa3c1ab66e52cfd5e177255.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliu2025scalable,\\ntitle={Scalable First-order Method for Certifying Optimal k-Sparse {GLM}s},\\nauthor={Jiachang Liu and Soroosh Shafiee and Andrea Lodi},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=HUkPaXsB3s}\\n}"},"paperhash":{"value":"liu|scalable_firstorder_method_for_certifying_optimal_ksparse_glms"}},"id":"HUkPaXsB3s","forum":"HUkPaXsB3s","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission201/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission201/Authors"],"number":201,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission201/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757137201153,"cdate":1757137201153,"tmdate":1764510129684,"mdate":1764510129684,"pdate":1764306363516,"odate":1764510129666,"version":2},{"content":{"title":{"value":"Distributionally Robust Optimization via Iterative Algorithms in Continuous Probability Spaces"},"authors":{"value":["Linglingzhi Zhu","Yunqin Zhu","Yao Xie"]},"authorids":{"value":["~Linglingzhi_Zhu1","~Yunqin_Zhu1","~Yao_Xie2"]},"keywords":{"value":["Infinite-Dimensional Optimization; Distributionally Robust Optimization"]},"TLDR":{"value":"The minimax theoretical perspective for addressing distributionally robust optimization."},"abstract":{"value":"We consider a minimax problem motivated by distributionally robust optimization (DRO) when the worst-case distribution is continuous, leading to significant computational challenges due to the infinite-dimensional nature of the optimization problem. Leveraging Brenier’s theorem, we represent the worst-case distribution as a transport map of a continuous reference measure and reformulate the regularized discrepancy-based DRO as a minimax problem in Wasserstein space. We further propose an algorithmic framework with global convergence guarantees and complexity bounds for obtaining approximate stationary points. Under this continuous formulation, the proposed algorithms overcome the scalability, generalization, and worst-case inference limitations of discrete DRO approaches. Numerical results with neural network-based transport maps demonstrate that the proposed method enables both stable training of robust classifiers and effective worst-case inference for classification tasks."},"pdf":{"value":"/pdf/c49a483fe16b6574e36fa7267ffd51af63634902.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhu2025distributionally,\\ntitle={Distributionally Robust Optimization via Iterative Algorithms in Continuous Probability Spaces},\\nauthor={Linglingzhi Zhu and Yunqin Zhu and Yao Xie},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=xDRGZLcuN8}\\n}"},"paperhash":{"value":"zhu|distributionally_robust_optimization_via_iterative_algorithms_in_continuous_probability_spaces"}},"id":"xDRGZLcuN8","forum":"xDRGZLcuN8","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission200/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission200/Authors"],"number":200,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission200/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757136772045,"cdate":1757136772045,"tmdate":1764510129711,"mdate":1764510129711,"pdate":1764306363502,"odate":1764510129655,"version":2},{"content":{"title":{"value":"LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection"},"authors":{"value":["Adam Jovine","Tinghan Ye","David Shmoys","Peter I. Frazier"]},"authorids":{"value":["~Adam_Jovine1","~Tinghan_Ye1","~David_Shmoys1","~Peter_I._Frazier1"]},"keywords":{"value":["LLM","Preference Learning","Multi Objective Optimization"]},"abstract":{"value":"Multi-objective optimization often produces large sets of Pareto-optimal solutions, creating a bottleneck for human experts who must select the best option. This difficulty is compounded by the fact that expert preferences are often complex and hard to formalize. To address this, we introduce LISTEN, a framework that leverages a large language model (LLM) as a zero-shot preference oracle, guided only by an expert's high-level priorities in natural language. \\nTo operate within LLM constraints like context windows and inference costs, we propose two iterative algorithms: LISTEN-U, which uses the LLM to refine a parametric utility function, and LISTEN-T, a non-parametric method that performs tournament-style selections over small batches of solutions."},"pdf":{"value":"/pdf/ddcd4d7c5df48f119b6478e3b7fa1e931b39ccf2.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njovine2025listen,\\ntitle={{LISTEN} to Your Preferences: An {LLM} Framework for Multi-Objective Selection},\\nauthor={Adam Jovine and Tinghan Ye and David Shmoys and Peter I. Frazier},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=xtTpyGXcB0}\\n}"},"paperhash":{"value":"jovine|listen_to_your_preferences_an_llm_framework_for_multiobjective_selection"}},"id":"xtTpyGXcB0","forum":"xtTpyGXcB0","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission199/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission199/Authors"],"number":199,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission199/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757135203693,"cdate":1757135203693,"tmdate":1764510129705,"mdate":1764510129705,"pdate":1764306363485,"odate":1764510129631,"version":2},{"content":{"title":{"value":"Data to Dose: Efficient Synthetic Data Generation with Expert Guidance for Personalized Dosing"},"authors":{"value":["H. Satyam Verma","Holly Wiberg","Shixiang Zhu","Sridhar Tayur"]},"authorids":{"value":["~H._Satyam_Verma1","~Holly_Wiberg1","~Shixiang_Zhu1","~Sridhar_Tayur1"]},"keywords":{"value":["Generative Modeling","Bayesian Optimization","Personalized Dosing","Expert-in-the-loop","Preference learning"]},"TLDR":{"value":"We introduce GenEx, a framework that combines preference-based Bayesian optimization with expert-gated generative models to efficiently learn personalized dosing under data scarcity."},"abstract":{"value":"Effective personalized dosing is constrained by limited data, noisy outcomes, and heterogeneous patient profiles. We introduce GenEx, a hybrid framework that couples preference-based Bayesian optimization with a generative model fine-tuned via expert feedback. Expert pairwise rankings update the Gaussian Process (GP) surrogate and, via an expert–generator agreement test, gate uncertainty-guided synthetic data injection at the GP’s highest-variance doses. We provide guarantees of sublinear expected regret under decaying generator bias and validate them in numerical studies. We find that GenEx converges faster and improves decision quality over preference-only and synthetic-only baselines, enabling safer and more effective individualized treatment."},"pdf":{"value":"/pdf/b50a2e2daf36646c23d5a5a79251280c69540cc5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nverma2025data,\\ntitle={Data to Dose: Efficient Synthetic Data Generation with Expert Guidance for Personalized Dosing},\\nauthor={H. Satyam Verma and Holly Wiberg and Shixiang Zhu and Sridhar Tayur},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=syVuT5gRuy}\\n}"},"paperhash":{"value":"verma|data_to_dose_efficient_synthetic_data_generation_with_expert_guidance_for_personalized_dosing"}},"id":"syVuT5gRuy","forum":"syVuT5gRuy","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission197/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission197/Authors"],"number":197,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission197/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757133899465,"cdate":1757133899465,"tmdate":1764510129540,"mdate":1764510129540,"pdate":1764306363182,"odate":1764510129516,"version":2},{"content":{"title":{"value":"Contextual Optimization Under Model Misspecification: A Tractable and Generalizable Approach"},"authors":{"value":["Omar Bennouna","Jiawei Zhang","Saurabh Amin","Asuman E. Ozdaglar"]},"authorids":{"value":["~Omar_Bennouna1","~Jiawei_Zhang6","~Saurabh_Amin1","~Asuman_E._Ozdaglar1"]},"keywords":{"value":["Contextual optimization","Constrained Optimization","Linear Programming"]},"abstract":{"value":"Contextual optimization problems arise in decision-making applications where historical data and contextual features are used to learn predictive models that guide optimal decisions. Practical applications often face model misspecification from incomplete knowledge of the data-generating process, leading to suboptimal decisions. Existing methods mainly address well-specified models, leaving a gap in the literature in handling misspecification. We propose a consistent, tractable and generalizable Integrated Learning and Optimization (ILO) framework that successfully addresses this gap in the literature."},"pdf":{"value":"/pdf/7a28f08d966c486d1306486bc21be588addeb142.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbennouna2025contextual,\\ntitle={Contextual Optimization Under Model Misspecification: A Tractable and Generalizable Approach},\\nauthor={Omar Bennouna and Jiawei Zhang and Saurabh Amin and Asuman E. Ozdaglar},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=gQ8cGJ8R8B}\\n}"},"paperhash":{"value":"bennouna|contextual_optimization_under_model_misspecification_a_tractable_and_generalizable_approach"}},"id":"gQ8cGJ8R8B","forum":"gQ8cGJ8R8B","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission195/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission195/Authors"],"number":195,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission195/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757133600781,"cdate":1757133600781,"tmdate":1764510129499,"mdate":1764510129499,"pdate":1764306363181,"odate":1764510129485,"version":2},{"content":{"title":{"value":"Decision-Focused Sequential Experimental Design: A Directional Uncertainty-Guided Approach"},"authors":{"value":["Beichen Wan","Mo Liu","Paul Grigas","Zuo-Jun Shen"]},"authorids":{"value":["bcwan@unc.edu","~Mo_Liu1","~Paul_Grigas1","~Zuo-Jun_Shen1"]},"keywords":{"value":["sequential experimental design","decision-focused learning","smart predict-then-optimize","directional uncertainty"]},"TLDR":{"value":"We propose a new criteria for sequential experimental design in the setting of decision-focused learning with strong theoretical guarantees."},"abstract":{"value":"Classical experimental design has traditionally focused on constructing design variables that facilitate the selection of models with high predictive accuracy. In decision-focused learning, however, the model that achieves the lowest prediction error may not coincide with the one that induces the best downstream decision. Motivated by this misalignment, we investigate appropriate criteria for sequential experimental design in decision-focused settings. Specifically, we consider a sequential data acquisition problem in which a learner adaptively selects samples to label, or equivalently, treatment responses to observe. Existing experimental design methods are inherently decision-blind: they aim to reduce predictive uncertainty, even though reductions in predictive error need not translate into improvements in decision quality. To bridge this gap, we introduce a *directional uncertainty* criterion that aligns predictive uncertainty with the structure of the downstream decision-making problem, in contrast to naïve decision-blind uncertainty quantification methods. We show that this transformation admits strong theoretical guarantees and achieves reduced sample complexity relative to decision-blind design."},"pdf":{"value":"/pdf/7113fb0f2f34d09f62596da76961fef93644d3a8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwan2025decisionfocused,\\ntitle={Decision-Focused Sequential Experimental Design: A Directional Uncertainty-Guided Approach},\\nauthor={Beichen Wan and Mo Liu and Paul Grigas and Zuo-Jun Shen},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=d0YZKGB649}\\n}"},"paperhash":{"value":"wan|decisionfocused_sequential_experimental_design_a_directional_uncertaintyguided_approach"}},"id":"d0YZKGB649","forum":"d0YZKGB649","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission194/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission194/Authors"],"number":194,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission194/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757133447835,"cdate":1757133447835,"tmdate":1764510129483,"mdate":1764510129483,"pdate":1764306363101,"odate":1764510129467,"version":2},{"content":{"title":{"value":"Model-Free Assessment of Simulator Fidelity via Quantile Curves"},"authors":{"value":["Yu-Shiou Willy Lin","Garud Iyengar","Kaizheng Wang"]},"authorids":{"value":["~Yu-Shiou_Willy_Lin1","~Garud_Iyengar1","~Kaizheng_Wang1"]},"keywords":{"value":["Simulation","Quantile function estimation","human-AI alignment","distribution-free"]},"TLDR":{"value":"We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulator outputs and the ground-truth distributions."},"abstract":{"value":"Simulation is now pervasive, arising from manufacturing to LLM-driven applications in research, education, and consumer surveys. Yet, fully characterizing the discrepancy between simulators and ground truth remains challenging. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth distributions. The approach does not impose any modeling assumptions on the simulator and it applies broadly across many parameter families: from Bernoulli and multinomial to continuous, vector-valued settings. The resulting quantile curve supports risk-aware summaries (e.g., VaR/CVaR) and comparison of simulators or prompts performance. We illustrate our framework through an application assessing LLM simulation fidelity on the OpinionQA dataset, augmented with simulations spanning seven LLMs."},"pdf":{"value":"/pdf/0c31721be535f6a6bd1f1a1479b882aa387921a9.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlin2025modelfree,\\ntitle={Model-Free Assessment of Simulator Fidelity via Quantile Curves},\\nauthor={Yu-Shiou Willy Lin and Garud Iyengar and Kaizheng Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=CTGNVLAqgQ}\\n}"},"paperhash":{"value":"lin|modelfree_assessment_of_simulator_fidelity_via_quantile_curves"}},"id":"CTGNVLAqgQ","forum":"CTGNVLAqgQ","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission193/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission193/Authors"],"number":193,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission193/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757133395603,"cdate":1757133395603,"tmdate":1764510129412,"mdate":1764510129412,"pdate":1764306363033,"odate":1764510129387,"version":2},{"content":{"title":{"value":"Offline Dynamic Pricing under Covariate Shift and Local Differential Privacy via Twofold Pessimism"},"authors":{"value":["Jongmin Mun","Xiaocong Xu","Yingying Fan"]},"authorids":{"value":["~Jongmin_Mun1","~Xiaocong_Xu2","~Yingying_Fan1"]},"keywords":{"value":["covariate shift","local diffential privacy","transfer learning","offline dynamic pricing","predict-then-optimize"]},"abstract":{"value":"We study offline policy learning under market shift and privacy protection. Motivated by high-stakes pricing for new products,  where price experimentation is infeasible, we leverage historical transaction data from heterogeneous, privacy-protected sources.\\nWe model heterogeneity via a covariate shift assumption, where the relationship between price, features, and revenue remains invariant, and privacy through local differential privacy (LDP), where each data point is perturbed before use. Viewing both as distributional shifts, we design a policy learning algorithm grounded in the pessimism principle of offline reinforcement learning.\\nWithout privacy, our predict-then-optimize approach constructs a pessimistic revenue predictor   and optimizes it to set prices, achieving minimax-optimal decision error. Under LDP, we apply the Laplace mechanism and adapt the pessimistic revenue predictor to account for additional uncertainty introduced by privacy noise. The resulting doubly pessimistic objective is then optimized to determine the final pricing policy."},"pdf":{"value":"/pdf/9692eadbf213adca9b49076cd8ee8feee732cddf.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmun2025offline,\\ntitle={Offline Dynamic Pricing under Covariate Shift and Local Differential Privacy via Twofold Pessimism},\\nauthor={Jongmin Mun and Xiaocong Xu and Yingying Fan},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ZL748l6oQG}\\n}"},"paperhash":{"value":"mun|offline_dynamic_pricing_under_covariate_shift_and_local_differential_privacy_via_twofold_pessimism"}},"id":"ZL748l6oQG","forum":"ZL748l6oQG","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission191/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission191/Authors"],"number":191,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission191/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757132456600,"cdate":1757132456600,"tmdate":1764510129363,"mdate":1764510129363,"pdate":1764306362983,"odate":1764510129294,"version":2},{"content":{"title":{"value":"Lyapunov-Based Sample Complexity Analysis for Weakly-Coupled MDPs"},"authors":{"value":["Tianhao Wu","Matthew Zurek","Yudong Chen","Weina Wang","Qiaomin Xie"]},"authorids":{"value":["~Tianhao_Wu4","~Matthew_Zurek1","~Yudong_Chen1","~Weina_Wang1","~Qiaomin_Xie1"]},"keywords":{"value":["Weakly-Coupled MDPs; Sample Complexity; Average Reward; Reinforcement Learning"]},"TLDR":{"value":"We study learning in average-reward weakly coupled Markov decision processes (WCMDPs) with heterogeneous arms."},"abstract":{"value":"We study learning in average-reward weakly coupled Markov decision processes (WCMDPs) with heterogeneous arms. Naive approaches suffer exponential computation and sample complexity in the number of subsystems. We study a plug-in approach built on an efficient planning algorithm, which attains the first finite-sample (PAC) optimality-gap guarantees with polynomial sample complexity. This result is established under a new framework built on a Lyapunov analysis of a reference policy combined with a Lyapunov drift transfer technique, which can be viewed as a generalization of the classical simulation lemma."},"pdf":{"value":"/pdf/739f54c3cae5f75ea69f7e3b43485f72fb9de28a.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwu2025lyapunovbased,\\ntitle={Lyapunov-Based Sample Complexity Analysis for Weakly-Coupled {MDP}s},\\nauthor={Tianhao Wu and Matthew Zurek and Yudong Chen and Weina Wang and Qiaomin Xie},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=npV2sxCM7P}\\n}"},"paperhash":{"value":"wu|lyapunovbased_sample_complexity_analysis_for_weaklycoupled_mdps"}},"id":"npV2sxCM7P","forum":"npV2sxCM7P","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission189/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission189/Authors"],"number":189,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission189/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757131292278,"cdate":1757131292278,"tmdate":1764510129274,"mdate":1764510129274,"pdate":1764306362880,"odate":1764510129256,"version":2},{"content":{"title":{"value":"Offline Contextual Bandits with Covariate Shift"},"authors":{"value":["Yingying Fan","Yuxuan Han","Jinchi Lv","Xiaocong Xu","Zhengyuan Zhou"]},"authorids":{"value":["~Yingying_Fan1","~Yuxuan_Han1","~Jinchi_Lv1","~Xiaocong_Xu2","~Zhengyuan_Zhou2"]},"keywords":{"value":["bandit learning; covarite shift; distributionally robust learning;"]},"abstract":{"value":"Offline policy learning aims to optimize decision-making policies using historical data and plays a central role in many real-world applications, such as personalized advertising, medical treatment recommendation, and pricing decisions. A major challenge in this setting is the potential mismatch between the training environment---where the data were collected---and the test environment---where the learned policy is evaluated. This challenge has motivated extensive research on distributionally robust methods, which aim to maintain performance under worst-case distribution shifts. However, such approaches can be overly conservative when the environment changes in more structured ways. In this paper, we focus on the offline learning setting where the only difference between the training and test environments lies in the distribution of the context variables. Adopting the concept of transfer exponents from the transfer learning literature to model such covariate shift, we establish minimax-optimal sample complexity bounds for offline decision-making with general nonparametric reward functions. We further show that a pessimism-based algorithm attains these optimal rates."},"pdf":{"value":"/pdf/f1c391d87ccfd2e1d7aa44786f48851601266c72.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nfan2025offline,\\ntitle={Offline Contextual Bandits with Covariate Shift},\\nauthor={Yingying Fan and Yuxuan Han and Jinchi Lv and Xiaocong Xu and Zhengyuan Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=098EJpV1WN}\\n}"},"paperhash":{"value":"fan|offline_contextual_bandits_with_covariate_shift"}},"id":"098EJpV1WN","forum":"098EJpV1WN","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission186/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission186/Authors"],"number":186,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission186/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757131154863,"cdate":1757131154863,"tmdate":1764510129150,"mdate":1764510129150,"pdate":1764306362802,"odate":1764510129120,"version":2},{"content":{"title":{"value":"Dynamically Augmented CVaR for MDPs and Uncertainty Quantifications for Robust MDPs Characterizing Risk"},"authors":{"value":["Eugene A. Feinberg","Rui Ding"]},"authorids":{"value":["~Eugene_A._Feinberg1","rrd051488@gmail.com"]},"keywords":{"value":["Conditional Value-at-Risk","Robust Markov Decision Process","sequential optimization","optimal policy","finite and infinite horizon"]},"TLDR":{"value":"The paper introduces dynamically augmented CVaR risk measure for Markov Decision Processes having advantages compared to other known definitions of CVaR for MDPs"},"abstract":{"value":"CVaR optimization is an important topic, and there are additional complications for defining and optimizing CVaR for sequential decision-making.  This paper investigates the relation between CVaR optimization for an MDP with total discounted costs and a specially constructed Robust MDPs (RMDPs).  This RMDP was introduced to the literature 10 years ago. It was proposed for efficient calculations of optimal CVaR values and is broadly used for this purpose.  About two years ago it was understood that these calculations lead to lower bounds of the minimal static CVaR.  This paper provides additional links between static CVaR and the RMDP.  It shows that the optimal value of  static CVaR is another characteristic for the RMDP rather than its value.  Based on this understanding, this paper introduces the Dynamically augmented CVaR (DCVaR) risk measure, which is more natural than  static CVaR.  Unlike static CVaR, DCVaR does not sufferer from time inconsistency.  In addition, DCVaR’s  value function is equal to the value function of the RMDP, and it can be efficiently computed by value iterations. Optimal policies minimizing DCVaR exist, and they can be computed efficiently by the algorithm proposed three years ago.  DCVaR has certain similarities with nested CVaR, and DCVaR can be viewed as a flexible version of nested CVaR in which tail risk levels can be adjusted depending on achieved gains or losses."},"pdf":{"value":"/pdf/59f5903c7df07648ed6fa5e7ed0874bb60bab91e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nfeinberg2025dynamically,\\ntitle={Dynamically Augmented {CV}aR for {MDP}s and Uncertainty Quantifications for Robust {MDP}s Characterizing Risk},\\nauthor={Eugene A. Feinberg and Rui Ding},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Ny0XcgaUJn}\\n}"},"paperhash":{"value":"feinberg|dynamically_augmented_cvar_for_mdps_and_uncertainty_quantifications_for_robust_mdps_characterizing_risk"}},"id":"Ny0XcgaUJn","forum":"Ny0XcgaUJn","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission185/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission185/Authors"],"number":185,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission185/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757130908022,"cdate":1757130908022,"tmdate":1764510129136,"mdate":1764510129136,"pdate":1764306362742,"odate":1764510129048,"version":2},{"content":{"title":{"value":"Conformal Tail Risk Control for Large Language Model Alignment"},"authors":{"value":["Catherine Chen","Jingyan Shen","Zhun Deng","Lihua Lei"]},"authorids":{"value":["~Catherine_Chen5","~Jingyan_Shen1","~Zhun_Deng1","~Lihua_Lei2"]},"keywords":{"value":["large language models","conformal risk control","tail risk","human-machine misalignment","calibration","l-statistics"]},"TLDR":{"value":"We develop a lightweight calibration method that leverages conformal risk control and L-statistics to achieve guaranteed tail risk control for any given LLM under no assumptions on the statistical properties and the alignment quality of the LLM."},"abstract":{"value":"Recent developments in large language models (LLMs) have led to their widespread usage for various tasks. The prevalence of LLMs in society implores the assurance on the reliability of their performance. In particular, risk-sensitive applications demand meticulous attention to unexpectedly poor outcomes, i.e., tail events, for instance, toxic answers, humiliating language, and offensive outputs. Due to the costly nature of acquiring human annotations, general-purpose scoring models have been created to automate the process of quantifying these tail events. This phenomenon introduces potential human-machine misalignment between the respective scoring mechanisms. In this work, we present a lightweight calibration framework for blackbox models that ensures the alignment of humans and machines with provable guarantees. Our framework provides a rigorous approach to controlling any distortion risk measure that is characterized by a weighted average of quantiles of the loss incurred by the LLM with high confidence. The theoretical foundation of our method relies on the connection between conformal risk control and a traditional family of statistics, i.e., L-statistics. To demonstrate the utility of our framework, we conduct comprehensive experiments that address the issue of human-machine misalignment."},"pdf":{"value":"/pdf/ffbcf33684b2554840c335b9c91f41fbb47f00f2.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nchen2025conformal,\\ntitle={Conformal Tail Risk Control for Large Language Model Alignment},\\nauthor={Catherine Chen and Jingyan Shen and Zhun Deng and Lihua Lei},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=MMDVf8RsHz}\\n}"},"paperhash":{"value":"chen|conformal_tail_risk_control_for_large_language_model_alignment"}},"id":"MMDVf8RsHz","forum":"MMDVf8RsHz","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission183/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission183/Authors"],"number":183,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission183/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757129513774,"cdate":1757129513774,"tmdate":1764510129039,"mdate":1764510129039,"pdate":1764306362602,"odate":1764510129015,"version":2},{"content":{"title":{"value":"Near-Optimal Real-Time Personalization with Simple Transformers"},"authors":{"value":["Lin An","Andrew A Li","Vaisnavi Nemala","Gabriel Visotsky"]},"authorids":{"value":["~Lin_An3","~Andrew_A_Li1","~Vaisnavi_Nemala1","~Gabriel_Visotsky1"]},"keywords":{"value":["Personalization","Transformers","Online Optimization"]},"abstract":{"value":"Real-time personalization by and large relies on embedding-based models, which enable fast optimization via nearest-neighbors, but fail to capture complex user behavior. Transformer-based models successfully capture such behavior, but are provably hard to optimize. We study simple transformers, i.e. those with a single self-attention layer, and show they still capture rich user behavior despite their simplicity. We then develop a sub-linear time algorithm with near-optimal performance. On large-scale Spotify and Trivago datasets, simple transformers match the accuracy of deeper models while enabling real-time recommendations, improving objective values by over 20% against natural benchmarks."},"pdf":{"value":"/pdf/1561947a548a97e9d7c6456714e0edd8206857ae.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nan2025nearoptimal,\\ntitle={Near-Optimal Real-Time Personalization with Simple Transformers},\\nauthor={Lin An and Andrew A Li and Vaisnavi Nemala and Gabriel Visotsky},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Ca3UpdJDHz}\\n}"},"paperhash":{"value":"an|nearoptimal_realtime_personalization_with_simple_transformers"}},"id":"Ca3UpdJDHz","forum":"Ca3UpdJDHz","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission182/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission182/Authors"],"number":182,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission182/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757129058646,"cdate":1757129058646,"tmdate":1764510128963,"mdate":1764510128963,"pdate":1764306362536,"odate":1764510128949,"version":2},{"content":{"title":{"value":"Chance-constrained Flow Matching for High-Fidelity Constraint-aware Generation"},"authors":{"value":["Jinhao Liang","Sandeep Madireddy","Ferdinando Fioretto"]},"authorids":{"value":["~Jinhao_Liang1","~Sandeep_Madireddy1","~Ferdinando_Fioretto1"]},"keywords":{"value":["flow matching","chance constraints","generative modeling"]},"abstract":{"value":"Generative models excel at synthesizing high-fidelity samples from complex data distributions, but they often violate hard constraints arising from physical laws or task specifications. A common remedy is to project intermediate samples onto the feasible set; however, repeated projection can distort the learned distribution and induce a mismatch with the data manifold. Thus, recent multi-stage procedures attempt to defer projection to \\"clean\\" samples during sampling, but they increase algorithmic complexity and accumulate errors across steps.  This paper addresses these challenges by proposing a novel training-free method, Chance-constrained Flow Matching (CCFM), that integrates stochastic optimization into the sampling process, enabling effective enforcement of hard constraints while maintaining high-fidelity sample generation. Importantly, CCFM guarantees feasibility in the same manner as conventional repeated projection, yet, despite operating directly on noisy intermediate samples, it is theoretically equivalent to projecting onto the feasible set defined by clean samples. This yields a sampler that mitigates distributional distortion. Empirical experiments show that CCFM outperforms current state-of-the-art constrained generative models in modeling complex physical systems governed by partial differential equations and molecular docking problems, delivering higher feasibility and fidelity."},"pdf":{"value":"/pdf/0f9bd0e3e20b17b9161a368b3e8f68b7f681c166.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliang2025chanceconstrained,\\ntitle={Chance-constrained Flow Matching for High-Fidelity Constraint-aware Generation},\\nauthor={Jinhao Liang and Sandeep Madireddy and Ferdinando Fioretto},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=IJnHZ6VO6a}\\n}"},"paperhash":{"value":"liang|chanceconstrained_flow_matching_for_highfidelity_constraintaware_generation"}},"id":"IJnHZ6VO6a","forum":"IJnHZ6VO6a","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission181/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission181/Authors"],"number":181,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission181/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757128839591,"cdate":1757128839591,"tmdate":1764510128938,"mdate":1764510128938,"pdate":1764306362472,"odate":1764510128924,"version":2},{"content":{"title":{"value":"Efficient Rashomon Set Approximation for Decision Trees"},"authors":{"value":["Zakk Heile","Varun Babbar","Hayden McTavish","Cynthia Rudin"]},"authorids":{"value":["~Zakk_Heile1","~Varun_Babbar3","~Hayden_McTavish1","~Cynthia_Rudin1"]},"keywords":{"value":["Rashomon","Rashomon set","Decision tree"]},"abstract":{"value":"Standard machine learning pipelines often admit many near-optimal models. These \\"Rashomon sets'' pose a range of challenges and opportunities for uncertainty-aware, robust decision making. They allow incorporation of domain knowledge and user preferences that would otherwise be difficult to specify directly in an objective, and they quantify diversity in the plausible models and predictions for a given training dataset and objective function. However, the applicability of Rashomon sets has been limited by computational intractability. Computation of Rashomon sets even for simple, interpretable model classes like sparse decision trees continues to require immense memory and runtime resources. We present LicketyRESPLIT, an algorithm to approximate this Rashomon set with orders of magnitude improvement in runtime and memory usage. We validate that LicketyRESPLIT regularly recovers almost all of the full Rashomon set. This work dramatically expands the ability of researchers and practitioners to model the Rashomon set for real-world datasets."},"pdf":{"value":"/pdf/25fa1827ae2abfa4b37f27e8682a20a36446c756.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nheile2025efficient,\\ntitle={Efficient Rashomon Set Approximation for Decision Trees},\\nauthor={Zakk Heile and Varun Babbar and Hayden McTavish and Cynthia Rudin},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=JlnpgWUXfS}\\n}"},"paperhash":{"value":"heile|efficient_rashomon_set_approximation_for_decision_trees"}},"id":"JlnpgWUXfS","forum":"JlnpgWUXfS","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission180/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission180/Authors"],"number":180,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission180/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757128529727,"cdate":1757128529727,"tmdate":1764510128892,"mdate":1764510128892,"pdate":1764306362468,"odate":1764510128874,"version":2},{"content":{"title":{"value":"Online Learning for Dynamic Service Mode Control"},"authors":{"value":["Wenqian Xing","Yue Hu","Anand Kalvit","Vahid Sarhangian"]},"authorids":{"value":["~Wenqian_Xing1","yuehu@stanford.edu","~Anand_Kalvit1","~Vahid_Sarhangian1"]},"keywords":{"value":["Online Learning","Queueing","Service mode control","Unknown parameters"]},"TLDR":{"value":"We develop online learning algorithms for dynamic service mode control in queues, achieving near-optimal regret through regenerative analysis and validating the approach in AI-assisted healthcare operations."},"abstract":{"value":"Modern service systems are increasingly adopting new modalities enabled by emerging technologies, such as AI-assisted services, to better balance quality and efficiency. Motivated by this trend, we study dynamic service mode control in a single-server queue with two switchable modes, each with a distinct service rate and an unknown reward distribution. The objective is to maximize the long-run average of expected cumulative rewards minus holding costs achievable under non-anticipating, state-dependent policies. To address the problem, we first establish the optimality of a threshold policy under full information of the problem primitives. When reward distributions are unknown but samples are observable, we propose an online learning algorithm that uses Upper Confidence Bound (UCB) estimates of the unknown parameters to adaptively learn the optimal threshold. Our algorithm achieves statistically near-optimal regret of $\\\\tilde{{O}}(\\\\sqrt{T})$ and demonstrates strong numerical performance. Additionally, when additional partial information about the optimal policy is available ex ante (specifically, a non-trivial lower bound on the optimal threshold), we show that an episodic greedy policy achieves constant regret by leveraging a free-exploration property intrinsic to this special setting. Methodologically, we develop a novel regret decomposition and regenerative cycle-based analysis, offering general tools for learning-based queueing control. Lastly, we conduct a healthcare case study on AI-assisted patient messaging demonstrating the practical utility of our approach."},"pdf":{"value":"/pdf/20aeb1bce001f14e0d0bb1a793820e905d59b07b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nxing2025online,\\ntitle={Online Learning for Dynamic Service Mode Control},\\nauthor={Wenqian Xing and Yue Hu and Anand Kalvit and Vahid Sarhangian},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=SeY6vDbUx1}\\n}"},"paperhash":{"value":"xing|online_learning_for_dynamic_service_mode_control"}},"id":"SeY6vDbUx1","forum":"SeY6vDbUx1","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission178/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission178/Authors"],"number":178,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission178/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757127874962,"cdate":1757127874962,"tmdate":1764510128823,"mdate":1764510128823,"pdate":1764306362296,"odate":1764510128809,"version":2},{"content":{"title":{"value":"FlowGINO: Continuous Reconstruction from Sparse Observations along with Aleatoric and Epistemic Uncertainty Estimation"},"authors":{"value":["Alif Bin Abdul Qayyum","Byung-Jun Yoon"]},"authorids":{"value":["~Alif_Bin_Abdul_Qayyum1","~Byung-Jun_Yoon1"]},"keywords":{"value":["Uncertainty estimate","continuous reconstruction"]},"abstract":{"value":"Mapping out physical fields in continuous domain from sparse sensor data observations is a difficult challenge and an active research endeavor in many scientific fields. Since the processes that create this data are often not fully understood, there is increasing interest in leveraging deep neural networks to address this problem. Despite significant progress in using deep learning methods like Implicit Neural Representations (INRs) and Fourier Neural Operators (FNOs) for reconstructing physical fields, there remains a notable gap in research on quantifying the uncertainty of these reconstructions. For high-stakes applications, such as climate modeling, it is critically important to estimate and disentangle the two types of uncertainty: reducible *Epistemic Uncertainty* and irreducible *Aleatoric Uncertainty*. Effectively quantifying and separating these uncertainties is essential for the reliable application of deep learning models across scientific domains. We introduce **Flow**-matching **G**eometry **I**nformed **N**eural **O**perator (**FlowGINO**) which is not only capable of reconstructing continuous physical fields but also capable of estimating both epistemic and aleatoric uncertainty in a disentangled manner."},"pdf":{"value":"/pdf/3558f0e57cee0882428033906526eb18c10d6e5e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nqayyum2025flowgino,\\ntitle={Flow{GINO}: Continuous Reconstruction from Sparse Observations along with Aleatoric and Epistemic Uncertainty Estimation},\\nauthor={Alif Bin Abdul Qayyum and Byung-Jun Yoon},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=gOZlqUCFQ6}\\n}"},"paperhash":{"value":"qayyum|flowgino_continuous_reconstruction_from_sparse_observations_along_with_aleatoric_and_epistemic_uncertainty_estimation"}},"id":"gOZlqUCFQ6","forum":"gOZlqUCFQ6","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission174/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission174/Authors"],"number":174,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission174/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757125779728,"cdate":1757125779728,"tmdate":1764510128710,"mdate":1764510128710,"pdate":1764306361775,"odate":1764510128696,"version":2},{"content":{"title":{"value":"SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations"},"authors":{"value":["Haoting Zhang","Haoxian Chen","Donglin Zhan","Hanyang Zhao","Henry Lam","Wenpin Tang","David Yao","Zeyu Zheng"]},"authorids":{"value":["~Haoting_Zhang2","~Haoxian_Chen2","~Donglin_Zhan1","~Hanyang_Zhao1","~Henry_Lam1","~Wenpin_Tang1","~David_Yao1","~Zeyu_Zheng2"]},"keywords":{"value":["simulation optimization","large language models"]},"abstract":{"value":"The field of simulation optimization (SO) encompasses various methods developed to optimize complex, expensive-to-sample stochastic systems. Established methods include, but are not limited to, ranking-and-selection for finite alternatives and surrogate-based methods for continuous domains, with broad applications in engineering and operations management. The recent advent of large language models (LLMs) offers a new paradigm for exploiting system structure and automating the strategic selection and composition of these established SO methods into a tailored optimization procedure. This work introduces SOCRATES (Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations), a novel two-stage procedure that leverages LLMs to automate the design of tailored SO algorithms. The first stage constructs an ensemble of digital replicas of the real system. An LLM is employed to implement causal discovery from a textual description of the system, generating a structural \`skeleton' that guides the sample-efficient learning of the replicas. In the second stage, this replica ensemble is used as an inexpensive testbed to evaluate a set of baseline SO algorithms. An LLM then acts as a meta-optimizer, analyzing the performance trajectories of these algorithms to iteratively revise and compose a final, hybrid optimization schedule. This schedule is designed to be adaptive, with the ability to be updated during the final execution on the real system when the optimization performance deviates from expectations. By integrating LLM-driven reasoning with LLM-assisted trajectory-aware meta-optimization, SOCRATES creates an effective and sample-efficient solution for complex SO optimization problems."},"pdf":{"value":"/pdf/8750a6a103af345de0a88bb9c764cf58b3ae18ed.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhang2025socrates,\\ntitle={{SOCRATES}: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations},\\nauthor={Haoting Zhang and Haoxian Chen and Donglin Zhan and Hanyang Zhao and Henry Lam and Wenpin Tang and David Yao and Zeyu Zheng},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=gdoRFWQ50s}\\n}"},"paperhash":{"value":"zhang|socrates_simulation_optimization_with_correlated_replicas_and_adaptive_trajectory_evaluations"}},"id":"gdoRFWQ50s","forum":"gdoRFWQ50s","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission173/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission173/Authors"],"number":173,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission173/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757125567825,"cdate":1757125567825,"tmdate":1764510128649,"mdate":1764510128649,"pdate":1764306361719,"odate":1764510128631,"version":2},{"content":{"title":{"value":"Learning from a Biased Sample"},"authors":{"value":["Roshni Sahoo","Lihua Lei","Stefan Wager"]},"authorids":{"value":["~Roshni_Sahoo1","~Lihua_Lei2","~Stefan_Wager1"]},"keywords":{"value":["Distributionally Robust Optimization; Machine Learning; Biased Sample; Duality; Conditional Value-at-Risk"]},"TLDR":{"value":"We propose a conditional distributionally robust optimization-based framework for learning under a biased sample, which is equivalent to an empirical risk minimization problem with an auxiliary dual function and hence amenable to neural nets."},"abstract":{"value":"The empirical risk minimization approach to data-driven decision making requires access to training data drawn under the same conditions as those that will be faced when the decision rule is deployed. However, in a number of settings, we may be concerned that our training sample is biased in the sense that some groups (characterized by either observable or unobservable attributes) may be under- or over-represented relative to the general population; and in this setting empirical risk minimization over the training set may fail to yield rules that perform well at deployment. We propose a model of sampling bias called conditional Γ-biased sampling, where observed covariates can affect the probability of sample selection arbitrarily much but the amount of unexplained variation in the probability of sample selection is bounded by a constant factor. Applying the distributionally robust optimization framework, we propose a method for learning a decision rule that minimizes the worst-case risk incurred under a family of test distributions that can generate the training distribution under Γ-biased sampling. We apply a result of Rockafellar and Uryasev to show that this problem is equivalent to an augmented convex risk minimization problem. We give statistical guarantees for learning a model that is robust to sampling bias via the method of sieves, and\\npropose a deep learning algorithm whose loss function captures our robust learning target. We empirically validate our proposed method in a case study on prediction of mental health scores from health survey data and a case study on ICU length of stay prediction."},"pdf":{"value":"/pdf/b54b43c43d8284a5403487c454cb791ee0363479.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nsahoo2025learning,\\ntitle={Learning from a Biased Sample},\\nauthor={Roshni Sahoo and Lihua Lei and Stefan Wager},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=TUfasIvvwx}\\n}"},"paperhash":{"value":"sahoo|learning_from_a_biased_sample"}},"id":"TUfasIvvwx","forum":"TUfasIvvwx","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission170/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission170/Authors"],"number":170,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission170/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757125187675,"cdate":1757125187675,"tmdate":1764510128546,"mdate":1764510128546,"pdate":1764306361080,"odate":1764510128531,"version":2},{"content":{"title":{"value":"Mixed Integer Programming for Change-point Detection"},"authors":{"value":["Apoorva Narula","Yao Xie","Santanu Dey"]},"authorids":{"value":["~Apoorva_Narula1","~Yao_Xie2","~Santanu_Dey1"]},"keywords":{"value":["Change-point Detection","Mixed Integer Programming","Piecewise-linear fitting"]},"TLDR":{"value":"We propose an MIP for change-point detection via continuous piecewise-linear fitting whose LP relaxation projects integrally onto segment-assignment variables, yielding faster runtimes."},"abstract":{"value":"We propose a new mixed-integer programming formulation for fitting continuous piecewise linear functions. A key family of variables in this formulation is what we call as the segment assignment variables. These are indicator variables specifying which segment each data point belongs to. We prove that the projection of the linear programming relaxation of our formulation onto the segment assignment variables is integral. We compare our formulations against the most computationally efficient benchmarks in literature, both theoretically and through computational experiments on publicly available datasets. We observe that our approach achieves a significant speedup in terms of runtime relative to these benchmark formulations on larger datasets, and comparable performance on smaller ones."},"pdf":{"value":"/pdf/93e1dcc0722fbd209330404b9e0f900883076f11.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnarula2025mixed,\\ntitle={Mixed Integer Programming for Change-point Detection},\\nauthor={Apoorva Narula and Yao Xie and Santanu Dey},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=1IjOhjVYkn}\\n}"},"paperhash":{"value":"narula|mixed_integer_programming_for_changepoint_detection"}},"id":"1IjOhjVYkn","forum":"1IjOhjVYkn","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission168/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission168/Authors"],"number":168,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission168/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757124549596,"cdate":1757124549596,"tmdate":1764510128488,"mdate":1764510128488,"pdate":1764306360964,"odate":1764510128471,"version":2},{"content":{"title":{"value":"Landscape of Policy Optimization for Finite Horizon MDPs with General State and Action"},"authors":{"value":["Xin Chen","Yifan Hu","Minda Zhao"]},"authorids":{"value":["~Xin_Chen7","~Yifan_Hu2","~Minda_Zhao3"]},"keywords":{"value":["finite-horizon Markov Decision Processes (MDPs)","policy gradient methods","Polyak-Łojasiewicz-Kurdyka (PŁK) condition","inventory","cash balance","data-driven operations models"]},"abstract":{"value":"Policy gradient methods are widely used in reinforcement learning. Yet, the nonconvexity of policy optimization imposes significant challenges in understanding the global convergence of policy gradient methods. For a class of finite-horizon MDPs with general state and action spaces, we develop a framework that provides a set of easily verifiable assumptions to ensure the Polyak-Łojasiewicz-Kurdyka (PŁK) condition of the policy optimization. Leveraging the PŁK condition, policy gradient methods converge to the globally optimal policy with a non-asymptomatic rate despite nonconvexity. Our results find applications in various control and operations models, including entropy-regularized tabular MDPs, Linear Quadratic Regulator problems, stochastic inventory models, and stochastic cash balance problems, for which we show an $\\\\epsilon$-optimal policy can be obtained using a sample size in $\\\\tilde{\\\\mathcal O}(\\\\epsilon^{-1})$ and polynomial in terms of the planning horizon by stochastic policy gradient methods. Our result establishes the first sample complexity for multi-period inventory systems with Markov-modulated demands and stochastic cash balance problems in the literature."},"pdf":{"value":"/pdf/6a1262593745a84b6d0d9779a068561059620e17.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nchen2025landscape,\\ntitle={Landscape of Policy Optimization for Finite Horizon {MDP}s with General State and Action},\\nauthor={Xin Chen and Yifan Hu and Minda Zhao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=uaQqUKpqO4}\\n}"},"paperhash":{"value":"chen|landscape_of_policy_optimization_for_finite_horizon_mdps_with_general_state_and_action"}},"id":"uaQqUKpqO4","forum":"uaQqUKpqO4","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission167/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission167/Authors"],"number":167,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission167/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757124241391,"cdate":1757124241391,"tmdate":1764510128449,"mdate":1764510128449,"pdate":1764306360834,"odate":1764510128432,"version":2},{"content":{"title":{"value":"Conformalized Decision Risk Assessment"},"authors":{"value":["Wenbin Zhou","Agni Orfanoudaki","Shixiang Zhu"]},"authorids":{"value":["~Wenbin_Zhou1","~Agni_Orfanoudaki2","~Shixiang_Zhu1"]},"keywords":{"value":["Conformal prediction","inverse optimization","risk assessment","decision making under uncertainty"]},"TLDR":{"value":"A framework for quantifying the probability that a candidate decision is suboptimal in an optimization setting"},"abstract":{"value":"We introduce \\\\texttt{CREDO}, a framework that provides distribution-free upper bounds on the probability that any candidate decision is suboptimal. By combining inverse optimization geometry with conformal prediction and generative modeling, \\\\texttt{CREDO} generates statistically rigorous and interpretable risk certificates. This enables decision-makers to audit and validate choices under uncertainty, bridging the gap between decision-making algorithms and human judgment."},"pdf":{"value":"/pdf/17d7992562c0be5f05b1f7ca184453fa37c7e981.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhou2025conformalized,\\ntitle={Conformalized Decision Risk Assessment},\\nauthor={Wenbin Zhou and Agni Orfanoudaki and Shixiang Zhu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=HGz4IGCWg7}\\n}"},"paperhash":{"value":"zhou|conformalized_decision_risk_assessment"}},"id":"HGz4IGCWg7","forum":"HGz4IGCWg7","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission165/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission165/Authors"],"number":165,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission165/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757123007109,"cdate":1757123007109,"tmdate":1764510128386,"mdate":1764510128386,"pdate":1764306360738,"odate":1764510128369,"version":2},{"content":{"title":{"value":"Achieving First-Order Statistical Improvements in Data-Driven Optimization"},"authors":{"value":["Henry Lam","Tianyu Wang"]},"authorids":{"value":["~Henry_Lam1","~Tianyu_Wang6"]},"keywords":{"value":["excess risk","first-order improvement","data-driven optimization"]},"TLDR":{"value":"We analyze the statistical performance of robust methods and find that the performance improvement over the empirical solution is usually not significant."},"abstract":{"value":"Recent proliferation of data-optimization integration has led to a range of methods that aim to improve the statistical performance of data-driven optimization decisions. However, while many of these methods are motivated intuitively from a robustness or regularization perspective, their resulting statistical benefits are often less clear and, even if available, are argued in a case-by-case fashion. We provide a systematic dissection of data-driven optimization formulations using the view of \`\`directionally perturbed'' empirical optimization, which demonstrably covers most of the existing formulations. On the negative side, we argue that under mild smoothness conditions, any such formulations can result in at best second-order improvements. On the positive side, we show that in the presence of auxiliary information such as the availability of additional unsupervised data, we can construct a principled methodology, by building connections to the concept of Monte Carlo control variate, to achieve general first-order improvements in terms of excess risk."},"pdf":{"value":"/pdf/ce3f7a7ffbfaf4345a5c0de32af3e63a089c4d58.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlam2025achieving,\\ntitle={Achieving First-Order Statistical Improvements in Data-Driven Optimization},\\nauthor={Henry Lam and Tianyu Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=kRqRr8Psbr}\\n}"},"paperhash":{"value":"lam|achieving_firstorder_statistical_improvements_in_datadriven_optimization"}},"id":"kRqRr8Psbr","forum":"kRqRr8Psbr","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission163/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission163/Authors"],"number":163,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission163/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757122564946,"cdate":1757122564946,"tmdate":1764510128365,"mdate":1764510128365,"pdate":1764306360646,"odate":1764510128349,"version":2},{"content":{"title":{"value":"Mechanistic Interpretability for Neural TSP Solvers"},"authors":{"value":["Reuben Narad","Léonard Boussioux","Michael Wagner"]},"authorids":{"value":["~Reuben_Narad1","~Léonard_Boussioux1","mrwagner@uw.edu"]},"keywords":{"value":["Mechanistic interpretability","Sparse autoencoders","Neural combinatorial optimization","Traveling Salesman Problem","Transformers","Reinforcement learning"]},"TLDR":{"value":"We apply Mechanistic Interpretability to a neural TSP solver, finding meaningful learned features in the model's neurons."},"abstract":{"value":"Neural networks have advanced combinatorial optimization, with Transformer-based solvers often outperforming classical algorithms on the Traveling Salesman Problem (TSP). However, these models remain black boxes, limiting our understanding of what optimization strategies they discover. We apply sparse autoencoders (SAEs) to interpret neural TSP solvers. To our knowledge, this is the first work to bring mechanistic interpretability from deep learning models to operations research. Our analysis reveals interpretable features that these solvers naturally developed that mirror fundamental TSP-solving concepts: boundary detection, spatial clustering, and geometric separations. These discoveries reveal how neural solvers approach combinatorial problems and suggest new directions for hybrid approaches that combine algorithmic transparency with neural performance. Interactive feature explorer: \\\\url{https://reubennarad.github.io/TSP_interp/}"},"pdf":{"value":"/pdf/dce73cbaa3fc3a9881062a73a009eec54bdb8287.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnarad2025mechanistic,\\ntitle={Mechanistic Interpretability for Neural {TSP} Solvers},\\nauthor={Reuben Narad and L{\\\\'e}onard Boussioux and Michael Wagner},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=nX0AoRt55a}\\n}"},"paperhash":{"value":"narad|mechanistic_interpretability_for_neural_tsp_solvers"}},"id":"nX0AoRt55a","forum":"nX0AoRt55a","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission162/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission162/Authors"],"number":162,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission162/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757122060862,"cdate":1757122060862,"tmdate":1764510128312,"mdate":1764510128312,"pdate":1764306360571,"odate":1764510128292,"version":2},{"content":{"title":{"value":"Integrating qualitative data into transit service design: a stochastic estimate-then-optimize approach"},"authors":{"value":["Alexandre Jacquillat","Shriya Karam"]},"authorids":{"value":["alexjacq@mit.edu","~Shriya_Karam1"]},"keywords":{"value":["transit planning","natural language processing","demand estimation","stochastic optimization"]},"TLDR":{"value":"This paper develop a stochastic estimate-then-optimize approach that leverages qualitative data to estimate origin–destination demand for a transit system and optimize transit frequencies."},"abstract":{"value":"Transportation planning models are typically calibrated using coarse numerical data. However, these data alone may fail to capture travel demand patterns at a granular spatiotemporal-level, and hence, may lead to a mismatch between service levels and passenger demand. At the same time, the availability of qualitative data offers opportunities to better align service with true travel demand patterns. Yet, unstructured qualitative data is rarely incorporated into demand estimation and decision-making, and doing so remains an open question with no readily-available solution. To address this gap, we develop a stochastic estimate-then-optimize approach that leverages unstructured qualitative data to derive operational value. Our approach combines natural language processing for transit-specific topic modeling, a novel approach to estimate origin–destination demand based on qualitative and quantitative data, and stochastic optimization to optimize transit frequencies. Our results demonstrate that our demand estimation phase outperforms numerical data-only benchmarks and that our optimization phase improves total passenger waiting time by 7%."},"pdf":{"value":"/pdf/a6127dd071afa6e4973caa6fd4280970c5547b73.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njacquillat2025integrating,\\ntitle={Integrating qualitative data into transit service design: a stochastic estimate-then-optimize approach},\\nauthor={Alexandre Jacquillat and Shriya Karam},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=NlfruoGCEh}\\n}"},"paperhash":{"value":"jacquillat|integrating_qualitative_data_into_transit_service_design_a_stochastic_estimatethenoptimize_approach"}},"id":"NlfruoGCEh","forum":"NlfruoGCEh","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission161/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission161/Authors"],"number":161,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission161/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757120629516,"cdate":1757120629516,"tmdate":1764510128290,"mdate":1764510128290,"pdate":1764306360569,"odate":1764510128275,"version":2},{"content":{"title":{"value":"Uncertainty Estimation using Variance-Gated Distributions"},"authors":{"value":["Martin Gillis","Isaac Xu","Thomas Trappenberg"]},"authorids":{"value":["~Martin_Gillis1","~Isaac_Xu1","~Thomas_Trappenberg1"]},"keywords":{"value":["uncertainty decomposition","Monte Carlo dropout","last-layer ensembles","committee machines","neural collapse"]},"abstract":{"value":"Evaluation of per-sample uncertainty quantification from neural networks is essential for decision-making involving high-risk applications. A common approach is to use the predictive distribution from Bayesian or approximation models and decompose the corresponding predictive uncertainty into epistemic (model-related) and aleatoric (data-related) components. However, additive decomposition has recently been questioned. In this work, we propose an intuitive framework for uncertainty estimation and decomposition based on the signal-to-noise ratio of class probability distributions across different model predictions. We introduce a variance-gated measure that scales predictions by a confidence factor derived from ensembles. We use this measure to discuss the existence of a collapse in the diversity of committee machines."},"pdf":{"value":"/pdf/44bf2c0ffe389fa262707337c4c32afac4b64e1d.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ngillis2025uncertainty,\\ntitle={Uncertainty Estimation using Variance-Gated Distributions},\\nauthor={Martin Gillis and Isaac Xu and Thomas Trappenberg},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=vTDvrwtaG0}\\n}"},"paperhash":{"value":"gillis|uncertainty_estimation_using_variancegated_distributions"}},"id":"vTDvrwtaG0","forum":"vTDvrwtaG0","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission157/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission157/Authors"],"number":157,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission157/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757120152929,"cdate":1757120152929,"tmdate":1764510128110,"mdate":1764510128110,"pdate":1764306360359,"odate":1764510128064,"version":2},{"content":{"title":{"value":"Learning to Optimize at Scale: A Benders Decomposition-TransfORmers Framework for Stochastic Combinatorial Optimization"},"authors":{"value":["Seung Jin Choi","Kimiya Jozani","Joshua F. Cooper","I Esra Buyuktahtakin"]},"authorids":{"value":["seungj9@vt.edu","~Kimiya_Jozani1","~Joshua_F._Cooper1","~I_Esra_Buyuktahtakin1"]},"keywords":{"value":["Stochastic Mixed-Integer Programming","Dynamic Decomposition","Transformer Models","Capacitated Lot-Sizing","Learning-Optimization Integration"]},"TLDR":{"value":"We develop a decomposition-transformer framework that learns to optimize large-scale stochastic combinatorial problems, achieving faster and more scalable solutions than classical methods."},"abstract":{"value":"We introduce the first integration of transformer-based learning within a dynamic\\n decomposition framework to solve large-scale two-stage stochastic mixed-integer\\n programs. We focus on the stochastic capacitated lot-sizing problem under demand\\n uncertainty. Our approach reformulates the problem to incorporate stochasticity\\n and partitions the problem into smaller, tractable subproblems using a dynamic\\n decomposition. These subproblems are solved by a transfORmer model, providing\\n a novel combination of learned combinatorial and relaxation-based cuts to the\\n master problem. This hybrid learning-optimization strategy bridges deep learning\\n with exact mathematical programming, achieving fast but high-quality solutions.\\n For the test set considered, our method outperforms traditional decomposition\\n and direct solvers in both runtime and scalability, demonstrating the potential\\n of transformers as surrogate optimizers embedded within structured solution\\n algorithms for stochastic combinatorial problems."},"pdf":{"value":"/pdf/ad81581151704ee69ea4762a8456de41a9ba1bb5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nchoi2025learning,\\ntitle={Learning to Optimize at Scale: A Benders Decomposition-Transf{OR}mers Framework for Stochastic Combinatorial Optimization},\\nauthor={Seung Jin Choi and Kimiya Jozani and Joshua F. Cooper and I Esra Buyuktahtakin},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=jVcPvWjrQ5}\\n}"},"paperhash":{"value":"choi|learning_to_optimize_at_scale_a_benders_decompositiontransformers_framework_for_stochastic_combinatorial_optimization"}},"id":"jVcPvWjrQ5","forum":"jVcPvWjrQ5","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission153/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission153/Authors"],"number":153,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission153/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757117075103,"cdate":1757117075103,"tmdate":1764510127997,"mdate":1764510127997,"pdate":1764306360039,"odate":1764510127977,"version":2},{"content":{"title":{"value":"Batch-Adaptive Annotations for Causal Inference with Text-Based Outcomes"},"authors":{"value":["Ezinne Nwankwo","Lauri Goldkind","Angela Zhou"]},"authorids":{"value":["~Ezinne_Nwankwo1","~Lauri_Goldkind1","~Angela_Zhou1"]},"keywords":{"value":["causal inference","homelessness services","llm as a judge"]},"abstract":{"value":"Estimating the causal effects of an intervention on outcomes is crucial to policy and decision-making. But often, information about outcomes can be missing or subject to non-standard measurement error. It may be possible to reveal ground-truth outcome information at a cost, for example via data annotation or follow-up; but budget constraints entail that only a fraction of the dataset can be labeled. In this setting, we optimize which data points should be sampled for outcome information and therefore efficient average treatment effect estimation with missing data. We do so by allocating data annotation in batches. We extend to settings where outcomes may be recorded in unstructured data that can be annotated at a cost, such as text or images, for example, in healthcare or social services. Our motivating application is a collaboration with a street outreach provider with millions of case notes, where it is possible to expertly label some, but not all, ground-truth outcomes. We demonstrate how expert labels and noisy imputed labels can be combined into a doubly robust causal estimator. We run experiments on simulated data and two real-world datasets, including one on street outreach interventions in homelessness services, to show the versatility of our proposed method."},"pdf":{"value":"/pdf/617f50fd8f275626bfcc7f1ca011432d6af6128b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnwankwo2025batchadaptive,\\ntitle={Batch-Adaptive Annotations for Causal Inference with Text-Based Outcomes},\\nauthor={Ezinne Nwankwo and Lauri Goldkind and Angela Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=h2yAIYMqzL}\\n}"},"paperhash":{"value":"nwankwo|batchadaptive_annotations_for_causal_inference_with_textbased_outcomes"}},"id":"h2yAIYMqzL","forum":"h2yAIYMqzL","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission152/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission152/Authors"],"number":152,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission152/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757116717072,"cdate":1757116717072,"tmdate":1764510127957,"mdate":1764510127957,"pdate":1764306359971,"odate":1764510127937,"version":2},{"content":{"title":{"value":"Active Learning for Stochastic Contextual Linear Bandits"},"authors":{"value":["Emma Brunskill","Ishani Karmarkar","Zhaoqi Li"]},"authorids":{"value":["~Emma_Brunskill2","~Ishani_Karmarkar1","~Zhaoqi_Li1"]},"keywords":{"value":["Contextual bandits","stochastic contextual linear bandits","active learning","sample efficiency","pure exploration","regret","experiment design"]},"TLDR":{"value":"We present active learning algorithms for exploration in contextual stochastic linear bandits and demonstrate improved sample efficiency."},"abstract":{"value":"A key goal in stochastic contextual linear bandits is to efficiently learn a near-optimal policy. Prior algorithms for this problem learn a policy by strategically sampling actions and naively (passively) sampling contexts from the underlying context distribution. However, in many practical scenarios---including online content recommendation, survey research, and clinical trials---practitioners can actively sample or recruit contexts based on prior knowledge of the context distribution. Despite this potential for _active learning_, the role of strategic context sampling in stochastic contextual linear bandits is underexplored. We propose an algorithm that learns a near-optimal policy by strategically sampling rewards of context-action pairs. We prove _instance-dependent_ theoretical guarantees demonstrating that our active context sampling strategy can improve over the minimax rate by up to a factor of $\\\\sqrt{d}$, where $d$ is the linear dimension. We also show empirically that our algorithm reduces the number of samples needed to learn a near-optimal policy, in tasks such as warfarin dose prediction and joke recommendation."},"pdf":{"value":"/pdf/87739c20df5fe56afbaa38795153712a8c207024.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbrunskill2025active,\\ntitle={Active Learning for Stochastic Contextual Linear Bandits},\\nauthor={Emma Brunskill and Ishani Karmarkar and Zhaoqi Li},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=PmPO7b9npu}\\n}"},"paperhash":{"value":"brunskill|active_learning_for_stochastic_contextual_linear_bandits"}},"id":"PmPO7b9npu","forum":"PmPO7b9npu","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission151/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission151/Authors"],"number":151,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission151/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757116619351,"cdate":1757116619351,"tmdate":1764510127877,"mdate":1764510127877,"pdate":1764306359905,"odate":1764510127856,"version":2},{"content":{"title":{"value":"Confounding-Robust Fitted-Q-Iteration under Observed Markovian Marginals"},"authors":{"value":["David Bruns-Smith","Angela Zhou"]},"authorids":{"value":["~David_Bruns-Smith1","~Angela_Zhou1"]},"keywords":{"value":["causal reinforcement learning","offline reinforcement learning"]},"abstract":{"value":"Sequential decision-making problems in medicine, economics, and e-commerce require the use of historical observational data when online experimentation is costly, dangerous or unethical. Given the rise of big data, these observational datasets are increasingly large and widely available, with great potential to improve decisions based on personalizing treatments to those who most benefit. The recent literature on offline reinforcement learning (RL) has made extensive progress on evaluating and optimizing sequential decision rules given only historical datasets of observed trajectories. In particular, methods that target estimation of the Q function leveraging black-box regression, such as fitted-Q-evaluation and fitted-Q-iteration (FQE/FQI), have gained popularity due to their computational ease and scalability \\\\citep{voloshin2019empirical}."},"pdf":{"value":"/pdf/98835577e51f2cfb6f6968b8cff201ae503c2bcf.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbruns-smith2025confoundingrobust,\\ntitle={Confounding-Robust Fitted-Q-Iteration under Observed Markovian Marginals},\\nauthor={David Bruns-Smith and Angela Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=GUpToARb5M}\\n}"},"paperhash":{"value":"brunssmith|confoundingrobust_fittedqiteration_under_observed_markovian_marginals"}},"id":"GUpToARb5M","forum":"GUpToARb5M","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission150/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission150/Authors"],"number":150,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission150/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757115820406,"cdate":1757115820406,"tmdate":1764510127798,"mdate":1764510127798,"pdate":1764306359843,"odate":1764510127731,"version":2},{"content":{"title":{"value":"DeepStock: Reinforcement Learning with Policy Regularizations for Inventory Management"},"authors":{"value":["Yaqi Xie","Xinru Hao","Jiaxi Liu","Will Ma","Linwei Xin","Lei Cao","Yidong Zhang"]},"authorids":{"value":["~Yaqi_Xie3","xinru.hxr@taobao.com","~Jiaxi_Liu1","~Will_Ma1","lx267@cornell.edu","huaju.cl@taobao.com","yidongzster@gmail.com"]},"keywords":{"value":["deep reinforcement learning","inventory management","policy regularization","basestock"]},"abstract":{"value":"In the age of big data and large-scale compute, Deep Reinforcement Learning (DRL) provides a general-purpose methodology for optimizing inventory policies. However, off-the-shelf implementations of DRL have seen mixed success, often plagued by sensitivity to the hyperparameters used during training. In this paper, we show that by imposing policy regularizations, grounded in classical inventory concepts such as \\"Base Stock\\", we can greatly accelerate hyperparameter tuning and improve the final performance of several DRL methods. We report details from a full-scale deployment of DRL with policy regularizations on Alibaba's e-commerce platform, Tmall.  Our paper also includes extensive synthetic experiments, which show that policy regularizations redefine the narrative on what is the best DRL method for inventory management."},"pdf":{"value":"/pdf/1954e9795333c8c883c180eb134102d20256d040.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nxie2025deepstock,\\ntitle={DeepStock: Reinforcement Learning with Policy Regularizations for Inventory Management},\\nauthor={Yaqi Xie and Xinru Hao and Jiaxi Liu and Will Ma and Linwei Xin and Lei Cao and Yidong Zhang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=jEdw8z1Sjg}\\n}"},"paperhash":{"value":"xie|deepstock_reinforcement_learning_with_policy_regularizations_for_inventory_management"}},"id":"jEdw8z1Sjg","forum":"jEdw8z1Sjg","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission148/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission148/Authors"],"number":148,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission148/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757113719831,"cdate":1757113719831,"tmdate":1764510127792,"mdate":1764510127792,"pdate":1764306359629,"odate":1764510127618,"version":2},{"content":{"title":{"value":"Tail-Optimized Caching for LLM Inference"},"authors":{"value":["Wenxin Zhang","Yueying Li","Ciamac C. Moallemi","Tianyi Peng"]},"authorids":{"value":["~Wenxin_Zhang8","~Yueying_Li1","~Ciamac_C._Moallemi1","~Tianyi_Peng1"]},"keywords":{"value":["prompt caching","large language models","tail latency","KV‑cache eviction","Least‑Recently‑Used"]},"abstract":{"value":"Prompt caching is critical for reducing latency and cost in LLM inference---OpenAI and Anthropic report up to 50–90\\\\% cost savings through prompt reuse. Despite its widespread success, little is known about what constitutes an optimal prompt caching policy, particularly when optimizing tail latency—a metric of central importance to practitioners. The widely used Least Recently Used (LRU) policy can perform arbitrarily poor on this metric, as it is oblivious to the heterogeneity of conversation lengths. To address this gap, we propose Tail-Optimized LRU, a simple two-line modification that reallocates KV cache capacity to prioritize high-latency conversations by evicting cache entries that are unlikely to affect future turns. Though the implementation is simple, we prove its optimality under a natural stochastic model of conversation dynamics, providing the first theoretical justification for LRU in this setting---a result that may be of independent interest to the caching community. \\nExperimentally, on real conversation data WildChat~\\\\citep{zhao2024wildchat}, Tail-Optimized LRU achieves up to 27.5\\\\% reduction in P90 tail Time to First Token latency and 23.9\\\\% in P95 tail latency compared to LRU, along with up to 38.9\\\\% decrease in SLO violations of 200ms. \\nWe believe this provides a practical and theoretically grounded option for practitioners seeking to optimize tail latency in real-world LLM deployments."},"pdf":{"value":"/pdf/689e8ae5b8ad38781a03ae2aa864eb6aad3bce4c.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhang2025tailoptimized,\\ntitle={Tail-Optimized Caching for {LLM} Inference},\\nauthor={Wenxin Zhang and Yueying Li and Ciamac C. Moallemi and Tianyi Peng},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=0rmUmYeOkA}\\n}"},"paperhash":{"value":"zhang|tailoptimized_caching_for_llm_inference"}},"id":"0rmUmYeOkA","forum":"0rmUmYeOkA","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission147/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission147/Authors"],"number":147,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission147/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757112425861,"cdate":1757112425861,"tmdate":1764510127603,"mdate":1764510127603,"pdate":1764306359508,"odate":1764510127587,"version":2},{"content":{"title":{"value":"Variational Generative Modeling of Stochastic Point Processes"},"authors":{"value":["Xinlong Du","Harsha Honnappa","Vinayak Rao"]},"authorids":{"value":["~Xinlong_Du1","~Harsha_Honnappa1","~Vinayak_Rao1"]},"keywords":{"value":["Generative model","Cox processes","variational inference"]},"TLDR":{"value":"VAE-like generative model for Cox processes"},"abstract":{"value":"We consider approximate inference for a class of Cox point processes i.e., point processes with stochastic intensities. Specifically, we consider processes where the Poisson intensity function is modeled as the solution of a stochastic differential equation (SDE). We propose a VAE-like approach where the latent variable is the solution to an SDE, the decoder is fixed (mapping the intensity function to a realization of an inhomogeneous Poisson process), and the encoder maps a point process realization to a posterior path measure corresponding to a diffusion process. Using tools from the theory of {\\\\it enlargement of filtrations}, we show that the  posterior path measure lies in a  variational family of SDE path measures. Consequently, evidence lower bound (ELBO) maximization coincides with likelihood maximization. We also introduce hybrid encoder architectures for modeling the drift function of the posterior SDE, conditioned on  varying length point process sample paths. Experiments on synthetic data showcase the ability to recover the ground truth measure and highlight the potential of this framework for modeling over-dispersed point processes"},"pdf":{"value":"/pdf/ffd859711ee4bad9442c04ca6813ce7471c536d3.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndu2025variational,\\ntitle={Variational Generative Modeling of Stochastic Point Processes},\\nauthor={Xinlong Du and Harsha Honnappa and Vinayak Rao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=FsdXAfyViO}\\n}"},"paperhash":{"value":"du|variational_generative_modeling_of_stochastic_point_processes"}},"id":"FsdXAfyViO","forum":"FsdXAfyViO","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission145/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission145/Authors"],"number":145,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission145/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757111429334,"cdate":1757111429334,"tmdate":1764510127543,"mdate":1764510127543,"pdate":1764306359433,"odate":1764510127526,"version":2},{"content":{"title":{"value":"Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating Event Tables to Queueing Dynamics"},"authors":{"value":["Daksh Mittal","Shunri Zheng","Jing Dong","Hongseok Namkoong"]},"authorids":{"value":["~Daksh_Mittal1","~Shunri_Zheng1","~Jing_Dong2","~Hongseok_Namkoong2"]},"keywords":{"value":["Stochastic modeling","Autoregressive sequence models","Simulation","Uncertainty Quantification"]},"abstract":{"value":"While queueing network models are powerful tools for analyzing service systems, they traditionally require substantial human effort and domain expertise to construct. To make this modeling approach more scalable and accessible, we propose a data-driven framework for queueing network modeling and simulation based on autoregressive sequence models trained on event-stream data. Instead of explicitly specifying arrival processes, service mechanisms, or routing logic, our approach learns the conditional distributions of event types and event times, recasting the modeling task as a problem of sequence distribution learning. We show that Transformer-style architectures can effectively parameterize these distributions, enabling automated construction of high-fidelity simulators. As a proof of concept, we validate our framework on event tables generated from diverse queueing networks, showcasing its utility in simulation, uncertainty quantification, and counterfactual evaluation. Leveraging advances in artificial intelligence and the growing availability of data, our framework takes a step toward more automated, data-driven modeling pipelines to support broader adoption of queueing network models across service domains."},"pdf":{"value":"/pdf/f4dc6c746ab73121997b4e3737a3b008b25435c8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmittal2025datadriven,\\ntitle={Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating Event Tables to Queueing Dynamics},\\nauthor={Daksh Mittal and Shunri Zheng and Jing Dong and Hongseok Namkoong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=r6ilhlC8GM}\\n}"},"paperhash":{"value":"mittal|datadriven_stochastic_modeling_using_autoregressive_sequence_models_translating_event_tables_to_queueing_dynamics"}},"id":"r6ilhlC8GM","forum":"r6ilhlC8GM","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission144/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission144/Authors"],"number":144,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission144/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757111287911,"cdate":1757111287911,"tmdate":1764510127526,"mdate":1764510127526,"pdate":1764306359334,"odate":1764510127508,"version":2},{"content":{"title":{"value":"Reducing Contextual Stochastic Bilevel Optimization via Structured Function Approximation"},"authors":{"value":["Maxime Bouscary","Jiawei Zhang","Saurabh Amin"]},"authorids":{"value":["~Maxime_Bouscary1","~Jiawei_Zhang6","~Saurabh_Amin1"]},"keywords":{"value":["stochastic optimization","bilevel optimization","contextual stochastic optimization","parametrization"]},"TLDR":{"value":"By parametrizing the context‐specific lower‐level solutions, CSBO can be reduced to a standard SBO problem and solved with near-optimal sample complexity."},"abstract":{"value":"Contextual Stochastic Bilevel Optimization (CSBO) extends standard stochastic bilevel optimization (SBO) by incorporating context-dependent lower-level problems. CSBO problems are generally intractable since existing methods require solving a distinct lower-level problem for each sampled context, resulting in prohibitive sample and computational complexity, in addition to relying on impractical conditional sampling oracles. We propose a reduction framework that approximates the lower-level solutions using expressive basis functions, thereby decoupling the lower-level dependence on context and transforming CSBO into a standard SBO problem solvable using only joint samples from the context and noise distribution. First, we show that this reduction preserves hypergradient accuracy and yields an $\\\\epsilon$-stationary solution to CSBO. Then, we relate the sample complexity of the reduced problem to simple metrics of the basis. This establishes sufficient criteria for a basis to yield $\\\\epsilon$-stationary solutions with a near-optimal complexity of $\\\\widetilde{\\\\mathcal O}(\\\\epsilon^{-3})$, matching the best-known rate for standard SBO up to logarithmic factors. Moreover, we show that Chebyshev polynomials provide a concrete and efficient choice of basis that satisfies these criteria for a broad class of problems. Empirical results on inverse and hyperparameter optimization demonstrate that our approach outperforms CSBO baselines in convergence, sample efficiency, and memory usage."},"pdf":{"value":"/pdf/79f2bdc6f859f9d38e1909239538af038b0704c2.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbouscary2025reducing,\\ntitle={Reducing Contextual Stochastic Bilevel Optimization via Structured Function Approximation},\\nauthor={Maxime Bouscary and Jiawei Zhang and Saurabh Amin},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=99q4niHwbo}\\n}"},"paperhash":{"value":"bouscary|reducing_contextual_stochastic_bilevel_optimization_via_structured_function_approximation"}},"id":"99q4niHwbo","forum":"99q4niHwbo","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission141/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission141/Authors"],"number":141,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission141/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757110330502,"cdate":1757110330502,"tmdate":1764510127411,"mdate":1764510127411,"pdate":1764306359260,"odate":1764510127398,"version":2},{"content":{"title":{"value":"Can Linear Probes Measure LLM Uncertainty ?"},"authors":{"value":["Ramzi Dakhmouche","Adrien Letellier","Hossein Gorji"]},"authorids":{"value":["~Ramzi_Dakhmouche1","~Adrien_Letellier1","~Hossein_Gorji1"]},"keywords":{"value":["Uncertainty Quantification","Large Language Models","Bayesian Statistics","Linear Probes"]},"TLDR":{"value":"We propose an efficient uncertainty quantification approach for LLMs, achieving competitive performance despite just leveraging linear probes."},"abstract":{"value":"Effective Uncertainty Quantification (UQ) represents a key aspect for reliable deployment of Large Language Models (LLMs) in automated decision-making and beyond. Yet, for LLM generation with multiple choice structure, the state-of-the-art in UQ is still dominated by the naive baseline given by the maximum softmax score. To address this shortcoming, we demonstrate that taking a principled approach via Bayesian statistics leads to improved performance despite leveraging the simplest possible model, namely linear regression. More precisely, we propose to train multiple Bayesian linear models, each predicting the output of a layer given the output of the previous one. Based on the obtained layer-level posterior distributions, we infer the global uncertainty level of the LLM by identifying a sparse combination of distributional features, leading to an efficient UQ scheme. Numerical experiments on various LLMs show consistent improvement over state-of-the-art baselines."},"pdf":{"value":"/pdf/9426fad44ef73f36371cf0b4267c94f59905a7ed.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndakhmouche2025can,\\ntitle={Can Linear Probes Measure {LLM} Uncertainty ?},\\nauthor={Ramzi Dakhmouche and Adrien Letellier and Hossein Gorji},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=xrRIwEQJ5D}\\n}"},"paperhash":{"value":"dakhmouche|can_linear_probes_measure_llm_uncertainty_"}},"id":"xrRIwEQJ5D","forum":"xrRIwEQJ5D","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission140/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission140/Authors"],"number":140,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission140/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757109537707,"cdate":1757109537707,"tmdate":1764510127369,"mdate":1764510127369,"pdate":1764306359185,"odate":1764510127352,"version":2},{"content":{"title":{"value":"Deep Learning for Solving Linear Integral Equations Associated with Markov Chains"},"authors":{"value":["Yanlin Qu","Jose Blanchet","Peter Glynn"]},"authorids":{"value":["~Yanlin_Qu1","~Jose_Blanchet1","~Peter_Glynn2"]},"keywords":{"value":["Markov chains","deep learning","Lyapunov functions","Poisson’s equation","stationary distributions","first-transition analysis"]},"abstract":{"value":"Linear integral equations are central to the analysis of general state-space Markov chains; solving them leads to Lyapunov functions (drift equation), the central limit theorem (Poisson’s equation), and stationary distributions (global balance equation). This paper develops a simple, simulator-based procedure that solves such equations by training a neural network to minimize a squared residual estimated via an unbiased “double-sample’’ loss of one-step transitions. The method does not require access to stationary distributions or long trajectories, and it extends to non-compact state spaces through a first-return decomposition that localizes training. A queueing case study demonstrates accuracy and robustness relative to Monte Carlo baselines."},"pdf":{"value":"/pdf/b48b25757b1ac4a4aa0808da7bfb1afd96a4d3e9.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nqu2025deep,\\ntitle={Deep Learning for Solving Linear Integral Equations Associated with Markov Chains},\\nauthor={Yanlin Qu and Jose Blanchet and Peter Glynn},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=dcheIPEuoo}\\n}"},"paperhash":{"value":"qu|deep_learning_for_solving_linear_integral_equations_associated_with_markov_chains"}},"id":"dcheIPEuoo","forum":"dcheIPEuoo","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission136/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission136/Authors"],"number":136,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission136/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757107457555,"cdate":1757107457555,"tmdate":1764510127299,"mdate":1764510127299,"pdate":1764306359000,"odate":1764510127284,"version":2},{"content":{"title":{"value":"Human-AI Interaction in Product Recommendation"},"authors":{"value":["Jing Dong","Prakirt Jhunjhunwala","Yash Kanoria"]},"authorids":{"value":["~Jing_Dong2","~Prakirt_Jhunjhunwala1","~Yash_Kanoria1"]},"keywords":{"value":["Human-AI Interaction","Rational Inattention"]},"TLDR":{"value":"We formally characterize, in an e-commerce setting, the optimal trade-off between the infromation provided by the user and the number of recommendations by an AI agent to maximize overall utility under cognitive costs."},"abstract":{"value":"We study the strategic interaction between a user and an AI agent in product recommendation. The user conveys preferences through a costly, noisy message, incurring cognitive communication cost, while the agent interprets this signal to form a posterior belief and provides a set of  recommendations that balances the diversity in the recommendation with the search cost incurred by the user to evaluate the recommendations. The objective is to optimally trade off the utility the user derives from the best recommendation against communication and search costs, modeled through a rational inattention framework. Our main contribution is a formal characterization of the optimal interaction strategy, derived through a high-dimensional approximation that yields the near-optimal trade-off between utility and costs. We show how the optimal strategy depends on feature-space dimension and cost parameters, and we identify distinct regimes where the balance between communication and search shifts sharply. A key insight from our result is that, even in high dimensional setting, the optimal strategy cannot rely only on communication or search in isolation. Instead, both mechanism must be jointly optimized to achieve high utility."},"pdf":{"value":"/pdf/a565d3208052b12c25cc6213f26e0ca98d03e718.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndong2025humanai,\\ntitle={Human-{AI} Interaction in Product Recommendation},\\nauthor={Jing Dong and Prakirt Jhunjhunwala and Yash Kanoria},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=eelx5yaoUu}\\n}"},"paperhash":{"value":"dong|humanai_interaction_in_product_recommendation"}},"id":"eelx5yaoUu","forum":"eelx5yaoUu","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission135/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission135/Authors"],"number":135,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission135/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757107370280,"cdate":1757107370280,"tmdate":1764510127257,"mdate":1764510127257,"pdate":1764306358857,"odate":1764510127238,"version":2},{"content":{"title":{"value":"A Covering Framework for Offline POMDPs Learning using Belief Space Metric"},"authors":{"value":["Youheng Zhu","Yiping Lu"]},"authorids":{"value":["~Youheng_Zhu1","~Yiping_Lu1"]},"keywords":{"value":["POMDP","Covering Number"]},"abstract":{"value":"In off‑policy evaluation (OPE) for partially observable Markov decision processes (POMDPs), an agent must infer hidden states from past observations, which exacerbates both the curse of horizon and the curse of memory in existing OPE methods. This paper introduces a novel covering analysis framework that exploits the intrinsic metric structure of the belief space (distributions over latent states) to relax traditional coverage assumptions. By focusing on the policies with stability property, we derive error bounds that mitigate exponential blow-ups in horizon and memory length. Our unified analysis technique applies to a broad class of OPE algorithms, yielding concrete error bounds and coverage requirements expressed in terms of belief space metrics rather than raw history coverage. We illustrate the improved sample efficiency of this framework via case studies: the double sampling Bellman error minimization algorithm, and the memory-based future-dependent value functions (FDVF). In both cases, our coverage definition based on the belief‐space metric yields tighter bounds."},"pdf":{"value":"/pdf/7cd9cef3327ee7f4516070413f1b73506b279777.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhu2025a,\\ntitle={A Covering Framework for Offline {POMDP}s Learning using Belief Space Metric},\\nauthor={Youheng Zhu and Yiping Lu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=fnCOYJUU4B}\\n}"},"paperhash":{"value":"zhu|a_covering_framework_for_offline_pomdps_learning_using_belief_space_metric"}},"id":"fnCOYJUU4B","forum":"fnCOYJUU4B","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission134/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission134/Authors"],"number":134,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission134/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757104475218,"cdate":1757104475218,"tmdate":1764510127257,"mdate":1764510127257,"pdate":1764306358748,"odate":1764510127236,"version":2},{"content":{"title":{"value":"Mechanistic Modeling of Social Conditions in Disease-Prediction Simulations via Copula-Informed Probabilistic Graphical Models: HIV Case Study"},"authors":{"value":["Amir Khosheghbal","Peter Haas","Chaitra Gopalappa"]},"authorids":{"value":["~Amir_Khosheghbal1","~Peter_Haas1","~Chaitra_Gopalappa1"]},"keywords":{"value":["Graphical models","Machine learning","Copula","Social determinants of health","Simulation","Infectious diseases"]},"TLDR":{"value":"Copula-informed probabilistic graphical modeling to estimate multivariate joint distributions from univariate marginals."},"abstract":{"value":"This work has already been published; here, we provide a brief overview [1]. Epidemic models typically simulate the spread of diseases as functions of behaviors, e.g., sexual and care behaviors for sexually transmitted diseases. However, multilevel factors, including poverty, housing or food insecurity, mental health, substance use disorder, etc., which are called social determinants of health (SDH), are drivers of those behaviors. There is increasing awareness of the need to incorporate SDH into epidemic simulation models to evaluate structural interventions alongside behavioral interventions. However, the multivariate joint associations between SDH and behaviors needed for modeling are not available. Data for SDH are mostly available as county-level marginal distributions, and associations between SDH and behaviors are mostly bivariate. To address this problem, we combine copula theory and probabilistic graphical models to estimate multivariate joint distributions. We estimate bivariate associations between SDH using a novel copula approach that transitions from continuous to discrete copulas. We then use these bivariate associations—together with bivariate associations between SDH and behaviors from the literature—as links in an undirected graphical model to calculate the multivariate joint distributions. As a case study, we used the joint distributions to model HIV-risk related behaviors as function of SDH in a national-level HIV/AIDS (PATH 4.0) model and studied the impact of hypothetical 100% efficacious SDH interventions on HIV prevention. We found that this intervention could lead to a cumulative 10-year reduction of 29% in HIV incidence.\\n\\n[1] Khosheghbal, A., Haas, P.J. & Gopalappa, C. Mechanistic modeling of social conditions in disease-prediction simulations via copulas and probabilistic graphical models: HIV case study. Health Care Manag Sci 28, 28–49 (2025). https://doi.org/10.1007/s10729-024-09694-3"},"pdf":{"value":"/pdf/c13c5da72aa5d8170e872b7d57d0cf01ab474760.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkhosheghbal2025mechanistic,\\ntitle={Mechanistic Modeling of Social Conditions in Disease-Prediction Simulations via Copula-Informed Probabilistic Graphical Models: {HIV} Case Study},\\nauthor={Amir Khosheghbal and Peter Haas and Chaitra Gopalappa},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=8R9uyDEwYx}\\n}"},"paperhash":{"value":"khosheghbal|mechanistic_modeling_of_social_conditions_in_diseaseprediction_simulations_via_copulainformed_probabilistic_graphical_models_hiv_case_study"}},"id":"8R9uyDEwYx","forum":"8R9uyDEwYx","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission133/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission133/Authors"],"number":133,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission133/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757104325056,"cdate":1757104325056,"tmdate":1764510127228,"mdate":1764510127228,"pdate":1764306358684,"odate":1764510127213,"version":2},{"content":{"title":{"value":"Fine-Grained Prototype-Based Interpretability for Operational Text Classification"},"authors":{"value":["Bowen Wei","Jinhao Pan","Ziwei Zhu"]},"authorids":{"value":["~Bowen_Wei1","~Jinhao_Pan1","~Ziwei_Zhu1"]},"keywords":{"value":["Interpretability","Uncertainty","Text Classification"]},"abstract":{"value":"We study interpretable, decision-centric NLP for operational settings that require accountability and robustness under uncertainty. We introduce \\\\emph{ProtoLens}, a prototype-based model that produces fine-grained (sub-sentence) rationales aligned to semantically coherent prototypes, enabling principled integration with OR-style decision rules (e.g., cost- and risk-sensitive thresholds, audits, and overrides). Across text classification benchmarks, ProtoLens provides interpretable, human-aligned explanations while matching or exceeding competitive baselines."},"pdf":{"value":"/pdf/e007846301f1716444fcb0052a83b5bdf689d831.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwei2025finegrained,\\ntitle={Fine-Grained Prototype-Based Interpretability for Operational Text Classification},\\nauthor={Bowen Wei and Jinhao Pan and Ziwei Zhu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=2meGerPB2W}\\n}"},"paperhash":{"value":"wei|finegrained_prototypebased_interpretability_for_operational_text_classification"}},"id":"2meGerPB2W","forum":"2meGerPB2W","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission131/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission131/Authors"],"number":131,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission131/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757103731922,"cdate":1757103731922,"tmdate":1764510127123,"mdate":1764510127123,"pdate":1764306358544,"odate":1764510127107,"version":2},{"content":{"title":{"value":"SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making"},"authors":{"value":["Yinsheng Wang","Tario G You","Léonard Boussioux","Shan Liu"]},"authorids":{"value":["~Yinsheng_Wang1","~Tario_G_You1","~Léonard_Boussioux1","~Shan_Liu1"]},"keywords":{"value":["Large Language Models","Optimization","Decision-Making"]},"TLDR":{"value":"This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs)."},"abstract":{"value":"This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains."},"pdf":{"value":"/pdf/5a72f242e570d7109afab7ba78f901e5561b67f9.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwang2025solid,\\ntitle={{SOLID}: a Framework of Synergizing Optimization and {LLM}s for Intelligent Decision-Making},\\nauthor={Yinsheng Wang and Tario G You and L{\\\\'e}onard Boussioux and Shan Liu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=fIYFy2sTm8}\\n}"},"paperhash":{"value":"wang|solid_a_framework_of_synergizing_optimization_and_llms_for_intelligent_decisionmaking"}},"id":"fIYFy2sTm8","forum":"fIYFy2sTm8","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission130/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission130/Authors"],"number":130,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission130/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757102284345,"cdate":1757102284345,"tmdate":1764510127089,"mdate":1764510127089,"pdate":1764306358513,"odate":1764510127072,"version":2},{"content":{"title":{"value":"Structured Difference-of-Q via Orthogonal Learning"},"authors":{"value":["Defu Cao","Angela Zhou"]},"authorids":{"value":["~Defu_Cao1","~Angela_Zhou1"]},"keywords":{"value":["causal reinforcement learning","offline reinforecement learning","ad"]},"abstract":{"value":"Offline reinforcement learning is important in many settings with available observational data but the inability to deploy new policies online due to safety, cost, and other concerns. Many recent advances in causal inference and machine learning target estimation of \`\`causal contrast\\" functions such as CATE, which is sufficient for optimizing decisions and can adapt to potentially smoother structure. We develop a dynamic generalization of the R-learner \\\\citep{nie2021learning,lewis2021double} for estimating and optimizing the difference of $Q^\\\\pi$-functions, $Q^\\\\pi(s,a)-Q^\\\\pi(s,a_0)$, for potential discrete-valued actions $a,a_0$, which can be used to optimize multiple-valued actions without loss of generality. We leverage orthogonal estimation to improve convergence rates, even if $Q$ and behavior policy (so-called nuisance functions) converge at slower rates and prove consistency of policy optimization under a margin condition. The method can leverage black-box  estimators of the $Q$-function and behavior policy to target estimation of a more structured $Q$-function contrast, and comprises of simple squared-loss minimization."},"pdf":{"value":"/pdf/a37fa6c7e4892ad0ea1fc08a9ea5f02fbb16ee29.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ncao2025structured,\\ntitle={Structured Difference-of-Q via Orthogonal Learning},\\nauthor={Defu Cao and Angela Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=xmU0tLDMCA}\\n}"},"paperhash":{"value":"cao|structured_differenceofq_via_orthogonal_learning"}},"id":"xmU0tLDMCA","forum":"xmU0tLDMCA","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission129/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission129/Authors"],"number":129,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission129/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757101158174,"cdate":1757101158174,"tmdate":1764510127064,"mdate":1764510127064,"pdate":1764306358437,"odate":1764510127049,"version":2},{"content":{"title":{"value":"Robust Strategic Classification under Decision-Dependent Cost Uncertainty"},"authors":{"value":["Sura Alhanouti","Guzin Bayraksan","Parinaz Naghizadeh"]},"authorids":{"value":["~Sura_Alhanouti1","~Guzin_Bayraksan1","~Parinaz_Naghizadeh1"]},"keywords":{"value":["Robust optimization","Decision-dependent Uncertainty","Strategic Classification","Strategic Machine learning","Game theory."]},"TLDR":{"value":"We study the classification of rational agents who strategically modify their inputs in response to algorithmic systems, incurring a cost that depends on the classifiers' decision."},"abstract":{"value":"Humans have been found to manipulate their inputs to algorithmic decision systems to receive favorable outcomes. This has motivated a line of work on \`\`strategic classification,'' wherein algorithmic decision rules are selected to prevent undesirable strategic responses. Prior works typically assume that the cost of such strategic behavior is fixed and independent of the classifier's decision. In practice, however, manipulation costs depend on past decisions: today's algorithmic decisions influence tomorrow's costs of strategic response. To capture this dependency, we propose to formulate the problem of strategic classification as a two-stage robust optimization problem with a decision-dependent uncertainty set. We formalize this problem, develop approximations and reformulations to solve it, and numerically illustrate our algorithm's ability to mitigate gaming of the algorithmic system."},"pdf":{"value":"/pdf/8a9ef15449ead3a81025084e30c746ed386b099b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nalhanouti2025robust,\\ntitle={Robust Strategic Classification under Decision-Dependent Cost Uncertainty},\\nauthor={Sura Alhanouti and Guzin Bayraksan and Parinaz Naghizadeh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=t8NeQQby18}\\n}"},"paperhash":{"value":"alhanouti|robust_strategic_classification_under_decisiondependent_cost_uncertainty"}},"id":"t8NeQQby18","forum":"t8NeQQby18","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission128/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission128/Authors"],"number":128,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission128/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757099376962,"cdate":1757099376962,"tmdate":1764510127036,"mdate":1764510127036,"pdate":1764306358361,"odate":1764510127020,"version":2},{"content":{"title":{"value":"A Deep Proactive Exploration Policy Based on Asymptotic Statistics for Asynchronous Q-Learning"},"authors":{"value":["Xinbo Shi","Jinyang Jiang","Ruihan Zhou","Yijie Peng","Jing Dong"]},"authorids":{"value":["~Xinbo_Shi1","~Jinyang_Jiang1","~Ruihan_Zhou1","~Yijie_Peng1","~Jing_Dong2"]},"keywords":{"value":["Q-learning","exploration policy","central limit theorem","deep learning"]},"TLDR":{"value":"Deep proactive learning for Q-learning exploration policy"},"abstract":{"value":"This paper presents a new methodology that adaptively optimizes exploration policy for the reinforcement learning problem. We shift the objective from value-function accuracy to direct policy identification, using the probability of correct selection as a metric. We establish a new central limit theorem for asynchronous Q-learning with adaptive step sizes and propose a regularized signal-to-noise ratio index for exploration policy designing. To address the computational cost of the high-dimensional optimization, we propose a novel pipeline with an offline, simulation-based proactive learning loop. This loop trains a deep neural network to serve as a fast, low-dimensional proxy for the complex optimization problem, allowing for efficient online policy updates in real-world applications. We validate our approach on the challenging RiverSwim environment, demonstrating superior performance compared to standard exploration heuristics."},"pdf":{"value":"/pdf/e4c8b8b16c5e0a9b98b548a7824bb70014da9991.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nshi2025a,\\ntitle={A Deep Proactive Exploration Policy Based on Asymptotic Statistics for Asynchronous Q-Learning},\\nauthor={Xinbo Shi and Jinyang Jiang and Ruihan Zhou and Yijie Peng and Jing Dong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=YuabDvTEzd}\\n}"},"paperhash":{"value":"shi|a_deep_proactive_exploration_policy_based_on_asymptotic_statistics_for_asynchronous_qlearning"}},"id":"YuabDvTEzd","forum":"YuabDvTEzd","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission125/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission125/Authors"],"number":125,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission125/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757097973385,"cdate":1757097973385,"tmdate":1764510126908,"mdate":1764510126908,"pdate":1764306358197,"odate":1764510126875,"version":2},{"content":{"title":{"value":"Human-Centric Perishable Inventory Management with AI-Assistance"},"authors":{"value":["Yu Nu","Meng Qi","Karan Girotra","Elena Belavina"]},"authorids":{"value":["~Yu_Nu1","~Meng_Qi1","girotra@cornell.edu","belavina@cornell.edu"]},"keywords":{"value":["Perishable inventory management","nonparametric estimation","behavioral operations","human-AI interaction","machine learning"]},"TLDR":{"value":"We develop two AI decision-making assistants that support decision-making in human-centric perishable inventory systems."},"abstract":{"value":"Up to 20\\\\% of food purchased by restaurants is wasted before reaching customers, with commercial leftovers being the major contributor due to poor production planning. This study introduces two AI decision-making assistants that support perishable inventory management differently in human-centric commercial kitchens. We address the periodic review inventory control problem for perishable goods with a fixed shelf life and demand censoring in an offline, data-driven setting. One AI assistant leverages a data-driven prescriptive solution to the multi-period inventory control problem, directly telling how much a human decision maker should replenish for the upcoming season given past sales data. We justify this prescriptive assistant with associated performance guarantees. Building on the data-driven prescriptive solution, the second AI assistant is enhanced in terms of detecting potential human decision-making biases in managing perishable inventory. Using machine learning models, it identifies from past user behavior whether a human decision maker is biased in their inventory decision making, and (if so) what human bias likely accounts for. Through an online experiment with Prolific workers, we further investigate how human users react to the deployment of different forms of AI assistance and uncover factors influencing their effectiveness. Results show that both types of AI assistants, whether providing data-driven prescriptive solutions or bias detection, improve perishable inventory management performance for human decision-makers. Additionally, integrating bias detection with prescriptive solutions could foster greater human adherence to algorithmic recommendations."},"pdf":{"value":"/pdf/e55b69b3091a480d182bdac02f7e15860cd80f21.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnu2025humancentric,\\ntitle={Human-Centric Perishable Inventory Management with {AI}-Assistance},\\nauthor={Yu Nu and Meng Qi and Karan Girotra and Elena Belavina},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=zxaMZHF1JW}\\n}"},"paperhash":{"value":"nu|humancentric_perishable_inventory_management_with_aiassistance"}},"id":"zxaMZHF1JW","forum":"zxaMZHF1JW","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission123/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission123/Authors"],"number":123,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission123/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757096942512,"cdate":1757096942512,"tmdate":1764510126806,"mdate":1764510126806,"pdate":1764306358040,"odate":1764510126781,"version":2},{"content":{"title":{"value":"Achieving $\\\\widetilde{\\\\mathcal O}(1/N)$ Optimality Gap in Weakly-Coupled Markov Decision Processes through Gaussian Approximation"},"authors":{"value":["Chen YAN","Weina Wang","Lei Ying"]},"authorids":{"value":["~Chen_YAN3","~Weina_Wang1","~Lei_Ying1"]},"keywords":{"value":["Markov Decision Processes","Gaussian Approximation","Stochastic Optimization"]},"TLDR":{"value":"We propose an SP-based policy for finite-horizon WCMDPs that achieves an $\\\\widetilde{\\\\mathcal O}(1/N)$ gap, overcoming the $\\\\mathcal{O}(1/\\\\sqrt{N})$ limits of LP-based methods in degenerate regimes."},"abstract":{"value":"We study finite-horizon weakly-coupled Markov decision processes (WCMDPs) with $N$ homogeneous agents, where each agent is modeled as an MDP. Prior work has shown that linear-programming-based (LP-based) policies, derived from the fluid approximation that captures the system’s mean dynamics, achieve an $\\\\mathcal{O}(1/\\\\sqrt{N})$ optimality gap per agent. In this paper, we present instances where this gap is in fact $\\\\Theta(1/\\\\sqrt{N})$.\\nWe further propose a novel stochastic-programming-based (SP-based) policy that, under a mild uniqueness assumption, achieves an $\\\\widetilde{\\\\mathcal O}(1/N)$ optimality gap per agent. Our approach constructs a Gaussian stochastic system centered around the fluid-optimal trajectory, capturing both the mean and the variance of the WCMDP dynamics. This results in a more accurate approximation than the fluid approximation. The policy is then obtained by solving a linear Gaussian stochastic program for this system.\\nTo the best of our knowledge, this is the first result to establish an $\\\\widetilde{\\\\mathcal O}(1/N)$ optimality gap for WCMDPs under a uniqueness assumption."},"pdf":{"value":"/pdf/167d48fbcdd0e5f45ac4e9d317031660ded6762a.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyan2025achieving,\\ntitle={Achieving \\\\\${\\\\textbackslash}widetilde\\\\{{\\\\textbackslash}mathcal O\\\\}(1/N)\\\\$ Optimality Gap in Weakly-Coupled Markov Decision Processes through Gaussian Approximation},\\nauthor={Chen YAN and Weina Wang and Lei Ying},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=xufNFlDoKj}\\n}"},"paperhash":{"value":"yan|achieving_\\\\widetilde\\\\mathcal_o1n_optimality_gap_in_weaklycoupled_markov_decision_processes_through_gaussian_approximation"}},"id":"xufNFlDoKj","forum":"xufNFlDoKj","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission122/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission122/Authors"],"number":122,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission122/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757096356300,"cdate":1757096356300,"tmdate":1764510126799,"mdate":1764510126799,"pdate":1764306357929,"odate":1764510126761,"version":2},{"content":{"title":{"value":"Deep Learning-Driven Contextual Stochastic Optimization for Real-Time Order Fulfillment"},"authors":{"value":["Tinghan Ye","Shuaicheng Tong","Changkun Guan","Beste Basciftci","Pascal Van Hentenryck"]},"authorids":{"value":["~Tinghan_Ye1","~Shuaicheng_Tong1","~Changkun_Guan1","~Beste_Basciftci1","~Pascal_Van_Hentenryck2"]},"keywords":{"value":["Optimization Proxy","Contextual Stochastic Optimization","Order Fulfillment","Real-Time Decision-Making","E-commerce Logistics"]},"abstract":{"value":"Order fulfillment optimization is a fundamental challenge in large-scale e-commerce, requiring real-time decisions for every incoming order. For enterprises with extensive fulfillment networks, selecting the optimal fulfillment plan demands balancing operational costs with strict service-level guarantees under uncertainty. To model this problem, this work introduces a two-stage contextual stochastic optimization framework explicitly capturing two sources of uncertainty, delivery timeliness and future inventory consumption. To enable real-time deployment in peak hours, where traditional solvers are computationally prohibitive, an optimization proxy is developed, training deep neural networks to approximate solutions of the underlying stochastic program with high fidelity. Computational experiments on a large-scale JD.com transactional dataset demonstrate that the proposed approach achieves orders-of-magnitude speedups compared to a state-of-the-art commercial solver while preserving similar solution quality. The results establish a scalable paradigm for real-time stochastic optimization in e-commerce logistics, bridging rigorous optimization with deep learning to deliver industrial-scale efficiency"},"pdf":{"value":"/pdf/3bd04f765404e12810a6c1d60ed91894fec42681.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nye2025deep,\\ntitle={Deep Learning-Driven Contextual Stochastic Optimization for Real-Time Order Fulfillment},\\nauthor={Tinghan Ye and Shuaicheng Tong and Changkun Guan and Beste Basciftci and Pascal Van Hentenryck},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=uhF4sYW6Nd}\\n}"},"paperhash":{"value":"ye|deep_learningdriven_contextual_stochastic_optimization_for_realtime_order_fulfillment"}},"id":"uhF4sYW6Nd","forum":"uhF4sYW6Nd","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission119/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission119/Authors"],"number":119,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission119/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757094495008,"cdate":1757094495008,"tmdate":1764510126630,"mdate":1764510126630,"pdate":1764306357773,"odate":1764510126559,"version":2},{"content":{"title":{"value":"Diffusion Generative Models meet Differential Privacy: A Theoretical Insight"},"authors":{"value":["Ziyu Huang","Wenpin Tang"]},"authorids":{"value":["~Ziyu_Huang2","~Wenpin_Tang1"]},"keywords":{"value":["Differential privacy","diffusion models","trustworthy AI","Generative Models"]},"TLDR":{"value":"This paper provides convergence analysis of  differentially private diffusion models, establishing Wasserstein-2 distance bounds for DP-SGD applied to score-matching objectives and revealing fundamental privacy-utility-dimensionality tradeoffs."},"abstract":{"value":"Score-based diffusion models have emerged as popular generative models trained on increasingly large datasets, yet they are often susceptible to attacks that can disclose sensitive information. To offer Differential Privacy (DP) guarantees, training these models for score-matching with DP-SGD has become a common solution. In this work, we study Differentially Private Diffusion Models (DPDM) both theoretically and empirically. We provide a quantitative $L^2$ rate of DP-SGD to its global optimum, leading to the first error analysis of diffusion models trained with DP-SGD. Our theoretical framework contributes to uncertainty quantification in generative AI systems, providing essential convergence guarantees for trustworthy decision-making applications that require both privacy preservation and reliability."},"pdf":{"value":"/pdf/ec4b87dd0f89240e7a0149dc9f75f8516086af22.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhuang2025diffusion,\\ntitle={Diffusion Generative Models meet Differential Privacy: A Theoretical Insight},\\nauthor={Ziyu Huang and Wenpin Tang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=6vDiFj3f6Z}\\n}"},"paperhash":{"value":"huang|diffusion_generative_models_meet_differential_privacy_a_theoretical_insight"}},"id":"6vDiFj3f6Z","forum":"6vDiFj3f6Z","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission118/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission118/Authors"],"number":118,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission118/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757094472970,"cdate":1757094472970,"tmdate":1764510126641,"mdate":1764510126641,"pdate":1764306357687,"odate":1764510126551,"version":2},{"content":{"title":{"value":"Understanding Scaling Laws via Neural Feature Learning Dynamics"},"authors":{"value":["Zihan Yao","Ruoyu Wu","Tianxiang Gao"]},"authorids":{"value":["~Zihan_Yao2","~Ruoyu_Wu3","~Tianxiang_Gao2"]},"keywords":{"value":["Scaling laws; Feature learning dynamics; Infinite-width and infinite-depth limit; Residual networks; Stochastic differential equations; Neural Tangent Kernel (NTK); Maximal update parameterization (μP)."]},"TLDR":{"value":"To understand when and why neural scaling laws succeed or fail, we analyze deep ResNets trained with SGD and show that, in the joint infinite-width–depth limit, their feature evolution is governed by a coupled forward–backward SDE system."},"abstract":{"value":"Recently, deep neural networks have revolutionized various domains, primarily due to their ability to consistently improve performance when scaling up resources, including model size, data, and compute, a phenomenon formalized as scaling laws. Yet, the theoretical basis of these principles remains unclear: why scaling works and when it breaks down. We address this gap by analyzing the feature learning dynamics of ResNets trained with SGD. In the joint infinite-width–depth limit, we show that feature evolution is governed by a coupled forward–backward stochastic system, which we term the \\\\textit{neural feature learning dynamic system}. This framework clarifies the mechanisms underlying scaling laws and offers a new mathematical tool for studying deep learning dynamics."},"pdf":{"value":"/pdf/205768d4ca72a3b15478ad9dafb4eb98d100daa7.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyao2025understanding,\\ntitle={Understanding Scaling Laws via Neural Feature Learning Dynamics},\\nauthor={Zihan Yao and Ruoyu Wu and Tianxiang Gao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=bQ9P1Z4wJW}\\n}"},"paperhash":{"value":"yao|understanding_scaling_laws_via_neural_feature_learning_dynamics"}},"id":"bQ9P1Z4wJW","forum":"bQ9P1Z4wJW","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission116/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission116/Authors"],"number":116,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission116/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757093515836,"cdate":1757093515836,"tmdate":1764510126462,"mdate":1764510126462,"pdate":1764306357462,"odate":1764510126444,"version":2},{"content":{"title":{"value":"Compound Poisson Limits in Weighted Bernoulli Congestion Games: Theory Meets Experiments"},"authors":{"value":["Ian Mac Kenney","Javiera Barrera","Roberto Cominetti"]},"authorids":{"value":["~Ian_Mac_Kenney1","~Javiera_Barrera1","~Roberto_Cominetti1"]},"keywords":{"value":["Compound Poisson","Congestion games","Wardrop equilibrium","Network flow"]},"TLDR":{"value":"Asymptotic convergence of Weighted Bernoulli Congestion Games"},"abstract":{"value":"Congestion games provide a key framework for modeling traffic in transporta-\\ntion networks. Cominetti et al. (2023) studied Bernoulli congestion games with\\nhomogeneous players and showed that Nash equilibria converge to Poisson ran-\\ndom variables linked to the Wardrop equilibrium of the nonatomic game. In this\\nwork, we extend this model to weighted Bernoulli congestion games, allowing\\nheterogeneous player weights. We have proven that arc loads and flows at equi-\\nlibrium converge to compound Poisson random variables, thereby strengthening\\nthe bridge between atomic and nonatomic models. We provided numerical ex-\\nperiments that further demonstrate that even with a small number of players, the\\nequilibrium closely approximates the limiting behavior, highlighting the model’s\\nability to capture the natural stochasticity of traffic flows."},"pdf":{"value":"/pdf/bce838d0774a625a1bdba9e55cfb2a5b5583614f.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkenney2025compound,\\ntitle={Compound Poisson Limits in Weighted Bernoulli Congestion Games: Theory Meets Experiments},\\nauthor={Ian Mac Kenney and Javiera Barrera and Roberto Cominetti},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=LB6HI4G93E}\\n}"},"paperhash":{"value":"kenney|compound_poisson_limits_in_weighted_bernoulli_congestion_games_theory_meets_experiments"}},"id":"LB6HI4G93E","forum":"LB6HI4G93E","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission115/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission115/Authors"],"number":115,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission115/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757092686221,"cdate":1757092686221,"tmdate":1764510126423,"mdate":1764510126423,"pdate":1764306357382,"odate":1764510126386,"version":2},{"content":{"title":{"value":"Q-learning with Posterior Sampling"},"authors":{"value":["Priyank Agrawal","Shipra Agrawal","Azmat Azati"]},"authorids":{"value":["~Priyank_Agrawal1","~Shipra_Agrawal1","~Azmat_Azati1"]},"keywords":{"value":["Q-learning","regret bounds","online reinforcement learning","reinforcement learning theory","posterior sampling","TD-learning"]},"TLDR":{"value":"Near optimal regret bounds for Q-learning with posterior sampling algorithm in a tabular episodic RL setting"},"abstract":{"value":"Bayesian posterior sampling techniques have demonstrated superior empirical performance in many exploration-exploitation settings. However, their theoretical analysis remains a challenge, especially in complex settings like reinforcement learning.\\nIn this paper, we introduce Q-Learning with Posterior Sampling (PSQL), a simple Q-learning-based algorithm that uses Gaussian posteriors on Q-values for exploration, akin to the popular Thompson Sampling algorithm in the multi-armed bandit setting. We show that in the tabular episodic MDP setting, PSQL achieves a regret bound of $\\\\tilde O(H^2\\\\sqrt{SAT})$, closely matching the known lower bound of $\\\\Omega(H\\\\sqrt{SAT})$. Here, S, A denote the number of states and actions in the underlying Markov Decision Process (MDP), and $T=KH$ with $K$ being the number of episodes and $H$ being the planning horizon. Our work provides several new technical insights into the core challenges in combining posterior sampling with dynamic programming and TD-learning-based RL algorithms, along with novel ideas for resolving those difficulties. We hope this will form a starting point for analyzing this efficient and important algorithmic technique in even more complex RL settings."},"pdf":{"value":"/pdf/c8c18dacdb2d840e25ffc76aca62ad4181a39c6e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nagrawal2025qlearning,\\ntitle={Q-learning with Posterior Sampling},\\nauthor={Priyank Agrawal and Shipra Agrawal and Azmat Azati},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=XUca2I1n8C}\\n}"},"paperhash":{"value":"agrawal|qlearning_with_posterior_sampling"}},"id":"XUca2I1n8C","forum":"XUca2I1n8C","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission114/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission114/Authors"],"number":114,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission114/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757092351443,"cdate":1757092351443,"tmdate":1764510126245,"mdate":1764510126245,"pdate":1764306357306,"odate":1764510126225,"version":2},{"content":{"title":{"value":"Overfitting in Adaptive Robust Optimization"},"authors":{"value":["Karl Zhu","Dimitris Bertsimas"]},"authorids":{"value":["~Karl_Zhu1","~Dimitris_Bertsimas1"]},"keywords":{"value":["Adaptive Robust Optimization","Overfitting","Regularization","Uncertainty Sets","Probabilistic Guarantees"]},"TLDR":{"value":"We show that adaptive robust optimization can overfit its uncertainty set, and propose a regularization perspective with constraint-dependent guarantees to mitigate brittleness."},"abstract":{"value":"Adaptive robust optimization (ARO) extends static robust optimization by allowing decisions to depend on the realized uncertainty - weakly dominating static solutions within the modeled uncertainty set.  However, ARO makes previous constraints that were independent of uncertainty now dependent, making it vulnerable to additional infeasibilities when realizations fall outside the uncertainty set. This phenomenon of adaptive policies being brittle is analogous to overfitting in machine learning. To mitigate against this, we propose assigning constraint-specific uncertainty set sizes, with harder constraints given stronger probabilistic guarantees. Interpreted through the overfitting lens, this acts as regularization: tighter guarantees shrink adaptive coefficients to ensure stability, while looser ones preserve useful flexibility. This view motivates a principled approach to designing uncertainty sets that balances robustness and adaptivity."},"pdf":{"value":"/pdf/f42d8b6fde87f7c9e4edbe3e1f1a1ba84fb83d01.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhu2025overfitting,\\ntitle={Overfitting in Adaptive Robust Optimization},\\nauthor={Karl Zhu and Dimitris Bertsimas},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=hyjBrnjCK7}\\n}"},"paperhash":{"value":"zhu|overfitting_in_adaptive_robust_optimization"}},"id":"hyjBrnjCK7","forum":"hyjBrnjCK7","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission111/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission111/Authors"],"number":111,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission111/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757087660146,"cdate":1757087660146,"tmdate":1764510126162,"mdate":1764510126162,"pdate":1764306356991,"odate":1764510126134,"version":2},{"content":{"title":{"value":"Ensuring Fairness in Priority-Based Admissions with Uncertain Scores"},"authors":{"value":["Zhiqiang Zhang","Pengyi Shi","Amy R Ward"]},"authorids":{"value":["~Zhiqiang_Zhang21","~Pengyi_Shi1","~Amy_R_Ward1"]},"keywords":{"value":["decision making under uncertainty","fairness-aware optimization","priority-based admissions","uncertainty quantification"]},"TLDR":{"value":"We provide a framework to prevent fairness interventions in priority-based admissions from backfiring due to ML error by statistically quantifying the uncertainty of both the systemic fairness adjustment direction and individual decisions."},"abstract":{"value":"Priority-based admission policies are widely used to determine who can access scarce resources. Such policies assign scores to arriving individuals and prioritize those with higher scores for admission. Ideally, the resources yield greater benefits for individuals with higher scores, while the scores also provide a mechanism for ensuring fairness in resource access, according to some agreed-upon metric. The core problem is that scores must be estimated from historical data, and so are prone to estimation error. As a result, well-intentioned interventions to promote fairness can backfire. Our contribution is to provide a framework for analytically adjusting these estimated scores, ensuring that fairness interventions are implemented with a high degree of confidence."},"pdf":{"value":"/pdf/b114fbb5216c2d2be8c63fabf80d617b9d8ba953.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhang2025ensuring,\\ntitle={Ensuring Fairness in Priority-Based Admissions with Uncertain Scores},\\nauthor={Zhiqiang Zhang and Pengyi Shi and Amy R Ward},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=XMZgZfBTwv}\\n}"},"paperhash":{"value":"zhang|ensuring_fairness_in_prioritybased_admissions_with_uncertain_scores"}},"id":"XMZgZfBTwv","forum":"XMZgZfBTwv","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission110/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission110/Authors"],"number":110,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission110/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757084991544,"cdate":1757084991544,"tmdate":1764510126098,"mdate":1764510126098,"pdate":1764306356879,"odate":1764510126075,"version":2},{"content":{"title":{"value":"Towards Efficient Foundation Model: A Novel Time Series Embedding"},"authors":{"value":["Jessy Xinyi Han","Arth Dharaskar","Nathaniel Lanier","Abdullah Omar Alomar","Aditya Agrawal","Angela Yuan","Jocelyn Hsieh","Ishan Shah","Muhammad Jehangir Amjad","Devavrat Shah"]},"authorids":{"value":["~Jessy_Xinyi_Han1","~Arth_Dharaskar1","~Nathaniel_Lanier1","~Abdullah_Omar_Alomar1","~Aditya_Agrawal2","~Angela_Yuan2","~Jocelyn_Hsieh1","~Ishan_Shah1","~Muhammad_Jehangir_Amjad1","~Devavrat_Shah1"]},"keywords":{"value":["Time Series Foundation Models","Time Series Embeddings","Time Series Classification"]},"TLDR":{"value":"We introduce a universal image-based time series embedding that rivals TimesFM on synthetic benchmarks while being far more resource-efficient, offering a lightweight alternative encoder for foundation models."},"abstract":{"value":"Time Series Foundation Model (TSFM) learns appropriate embeddings from pre-training data and uses them to embed the input time series for in-context learning to produce forecast. TSFM requires rich pre-training dataset and large computational resources to learn effective embeddings. In contrast, traditional time series modeling paradigm generates forecast for a given time series by fitting one of many pre-determined models and using the best of them to produce a forecast. Though resource efficient, it suffers from inability to utilize the pre-training data along with the challenges involved in the best model selection. In this work, we are motivated to bring the best of both worlds together to enable resource efficient TSFM approach. Towards that, we introduce a novel embedding of time series of any length and scale by mapping them to unit square (i.e $[0, 1]^2$) or equivalently a 2D image. To evaluate its efficacy compared to embedding from a TSFM, we consider the task of model identification or classification for dataset where each time series is generated from one of many pre-determined model class. We find that the performance of the proposed embeddings is comparable to that of embeddings from a pre-trained TSFM, but at a fraction of resource requirement. This suggests an alternative architectural possibility for a compute efficient TSFM."},"pdf":{"value":"/pdf/27657e7317d7b0232282a22703fa22047d3a331d.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhan2025towards,\\ntitle={Towards Efficient Foundation Model: A Novel Time Series Embedding},\\nauthor={Jessy Xinyi Han and Arth Dharaskar and Nathaniel Lanier and Abdullah Omar Alomar and Aditya Agrawal and Angela Yuan and Jocelyn Hsieh and Ishan Shah and Muhammad Jehangir Amjad and Devavrat Shah},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=16Z00qyZ8m}\\n}"},"paperhash":{"value":"han|towards_efficient_foundation_model_a_novel_time_series_embedding"}},"id":"16Z00qyZ8m","forum":"16Z00qyZ8m","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission108/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission108/Authors"],"number":108,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission108/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757083202717,"cdate":1757083202717,"tmdate":1764510126065,"mdate":1764510126065,"pdate":1764306356785,"odate":1764510126045,"version":2},{"content":{"title":{"value":"Self-Normalized Resets for Plasticity in Continual Learning"},"authors":{"value":["Adam Daniel Jozefiak","Vivek Farias"]},"authorids":{"value":["~Adam_Daniel_Jozefiak1","~Vivek_Farias1"]},"keywords":{"value":["Continual Learning","Plasticity Loss","Lifelong Learning","Neuron Resets"]},"abstract":{"value":"Plasticity Loss is an increasingly important phenomenon that refers to the empirical observation that as a neural network is continually trained on a sequence of changing tasks, its ability to adapt to a new task diminishes over time. We propose Self-Normalized Resets (SNR), which resets a neuron's weights when evidence indicates its firing rate has collapsed. Across a battery of continual learning problems and network architectures, we demonstrate that SNR consistently attains superior performance compared to its competitor algorithms. We establish the necessity of neuron-resets for mitigating plasticity loss by analyzing the task of learning a single ReLU neuron with gradient descent. Under an adversarial-target regime, an idealized SNR learns the target while regularization-based schemes can fail to learn. SNR’s reset-threshold is motivated by a simple hypothesis test for detecting inactive neurons. Seen through the lens of this hypothesis test, competing reset proposals yield suboptimal error rates in correctly detecting inactive neurons."},"pdf":{"value":"/pdf/980bebfca69723c343d602350f267406e4c53491.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njozefiak2025selfnormalized,\\ntitle={Self-Normalized Resets for Plasticity in Continual Learning},\\nauthor={Adam Daniel Jozefiak and Vivek Farias},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=AmrbrSnLB3}\\n}"},"paperhash":{"value":"jozefiak|selfnormalized_resets_for_plasticity_in_continual_learning"}},"id":"AmrbrSnLB3","forum":"AmrbrSnLB3","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission107/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission107/Authors"],"number":107,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission107/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757082335850,"cdate":1757082335850,"tmdate":1764510125993,"mdate":1764510125993,"pdate":1764306356723,"odate":1764510125970,"version":2},{"content":{"title":{"value":"Learning to Select and Rank from Choice-Based Feedback: A Simple Nested Approach"},"authors":{"value":["Junwen Yang","Yifan Feng"]},"authorids":{"value":["~Junwen_Yang1","~Yifan_Feng2"]},"keywords":{"value":["pure exploration","choice-based feedback","preference learning","dynamic assortments"]},"abstract":{"value":"We study a ranking and selection problem of learning from choice-based feedback with dynamic assortments. In this problem, a company sequentially displays a set of items to a population of customers and collects their choices as feedback. The only information available about the underlying choice model is that the choice probabilities are consistent with some unknown true strict ranking over the items. The objective is to identify, with the fewest samples, the most preferred item or the full ranking over the items at a high confidence level. We present novel and simple algorithms for both learning goals. In the first subproblem regarding best-item identification, we introduce an elimination-based algorithm, Nested Elimination (NE). In the more complex subproblem regarding full-ranking identification, we generalize NE and propose a divide-and-conquer algorithm, Nested Partition (NP). We provide strong characterizations of both algorithms through instance-specific and non-asymptotic bounds on the sample complexity. This is accomplished using an analytical framework that characterizes the system dynamics through analyzing a sequence of multidimensional random walks. We also establish a connection between our nested approach and the information-theoretic lower bounds. We thus show that NE is worst-case asymptotically optimal, and NP is optimal up to a constant factor. Finally, numerical experiments from both synthetic and real data corroborate our theoretical findings."},"pdf":{"value":"/pdf/d29252f5f532e800a7fa726f39216cff742c1aca.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyang2025learning,\\ntitle={Learning to Select and Rank from Choice-Based Feedback: A Simple Nested Approach},\\nauthor={Junwen Yang and Yifan Feng},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=BfxsJ0f3rQ}\\n}"},"paperhash":{"value":"yang|learning_to_select_and_rank_from_choicebased_feedback_a_simple_nested_approach"}},"id":"BfxsJ0f3rQ","forum":"BfxsJ0f3rQ","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission105/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission105/Authors"],"number":105,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission105/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757081229354,"cdate":1757081229354,"tmdate":1764510125953,"mdate":1764510125953,"pdate":1764306356571,"odate":1764510125925,"version":2},{"content":{"title":{"value":"Belief-Aware Inventory Control with Deep Mixture Models"},"authors":{"value":["Moritz Beck","Anh-Duy Pham"]},"authorids":{"value":["~Moritz_Beck1","~Anh-Duy_Pham1"]},"keywords":{"value":["Inventory Management","Mixture Models","Operations Research","POMDP"]},"TLDR":{"value":"This paper introduces a framework that combines deep mixture models with inven- tory optimization under uncertain demand, tackling key challenges at the intersec- tion of machine learning and operations research."},"abstract":{"value":"This paper introduces a framework that combines deep mixture models with inven-\\ntory optimization under uncertain demand, tackling key challenges at the intersec-\\ntion of machine learning and operations research. We propose deep neural mixture\\nmodels for demand forecasting that capture multimodal, bounded, and correlated\\npatterns while maintaining computational tractability for downstream optimization.\\nOur approach formulates inventory control as a partially observable Markov deci-\\nsion process (POMDP) where belief states over mixture components evolve via\\nBayesian updates. In order to enable practical implementation, we develop a belief\\nspace clustering approach using medoid clustering that reduces the belief space to\\na finite set of representative points. We provide theoretical guarantees including\\ncontraction properties of belief updates, Lipschitz continuity bounds, and explicit\\nperformance bounds under belief discretization. The framework supports diverse\\nneural architectures, including state-of-the-art deep learning time series forecasting\\nmodels. Experiments on real-world pharmaceutical demand data demonstrate that\\nthe method is computationally efficient and can lead to promising performance\\nwhen the forecasts are well calibrated."},"pdf":{"value":"/pdf/5e6439bc7630e10ebf8953d2f0df221bd7c78b4b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbeck2025beliefaware,\\ntitle={Belief-Aware Inventory Control with Deep Mixture Models},\\nauthor={Moritz Beck and Anh-Duy Pham},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=fWRckQwQ8K}\\n}"},"paperhash":{"value":"beck|beliefaware_inventory_control_with_deep_mixture_models"}},"id":"fWRckQwQ8K","forum":"fWRckQwQ8K","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission103/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission103/Authors"],"number":103,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission103/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757079415358,"cdate":1757079415358,"tmdate":1764510125890,"mdate":1764510125890,"pdate":1764306356569,"odate":1764510125874,"version":2},{"content":{"title":{"value":"RiskPO: Risk-based Policy Optimization with Verifiable Reward for LLM Post-Training"},"authors":{"value":["Tao Ren","Jinyang Jiang","Hui Yang","Wan Tian","Yijie Peng"]},"authorids":{"value":["~Tao_Ren2","~Jinyang_Jiang1","~Hui_Yang15","~Wan_Tian1","~Yijie_Peng1"]},"keywords":{"value":["RL","Risk based optimization","LLM post-training"]},"abstract":{"value":"Reinforcement Learning with Verifiable Reward has become a central paradigm for post-training Large Language Models (LLMs). Group Relative Policy Optimization (GRPO) with the mean-based objective suffers from limited exploration and reasoning gains. We propose Risk-based Policy Optimization (RiskPO), which leverages risk measures from Operations Research to address these issues. In particular, we introduce a Mixed Value-at-Risk objective and adopt a bundle-wise training scheme that bundles multiple questions to provide stable and informative signals. Numerical results show that RiskPO consistently outperforms GRPO and its variants across multiple mathematical reasoning benchmarks, achieving substantial improvements on both Pass@1 and Pass@k metrics. These results highlight the effectiveness of risk-based optimization in enhancing exploration and expanding the reasoning capabilities of LLMs."},"pdf":{"value":"/pdf/e60118add4f90a9de03636b04ddcba3c6c57ba12.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nren2025riskpo,\\ntitle={Risk{PO}: Risk-based Policy Optimization with Verifiable Reward for {LLM} Post-Training},\\nauthor={Tao Ren and Jinyang Jiang and Hui Yang and Wan Tian and Yijie Peng},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=8hxqmh25ZH}\\n}"},"paperhash":{"value":"ren|riskpo_riskbased_policy_optimization_with_verifiable_reward_for_llm_posttraining"}},"id":"8hxqmh25ZH","forum":"8hxqmh25ZH","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission101/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission101/Authors"],"number":101,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission101/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757077337279,"cdate":1757077337279,"tmdate":1764510125818,"mdate":1764510125818,"pdate":1764306356418,"odate":1764510125800,"version":2},{"content":{"title":{"value":"Hierarchical Implicit/Explicit Feedback Recommender System"},"authors":{"value":["Kody J. H. Law"]},"authorids":{"value":["~Kody_J._H._Law1"]},"keywords":{"value":["Recommender System","Partially observable Markov decision process","Bayesian experimental design","dialog systems"]},"TLDR":{"value":"We introduce the Mixed Slate Agent (MSA), which comprises an inner explicit feedback loop inside any standard implicit feedback recommender system -- together, this is called the Hierarchical Implicit/Explicit Feedback Recommender System (HIER)."},"abstract":{"value":"In the modern attention economy, ranking is a ubiquitous task–across relevant news feeds in social media, websites in search, products in e-commerce, music and movies in audio and video streaming services, etc. Actions (tasks) in task-oriented dialogue systems (TODS) can be viewed through this lens also. Current recommender systems often deliver ranked items only and feedback comes mostly from clicks, dwell-time, and other implicit feedback. They are therefore prone to wasting substantial resources on ambiguous items, especially when the target item is buried in a larger set of candidate items and the user needs to navigate multiple slates–this scenario is expected to become more prevalent with the next generation of resource-constrained wearable computing platforms, where TODS will be bandwidth-constrained and users will have a low tolerance for errors. We propose the Mixed-Slate Agent (MSA) method, which replaces the item-only slate with a mixed-slate including either a fixed or dynamic set of binary facet or attribute queries, selected by maximizing an acquisition function depending on the joint item/response belief state. A partially observable Markov decision process (POMDP) on the item belief-state formalises the dialog. This explicit feedback loop is used only for immediate disambiguation and is embedded inside any existing recommender system. The resulting method is called the Hierarchical Implicit/Explicit Feedback Recommender System (HIER). For $K$-element slates out of $N$ ranked items, our method can deliver up to a factor of $\\\\mathcal{O}(N\\\\log_2⁡K/  K\\\\log_2N)$ asymptotic improvement in scroll depth in comparison to the usual top-K approach. Numerical experiments on a toy problem, a realistic simulated goal-space environment, and real e-commerce and movie recommendation datasets demonstrate the impact of the method."},"pdf":{"value":"/pdf/22c70d9625788d9e8560aab6d14c0af544933d3e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlaw2025hierarchical,\\ntitle={Hierarchical Implicit/Explicit Feedback Recommender System},\\nauthor={Kody J. H. Law},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=WQZifU5q3Y}\\n}"},"paperhash":{"value":"law|hierarchical_implicitexplicit_feedback_recommender_system"}},"id":"WQZifU5q3Y","forum":"WQZifU5q3Y","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission100/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission100/Authors"],"number":100,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission100/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757076922352,"cdate":1757076922352,"tmdate":1764510125785,"mdate":1764510125785,"pdate":1764306356263,"odate":1764510125767,"version":2},{"content":{"title":{"value":"Quantifying policy uncertainty in generative flow networks with uncertain rewards"},"authors":{"value":["Ramón Dineth Nartallo-Kaluarachchi","Robert Manson-Sawko","Shashanka Ubaru","Dongsung Huh","Malgorzata J. Zimon","Lior Horesh"]},"authorids":{"value":["~Ramón_Dineth_Nartallo-Kaluarachchi1","~Robert_Manson-Sawko1","~Shashanka_Ubaru1","~Dongsung_Huh1","~Malgorzata_J._Zimon1","~Lior_Horesh1"]},"keywords":{"value":["uncertainty quantification","generative flow networks","polynomial chaos expansions"]},"TLDR":{"value":"A framework for quantifying uncertainty in GFlowNet policies stemming from uncertain rewards"},"abstract":{"value":"Generative flow networks are able to sample, via sequential construction, high-reward, complex objects according to a reward function. However, such reward functions are often approximated from noisy data leading to epistemic uncertainty in the learnt policy. We present an approach to quantify this uncertainty by constructing a surrogate model composed of a polynomial chaos expansion, fit on a small ensemble of trained flow networks. This model learns the relationship between reward functions, parametrised in a low-dimensional space, and the probability distributions over actions at each step along a trajectory. The surrogate model can then be used for inexpensive Monte Carlo sampling to estimate the uncertainty in the policy given uncertain rewards. We illustrate the performance of our approach on a Bayesian structure learning task, and compare it to a basic multilayer perceptron."},"pdf":{"value":"/pdf/33deea5a0d095f9edd92c2f4ce63bcc58888ea82.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnartallo-kaluarachchi2025quantifying,\\ntitle={Quantifying policy uncertainty in generative flow networks with uncertain rewards},\\nauthor={Ram{\\\\'o}n Dineth Nartallo-Kaluarachchi and Robert Manson-Sawko and Shashanka Ubaru and Dongsung Huh and Malgorzata J. Zimon and Lior Horesh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=68kzwj26t4}\\n}"},"paperhash":{"value":"nartallokaluarachchi|quantifying_policy_uncertainty_in_generative_flow_networks_with_uncertain_rewards"}},"id":"68kzwj26t4","forum":"68kzwj26t4","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission96/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission96/Authors"],"number":96,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission96/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757068031575,"cdate":1757068031575,"tmdate":1764510125634,"mdate":1764510125634,"pdate":1764306355962,"odate":1764510125616,"version":2},{"content":{"title":{"value":"Pure Exploration via Frank--Wolfe Self-Play"},"authors":{"value":["Xinyu Liu","Chao Qin","Wei You"]},"authorids":{"value":["~Xinyu_Liu37","~Chao_Qin1","~Wei_You3"]},"keywords":{"value":["pure exploration","zero-sum games","mixed-strategy equilibrium","Frank-Wolfe","differential inclusion"]},"TLDR":{"value":"We cast pure-exploration bandit problems as a two-player mixed-strategy game, and propose Frank–Wolfe Self-Play—simultaneous, one-hot, projection-free updates—with provable convergence via continuous-time Lyapunov (stochastic-approximation) analysis."},"abstract":{"value":"We study pure exploration in structured bandits through a game-theoretic lens. For a broad class of queries, the asymptotic instance complexity admits a maximin form that corresponds to a two-player zero-sum game: an experimenter who allocates measurements to rule out alternatives versus a skeptic who proposes them. Allowing the skeptic to mix turns this into a concave–convex saddle-point problem. This reformulation unlocks a simple, projection-free, tuning-free, bandit-friendly algorithm: Frank–Wolfe Self-Play, in which both players take one-hot Frank–Wolfe steps against the other's empirical mixed strategy. Our analysis proceeds via continuous-time dynamics: the limiting differential inclusion admits a Lyapunov function that decays exponentially, yielding a vanishing duality gap and convergence of the game value. We then embed the discrete updates into a perturbed flow and, using stochastic-approximation techniques, show that the game value converges. A linear-bandit case study highlights phenomena absent in unstructured settings—nonunique optima, optimal allocations with zero mass on the best arm, bilinear objectives, and boundary nonsmoothness—and shows how Frank–Wolfe Self-Play automatically discovers the correct solution where naive top-two/Thompson-style heuristics may fail. Overall, we offers a minimal modification to the classical Frank–Wolfe algorithm, which is provably optimal for pure exploration."},"pdf":{"value":"/pdf/ced8293727f6420d6ec933bb19e078198111c2de.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliu2025pure,\\ntitle={Pure Exploration via Frank--Wolfe Self-Play},\\nauthor={Xinyu Liu and Chao Qin and Wei You},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=l4QFYAtz0U}\\n}"},"paperhash":{"value":"liu|pure_exploration_via_frankwolfe_selfplay"}},"id":"l4QFYAtz0U","forum":"l4QFYAtz0U","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission95/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission95/Authors"],"number":95,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission95/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757063747325,"cdate":1757063747325,"tmdate":1764510125635,"mdate":1764510125635,"pdate":1764306355897,"odate":1764510125615,"version":2},{"content":{"title":{"value":"Follow-the-Perturbed-Leader for Decoupled Bandits: Best-of-Both-Worlds and Practicality"},"authors":{"value":["Chaiwon Kim","Jongyeong Lee","Min-hwan Oh"]},"authorids":{"value":["~Chaiwon_Kim1","~Jongyeong_Lee1","~Min-hwan_Oh1"]},"keywords":{"value":["Follow-the-Perturbed-Leader","Decoupled exploration and exploitation","Best-of-Both-Worlds"]},"TLDR":{"value":"We propose a practically efficient FTPL policy for decoupled MAB that achieves BOBW without convex optimization or resampling."},"abstract":{"value":"We study the decoupled multi-armed bandit (MAB) problem, where the learner selects one arm for exploration and one arm for exploitation in each round. The loss of the explored arm is observed but not counted, while the loss of the exploited arm is incurred without being observed. We propose a policy within the Follow-the-Perturbed-Leader (FTPL) framework using Pareto perturbations. Our policy achieves (near-)optimal regret regardless of the environment, i.e., Best-of-Both-Worlds (BOBW): constant regret in the stochastic regime, improving upon the optimal bound of the standard MABs, and minimax optimal regret in the adversarial regime. Moreover, our policy avoids both the optimization step required by the previous BOBW policy, Decoupled-Tsallis-INF [Rouyer and Seldin, 2020], and the resampling step that is typically necessary in FTPL. Consequently, it achieves substantial computational improvement, about $20$ times faster than Decoupled-Tsallis-INF, while demonstrating better empirical performance in both regimes."},"pdf":{"value":"/pdf/17bd1085e81b5897284c0ce6d38cc58bd600f35e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkim2025followtheperturbedleader,\\ntitle={Follow-the-Perturbed-Leader for Decoupled Bandits: Best-of-Both-Worlds and Practicality},\\nauthor={Chaiwon Kim and Jongyeong Lee and Min-hwan Oh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ZVTWeQUOrn}\\n}"},"paperhash":{"value":"kim|followtheperturbedleader_for_decoupled_bandits_bestofbothworlds_and_practicality"}},"id":"ZVTWeQUOrn","forum":"ZVTWeQUOrn","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission89/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission89/Authors"],"number":89,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission89/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757056066378,"cdate":1757056066378,"tmdate":1764510125424,"mdate":1764510125424,"pdate":1764306355585,"odate":1764510125407,"version":2},{"content":{"title":{"value":"Flow-based Conformal Prediction for Multi-dimensional Time Series"},"authors":{"value":["Junghwan Lee","Chen Xu","Yao Xie"]},"authorids":{"value":["~Junghwan_Lee3","~Chen_Xu12","~Yao_Xie2"]},"keywords":{"value":["Conformal Prediction","Time Series","Flow Models"]},"TLDR":{"value":"We propose a novel conformal prediction method for time series using flow with classifier-free guidance."},"abstract":{"value":"Time series prediction is a crucial task in sequential decision-making. With the increasing use of black-box models for time series prediction, the need for uncertainty quantification has become more critical. Conformal prediction has gained attention as a reliable uncertainty quantification framework. However, conformal prediction for time series faces two key challenges: (1) effectively leveraging sequential correlations in features and non-conformity scores, and (2) handling multi-dimensional outcomes. To address these challenges, we propose a novel conformal prediction method for time series using flow with classifier-free guidance. We provide theoretical guarantees by establishing an exact non-asymptotic marginal coverage and a finite-sample bound on conditional coverage for our method. Evaluations on real-world multi-dimensional time series datasets demonstrate that our method constructs significantly smaller prediction sets while maintaining target coverage, outperforming existing baselines."},"pdf":{"value":"/pdf/bc600c1e21c7fd2819a9e0220d939a089631ab5c.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlee2025flowbased,\\ntitle={Flow-based Conformal Prediction for Multi-dimensional Time Series},\\nauthor={Junghwan Lee and Chen Xu and Yao Xie},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=z2hzMjbHCT}\\n}"},"paperhash":{"value":"lee|flowbased_conformal_prediction_for_multidimensional_time_series"}},"id":"z2hzMjbHCT","forum":"z2hzMjbHCT","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission88/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission88/Authors"],"number":88,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission88/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757055487819,"cdate":1757055487819,"tmdate":1764510125420,"mdate":1764510125420,"pdate":1764306355432,"odate":1764510125405,"version":2},{"content":{"title":{"value":"Rebalancing and Clearance Pricing of Near-Expiry Inventory in Online Grocery Retail"},"authors":{"value":["Ziyuan Zhou","LONG HE","Zhengling Qi","Guangrui Ma","Yuanbo Peng","Yushu Yao","Zhongyi Zha","Mingyong Zhao","Zhenyu Zhuo"]},"authorids":{"value":["~Ziyuan_Zhou2","~LONG_HE1","~Zhengling_Qi1","~Guangrui_Ma3","pengyuanbo@meituan.com","yaoyushu@meituan.com","zhazhongyi@meituan.com","zhaomingyong@meituan.com","zhuozhenyu02@meituan.com"]},"keywords":{"value":["Inventory rebalancing","dynamic pricing","ML–OR integration","online grocery","perishable inventory","food waste"]},"abstract":{"value":"Perishable inventory management remains a critical challenge for online grocery retailers, where mismatches between demand and shelf life can lead to substantial financial losses and food waste. This article describes the development and deployment of an integrated, data-driven system for managing near-expiry (“red-line”) inventory across a nationwide network of micro-fulfillment centers (MFCs) operated by Meituan’s Little Elephant Supermarket. The system jointly optimizes nighttime inventory rebalancing and daytime clearance pricing using a closed-loop learning-and-optimization framework. It combines causal machine learning to estimate price elasticities, a linearized mixed-integer model for inventory rebalancing, and a Markov decision process for dynamic pricing. Since its rollout, the solution has reduced spoilage rates by 20\\\\%, increased revenue from red-line inventory by 14\\\\%, and improved annual profit by approximately 50 million CNY ($\\\\sim$ 7 million USD) as well as saved approximately 18 million CNY ($\\\\sim$ 2.5 million USD) in food waste, as measured across the entire operational network. Our work illustrates how aligning OR insights with adaptive ML tools can deliver scalable, interpretable, and uncertainty-aware decision systems, generating both economic and sustainability gains in complex retail operations."},"pdf":{"value":"/pdf/0c073eade789f14d86bd4b3912e602fc9576cf72.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhou2025rebalancing,\\ntitle={Rebalancing and Clearance Pricing of Near-Expiry Inventory in Online Grocery Retail},\\nauthor={Ziyuan Zhou and LONG HE and Zhengling Qi and Guangrui Ma and Yuanbo Peng and Yushu Yao and Zhongyi Zha and Mingyong Zhao and Zhenyu Zhuo},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ag4NlUaV0X}\\n}"},"paperhash":{"value":"zhou|rebalancing_and_clearance_pricing_of_nearexpiry_inventory_in_online_grocery_retail"}},"id":"ag4NlUaV0X","forum":"ag4NlUaV0X","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission86/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission86/Authors"],"number":86,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission86/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757053782979,"cdate":1757053782979,"tmdate":1764510125347,"mdate":1764510125347,"pdate":1764306355266,"odate":1764510125333,"version":2},{"content":{"title":{"value":"Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards"},"authors":{"value":["Wenlong Ji","Yihan Pan","Ruihao Zhu","Lihua Lei"]},"authorids":{"value":["~Wenlong_Ji1","~Yihan_Pan2","~Ruihao_Zhu2","~Lihua_Lei2"]},"keywords":{"value":["Multi-armed bandit","upper confidence bound","prediction powered inference","surrogate rewards"]},"abstract":{"value":"Multi-armed bandit (MAB) is a widely adopted framework for sequential decision-making under uncertainty. Traditional bandit algorithms rely solely on online data, which tends to be scarce as it must be gathered during the online phase when the arms are actively pulled. However, in many practical settings, rich auxiliary data, such as covariates of past users, is available prior to deploying any arms. We introduce a new setting for MAB where pre-trained machine learning (ML) models are applied to convert side information and historical data into \\\\emph{surrogate rewards}. A prominent feature of this setting is that the surrogate rewards may exhibit substantial bias, as true reward data is typically unavailable in the offline phase, forcing ML predictions to heavily rely on extrapolation. To address the issue, we propose the Machine Learning-Assisted Upper Confidence Bound (MLA-UCB) algorithm, which can be applied to any reward prediction model and any form of auxiliary data. When the predicted and true rewards are jointly Gaussian, it provably improves the cumulative regret, provided that the correlation is non-zero -- even in cases where the mean surrogate reward completely misaligns with the true mean rewards. Notably, our method requires no prior knowledge of the covariance matrix between true and surrogate rewards."},"pdf":{"value":"/pdf/031e85307b8660ad9cc8b5c39c1cb05e184b1b8f.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nji2025multiarmed,\\ntitle={Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards},\\nauthor={Wenlong Ji and Yihan Pan and Ruihao Zhu and Lihua Lei},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=f43NiUfcho}\\n}"},"paperhash":{"value":"ji|multiarmed_bandits_with_machine_learninggenerated_surrogate_rewards"}},"id":"f43NiUfcho","forum":"f43NiUfcho","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission83/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission83/Authors"],"number":83,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission83/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757045867114,"cdate":1757045867114,"tmdate":1764510125211,"mdate":1764510125211,"pdate":1764306355113,"odate":1764510125195,"version":2},{"content":{"title":{"value":"Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradient and AdamW"},"authors":{"value":["Di Zhang","Yihang Zhang","Suvrajeet Sen"]},"authorids":{"value":["~Di_Zhang12","~Yihang_Zhang6","~Suvrajeet_Sen1"]},"keywords":{"value":["LLMs Training","Stochastic Conjugate Subgradient","Beyond First Order"]},"TLDR":{"value":"Training LLMs with Stochastic Conjugate Subgradient and AdamW"},"abstract":{"value":"Algorithms based on Stochastic Gradient-based Descent (SGD), have long been central to training large language models (LLMs). However, their effectiveness can be questionable, particularly in large-scale applications where empirical evidence suggests potential performance limitations. In response, this paper proposes a stochastic conjugate subgradient method together with adaptive sampling tailored specifically for training LLMs. The method not only achieves faster convergence per iteration but also demonstrates improved scalability compared to traditional SGD techniques. It leverages several fundamental concepts including adaptive sample complexity analysis, an adaptive method to choose step-sizes, as well as a stochastic conjugate subgradient approach to determine search directions and utilizing an AdamW-like algorithm to adaptively adjust step sizes. This approach preserves the key advantages of first-order methods while effectively addressing non-smoothness inherent in training LLMs. Experimental results show that the proposed method not only maintains, but in many cases surpasses, the scalability of traditional SGD techniques, significantly enhancing both the speed and accuracy of the optimization process."},"pdf":{"value":"/pdf/80ddc1f0f0006d74d2b15808fc8481b9d165664e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhang2025beyond,\\ntitle={Beyond First-Order: Training {LLM}s with Stochastic Conjugate Subgradient and AdamW},\\nauthor={Di Zhang and Yihang Zhang and Suvrajeet Sen},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=KnuzHqCLww}\\n}"},"paperhash":{"value":"zhang|beyond_firstorder_training_llms_with_stochastic_conjugate_subgradient_and_adamw"}},"id":"KnuzHqCLww","forum":"KnuzHqCLww","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission81/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission81/Authors"],"number":81,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission81/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757043575349,"cdate":1757043575349,"tmdate":1764510125109,"mdate":1764510125109,"pdate":1764306355030,"odate":1764510125095,"version":2},{"content":{"title":{"value":"Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games"},"authors":{"value":["Yunhao Liang","Yuan Qu","Jingyuan Yang","Shaochong Lin","Zuo-Jun Shen"]},"authorids":{"value":["~Yunhao_Liang2","~Yuan_Qu2","~Jingyuan_Yang1","~Shaochong_Lin1","~Zuo-Jun_Shen1"]},"keywords":{"value":["Multi‑LLM Collaboration","Public Goods Games","Reinforcement Learning"]},"TLDR":{"value":"We propose MAC-SPGG, a game-theoretic RL framework that incentivizes scalable and robust cooperation among LLM agents via sequential public goods games."},"abstract":{"value":"Coordinating multiple large language models (LLMs) to solve complex tasks collaboratively poses a fundamental trade-off between the computation costs and collective performance compared with individual model. We introduce a novel, game-theoretically grounded reinforcement learning (RL) framework, the Multi-Agent Cooperation Sequential Public Goods Game (MAC-SPGG), to systematically incentivize cooperation in multi-LLM ensembles. In MAC-SPGG, LLM agents move in sequence, observing predecessors' outputs and updating beliefs to condition their own contributions. By redesigning the public-goods reward, effortful contributions become the unique Subgame Perfect Nash Equilibrium (SPNE), which eliminates free-riding under traditional SPGG or PGG. Its sequential protocol replaces costly round-based information exchanges with a streamlined decision flow, cutting communication overhead while retaining strategic depth. We prove the existence and uniqueness of the SPNE under realistic parameters, and empirically show that MAC-SPGG-trained ensembles outperform single-agent baselines, chain-of-thought prompting, and other cooperative methods, even achieving comparable performance to large-scale models across reasoning, math, code generation, and NLP tasks. Our results highlight the power of structured, incentive-aligned MAC-SPGG cooperation for scalable and robust multi-agent language generation."},"pdf":{"value":"/pdf/6ae4e1e028d0b4d389a7e44d33b0876ce92c6c2b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliang2025everyone,\\ntitle={Everyone Contributes! Incentivizing Strategic Cooperation in Multi-{LLM} Systems via Sequential Public Goods Games},\\nauthor={Yunhao Liang and Yuan Qu and Jingyuan Yang and Shaochong Lin and Zuo-Jun Shen},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=VPliNzOIgu}\\n}"},"paperhash":{"value":"liang|everyone_contributes_incentivizing_strategic_cooperation_in_multillm_systems_via_sequential_public_goods_games"}},"id":"VPliNzOIgu","forum":"VPliNzOIgu","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission80/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission80/Authors"],"number":80,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission80/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757043519170,"cdate":1757043519170,"tmdate":1764510125069,"mdate":1764510125069,"pdate":1764306354948,"odate":1764510125049,"version":2},{"content":{"title":{"value":"Perishable Online Inventory Control with Context-Aware Demand Distributions"},"authors":{"value":["Yuxiao Wen","Jingkai Huang","Weihua ZHOU","Zhengyuan Zhou"]},"authorids":{"value":["~Yuxiao_Wen1","~Jingkai_Huang1","~Weihua_ZHOU1","~Zhengyuan_Zhou2"]},"keywords":{"value":["online learning","inventory control","kernel regression","contextual bandits"]},"TLDR":{"value":"We study online contextual inventory control of perishable goods where the demand distribution can depend on contexts (and in a nonparametric way); then we give the minimax regret lower bound and a near-optimal algorithm."},"abstract":{"value":"We study the online contextual inventory control problem with perishable goods. We consider a more realistic---and more challenging---setting where the demand depends linearly on observable features (as is standard), but the (residual) noise distribution depends non-parametrically on the features. Surprisingly, little is known when the noise is context-dependent, which captures the heteroskedastic uncertainty in demand that is important in inventory control. Unfortunately, the optimal inventory quantity in this more general setting is no longer a linear function of features (as is the case in the standard setting), making online gradient descent---the gold standard therein---inapplicable. We first present a minimax regret lower bound $\\\\Omega(\\\\sqrt{d T}+T^{\\\\frac{p+1}{p+2}})$, which characterizes the fundamental limit of this learning problem. Here $d$ is the feature dimension, and $p \\\\leq d$ is an underlying dimension that captures the intrinsic complexity of the noise distribution. Further, we propose an algorithm achieves the near-optimal regret $\\\\widetilde{O}(\\\\sqrt{d T}+T^{\\\\frac{p+1}{p+2}})$. Additionally, under mild regularity conditions on the noise, we can achieve the improved $\\\\widetilde{O}(\\\\sqrt{d T} + p\\\\sqrt{T})$ regret. To our best knowledge, our results provide the first minimax optimal characterization for online inventory control with context-dependent noise."},"pdf":{"value":"/pdf/ffd170d4effdc5db92dbcc2d5974ac78eee8585a.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwen2025perishable,\\ntitle={Perishable Online Inventory Control with Context-Aware Demand Distributions},\\nauthor={Yuxiao Wen and Jingkai Huang and Weihua ZHOU and Zhengyuan Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=i1WEhRLDj5}\\n}"},"paperhash":{"value":"wen|perishable_online_inventory_control_with_contextaware_demand_distributions"}},"id":"i1WEhRLDj5","forum":"i1WEhRLDj5","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission78/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission78/Authors"],"number":78,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission78/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757042866378,"cdate":1757042866378,"tmdate":1764510125070,"mdate":1764510125070,"pdate":1764306354863,"odate":1764510125046,"version":2},{"content":{"title":{"value":"From Stacked Predictions to Decisions: A Contextual Optimization Approach"},"authors":{"value":["Yanru Guo","Ruiwei Jiang","Siqian Shen"]},"authorids":{"value":["yanruguo@umich.edu","~Ruiwei_Jiang1","~Siqian_Shen1"]},"keywords":{"value":["Contextual Optimization; Optimization Under Uncertainty; Stacking; Residual-based SAA"]},"TLDR":{"value":"We cast stacking as a contextual optimization problem and use an empirical residual-based sample average approximation (ER-SAA) pipeline to incorporate uncertainty into decision-making."},"abstract":{"value":"Optimization models and decision frameworks have seen increased use of the combination of multiple first-level learners using ensemble methods to improve predictive performance. In this work, we cast stacking as a contextual optimization problem, where a collection of $T$ first-level learners $\\\\{h_t\\\\}_{t=1}^{T}$ serve as context, a meta-learner estimates the target $Y$ conditional on this context, and decisions are selected to minimize the resulting conditional expected cost. We propose an empirical residual-based sample average approximation (ER-SAA) pipeline that incorporates the predictive uncertainty into the decision stage. Specifically, we (i) obtain out-of-sample first-level learners through cross-fitting, (ii) fit a meta-learner and estimate a possibly heteroskedastic scale map, and (iii) add back cross-fitted residuals as decision scenarios. This construction preserves stacking’s modeling flexibility and at the same time aligns learning with the conditional decision objective."},"pdf":{"value":"/pdf/29f33969010d3d284ce93f97ee87e0d4c420f99b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nguo2025from,\\ntitle={From Stacked Predictions to Decisions: A Contextual Optimization Approach},\\nauthor={Yanru Guo and Ruiwei Jiang and Siqian Shen},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=vyJmWcDTa0}\\n}"},"paperhash":{"value":"guo|from_stacked_predictions_to_decisions_a_contextual_optimization_approach"}},"id":"vyJmWcDTa0","forum":"vyJmWcDTa0","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission76/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission76/Authors"],"number":76,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission76/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757041627032,"cdate":1757041627032,"tmdate":1764510124978,"mdate":1764510124978,"pdate":1764306354658,"odate":1764510124964,"version":2},{"content":{"title":{"value":"End-to-End Learning for Information Gathering"},"authors":{"value":["Rares C Cristian","Pavithra Harsha","Georgia Perakis","Brian Quanz"]},"authorids":{"value":["~Rares_C_Cristian1","~Pavithra_Harsha1","~Georgia_Perakis1","~Brian_Quanz2"]},"keywords":{"value":["end-to-end learning","optimization","machine learning"]},"abstract":{"value":"This paper introduces an end-to-end, or joint prediction and optimization, framework for the class of two-stage contextual optimization problems with information-gathering. We showcase the approach on a dynamic electricity-scheduling problem on real data. We show that the adaptiveness of the end-to-end approach indeed provides benefits over other methods which train their forecasting method independently of the first information-gathering stage."},"pdf":{"value":"/pdf/4f6d0e6cdfbcd8a66919f142508db6f9286fbbc1.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ncristian2025endtoend,\\ntitle={End-to-End Learning for Information Gathering},\\nauthor={Rares C Cristian and Pavithra Harsha and Georgia Perakis and Brian Quanz},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=NVo6NWXR0a}\\n}"},"paperhash":{"value":"cristian|endtoend_learning_for_information_gathering"}},"id":"NVo6NWXR0a","forum":"NVo6NWXR0a","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission74/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission74/Authors"],"number":74,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission74/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757036486136,"cdate":1757036486136,"tmdate":1764510124906,"mdate":1764510124906,"pdate":1764306354555,"odate":1764510124891,"version":2},{"content":{"title":{"value":"MINTS: Minimalist Thompson Sampling"},"authors":{"value":["Kaizheng Wang"]},"authorids":{"value":["~Kaizheng_Wang1"]},"keywords":{"value":["Stochastic optimization","Bayesian method","profile likelihood","regret analysis"]},"abstract":{"value":"The Bayesian paradigm offers principled tools for sequential decision-making under uncertainty, but its reliance on a probabilistic model for all parameters can hinder the incorporation of complex structural constraints. We introduce a minimalist Bayesian framework that places a prior only on the location of the optimum. Nuisance parameters are eliminated via profile likelihood, which naturally handles constraints. As a direct instantiation, we develop a MINimalist Thompson Sampling (MINTS) algorithm. We further analyze MINTS for multi-armed bandits and establish near-optimal regret guarantees."},"pdf":{"value":"/pdf/dc70636301d7c33566f2819d55cb310e3ce879b7.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwang2025mints,\\ntitle={{MINTS}: Minimalist Thompson Sampling},\\nauthor={Kaizheng Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=bdU4TXlg35}\\n}"},"paperhash":{"value":"wang|mints_minimalist_thompson_sampling"}},"id":"bdU4TXlg35","forum":"bdU4TXlg35","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission73/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission73/Authors"],"number":73,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission73/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757036273739,"cdate":1757036273739,"tmdate":1764510124887,"mdate":1764510124887,"pdate":1764306354472,"odate":1764510124871,"version":2},{"content":{"title":{"value":"Distributionally Robust Multimodal Machine Learning"},"authors":{"value":["Peilin Yang","Yu Ma"]},"authorids":{"value":["~Peilin_Yang1","~Yu_Ma8"]},"keywords":{"value":["machine learning","distributionally robust optimization","multimodal learning"]},"TLDR":{"value":"Distributionally robust optimization for multimodal machine learning"},"abstract":{"value":"We consider the problem of distributionally robust multimodal machine learning. Existing approaches often rely on merging modalities on the feature level (early fusion) or heuristic uncertainty modeling, which downplays modality-aware effects and provide limited insights. We propose a novel distributionally robust optimization (DRO) framework that aims to study both the theoretical and practical insights of multimodal machine learning. We first justify this setup and show the significance of this problem through complexity analysis. We then establish both generalization upper bounds and minimax lower bounds which provide performance guarantees. These results are further extended in settings where we consider encoder-specific error propogations. Empirically, we demonstrate that our approach improves robustness in both simulation settings and real-world datasets. Together, these findings provide a principled foundation for employing multimodal machine learning models in high-stakes applications where uncertainty is unavoidable."},"pdf":{"value":"/pdf/128bc7da08a2247ca2ef11bfa87a6f81ca9531cc.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyang2025distributionally,\\ntitle={Distributionally Robust Multimodal Machine Learning},\\nauthor={Peilin Yang and Yu Ma},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=KOuUv5HJVX}\\n}"},"paperhash":{"value":"yang|distributionally_robust_multimodal_machine_learning"}},"id":"KOuUv5HJVX","forum":"KOuUv5HJVX","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission72/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission72/Authors"],"number":72,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission72/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757035256261,"cdate":1757035256261,"tmdate":1764510124841,"mdate":1764510124841,"pdate":1764306354442,"odate":1764510124823,"version":2},{"content":{"title":{"value":"Contextual Bandits for Large-Scale Structured Discrete Constrained Optimization Problems"},"authors":{"value":["Pavithra Harsha","Chitra K Subramanian","Naoki Abe","Shivaram Subramanian","Amadou Ba","Kevin Arturo Fernandez Roman","Mauricio Longinos Garrido","Miao Liu","Aurelie C. Lozano","Chandrasekhar Narayanaswami"]},"authorids":{"value":["~Pavithra_Harsha1","~Chitra_K_Subramanian1","~Naoki_Abe1","~Shivaram_Subramanian1","~Amadou_Ba1","~Kevin_Arturo_Fernandez_Roman1","~Mauricio_Longinos_Garrido1","~Miao_Liu1","~Aurelie_C._Lozano1","~Chandrasekhar_Narayanaswami1"]},"keywords":{"value":["Contextual bandits","regression oracles","mixed-integer programming (MIP)","diversity","solution pool","inverse gap weighing (IGW)"]},"TLDR":{"value":"We propose a regression-oracle and IGW-based framework for contextual bandits in combinatorial action spaces, using column generation, diverse solution pools, and a risk-averse strategy to cut regret in operations applications."},"abstract":{"value":"We study contextual bandits in high-dimensional combinatorial action spaces arising in structured constrained optimization problems, such as IT resource allocation and retail assortment pricing. Key quantities in the objective or constraints must be estimated from data during the trial sequence of actions. In [12], we propose a novel, practical, and transparent approach based on general-purpose regression oracles with Inverse Gap Weighting (IGW) for seamless integration within an optimization framework. IGW sampling is efficiently managed by: (a) a column-generation reformulation of the underlying Mixed Integer Programming (MIP) model which allows for flexible lower-level predictors, causal coherence, and efficient representation of large action spaces; (b) a diverse solution pool generation to balance the exploration-exploitation trade-off in large-action spaces. To address non-smooth rewards induced by constraints, we introduce a risk-averse phased learning strategy. Experiments on an IT auto-scaling task demonstrate substantial reductions in cumulative regret, with added gains from risk-averse methods that effectively manage constraint violations. This submission summarizes [12] and sketches our extensions towards a full theoretical regret analysis."},"pdf":{"value":"/pdf/1d3d672b33ca15c86708c51442790e8adaa535ed.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nharsha2025contextual,\\ntitle={Contextual Bandits for Large-Scale Structured Discrete Constrained Optimization Problems},\\nauthor={Pavithra Harsha and Chitra K Subramanian and Naoki Abe and Shivaram Subramanian and Amadou Ba and Kevin Arturo Fernandez Roman and Mauricio Longinos Garrido and Miao Liu and Aurelie C. Lozano and Chandrasekhar Narayanaswami},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=OwQmmMx7Bq}\\n}"},"paperhash":{"value":"harsha|contextual_bandits_for_largescale_structured_discrete_constrained_optimization_problems"}},"id":"OwQmmMx7Bq","forum":"OwQmmMx7Bq","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission71/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission71/Authors"],"number":71,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission71/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757025350012,"cdate":1757025350012,"tmdate":1764510124809,"mdate":1764510124809,"pdate":1764306354335,"odate":1764510124786,"version":2},{"content":{"title":{"value":"Distributionally Robust Regularization of Sparse Integer Programming Trained Learning Models"},"authors":{"value":["Sanjeeb Dash","Soumyadip Ghosh","Joao Goncalves","Mark S. Squillante"]},"authorids":{"value":["~Sanjeeb_Dash1","~Soumyadip_Ghosh2","~Joao_Goncalves1","~Mark_S._Squillante1"]},"keywords":{"value":["distributionally robust optimization","mixed integer programming","explainable machine learning","rule-based inference"]},"abstract":{"value":"Building explainable machine learning models is crucial for human users to be able to interpret the proposed statistical relationship obtained from the training data. Mixed integer optimization formulations are often used to train such models with explicit sparsity constraints, aiming to hit the right trade off between sparsity and prediction accuracy. Existing methods to find the right choice of sparsity -- e.g., via cross-validation -- are computationally expensive. For convex model training formulations, recent advances in distributionally robust optimization (DRO) provide strong generalization while sidestepping this computational burden. We describe an extension of such regularization via DRO to mixed integer sparse programs, providing statistical guarantees as a function of an associated sparsity parameter of the formulation. We illustrate the use of this approach in the case of building explainable binary classification models using sets of feature value rules."},"pdf":{"value":"/pdf/13de4cd3010af74b17ca8f71385ad9ce366e7ac5.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"TLDR":{"value":"introduces theory on DRO regularization of mixed integer programs; shows how to apply using sparse ruleset binary classification problem"},"_bibtex":{"value":"@inproceedings{\\ndash2025distributionally,\\ntitle={Distributionally Robust Regularization of Sparse Integer Programming Trained Learning Models},\\nauthor={Sanjeeb Dash and Soumyadip Ghosh and Joao Goncalves and Mark S. Squillante},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Dteg3cVABC}\\n}"},"paperhash":{"value":"dash|distributionally_robust_regularization_of_sparse_integer_programming_trained_learning_models"}},"id":"Dteg3cVABC","forum":"Dteg3cVABC","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission70/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission70/Authors"],"number":70,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission70/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757023966267,"cdate":1757023966267,"tmdate":1764510124802,"mdate":1764510124802,"pdate":1764306354270,"odate":1764510124755,"version":2},{"content":{"title":{"value":"A Theoretical Framework for Auxiliary-Loss-Free Load-Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models"},"authors":{"value":["X.Y. Han","Yuan Zhong"]},"authorids":{"value":["~X.Y._Han1","~Yuan_Zhong1"]},"keywords":{"value":["mixture-of-expert","MoE","load balancing","auxiliary loss free load balancing","online optimization","assignment problem","online convex optimization","online stochastic optimization"]},"TLDR":{"value":"A framework for analyzing load-balancing in Sparse Mixture-of-Experts (s-MoE) layers in AI training, focusing on the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure."},"abstract":{"value":"In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load-balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure --- proposed by DeepSeek's Wang et al. (2024) --- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the auxiliary-loss-free load-balancing of s-MoE in AI models."},"pdf":{"value":"/pdf/b8b4797dc087baa068b4217c5dd4cf9ceed006b3.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhan2025a,\\ntitle={A Theoretical Framework for Auxiliary-Loss-Free Load-Balancing of Sparse Mixture-of-Experts in Large-Scale {AI} Models},\\nauthor={X.Y. Han and Yuan Zhong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=sQHZ2w8UzP}\\n}"},"paperhash":{"value":"han|a_theoretical_framework_for_auxiliarylossfree_loadbalancing_of_sparse_mixtureofexperts_in_largescale_ai_models"}},"id":"sQHZ2w8UzP","forum":"sQHZ2w8UzP","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission68/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission68/Authors"],"number":68,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission68/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757012939765,"cdate":1757012939765,"tmdate":1764510124742,"mdate":1764510124742,"pdate":1764306354182,"odate":1764510124715,"version":2},{"content":{"title":{"value":"Training Deep-Parametric Policies Using Lagrangian Duality"},"authors":{"value":["Andrew W. Rosemberg","Alexandre Street","Davi Michel Valladao","Pascal Van Hentenryck"]},"authorids":{"value":["~Andrew_W._Rosemberg1","~Alexandre_Street1","~Davi_Michel_Valladao1","~Pascal_Van_Hentenryck2"]},"keywords":{"value":["Sequential decision making; Constrained reinforcement learning; Stochastic programming; Duality; Energy systems."]},"TLDR":{"value":"Efficiently Training Deep-Learning Parametric Policies for Sequential Decision Problems using Lagrangian Duality."},"abstract":{"value":"Sequential Decision Making under Uncertainty (SDMU) appears across energy, finance, and supply chains. Stochastic Dual Dynamic Programming (SDDP) is a powerful solution approach to these problems, but assumes convexity and stage-wise independence; Two-Stage Linear Decision Rules (TS-LDRs) relax independence and yield fast policies but are limited in non-convex environments. This paper introduces Two-Stage General Decision Rules (TS-GDR) and an instantiation, Two-Stage Deep Decision Rules (TS-DDR), which train nonlinear, time-invariant policies by combining deterministic optimization in the forward pass with duality-based closed-form gradients in the backward pass. On the Long-Term Hydrothermal Dispatch (LTHD) problem for the Bolivian grid, TS-DDR improves solution quality and reduces training/inference time by orders of magnitude compared to SDDP, Reinforcement Learning (RL), and TS-LDR across linear (DCLL), conic (SOC), and non-convex (AC) implementations; it also outperforms a model-predictive control baseline on the stochastic Goddard rocket control problem."},"pdf":{"value":"/pdf/d14d87ddc701efc7172933c2d38f85f046144abd.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nrosemberg2025training,\\ntitle={Training Deep-Parametric Policies Using Lagrangian Duality},\\nauthor={Andrew W. Rosemberg and Alexandre Street and Davi Michel Valladao and Pascal Van Hentenryck},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=wrZjuRvvNz}\\n}"},"paperhash":{"value":"rosemberg|training_deepparametric_policies_using_lagrangian_duality"}},"id":"wrZjuRvvNz","forum":"wrZjuRvvNz","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission67/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission67/Authors"],"number":67,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission67/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757010594539,"cdate":1757010594539,"tmdate":1764510124617,"mdate":1764510124617,"pdate":1764306354101,"odate":1764510124598,"version":2},{"content":{"title":{"value":"Estimation of Treatment Effects under Nonstationarity via the Truncated Policy Gradient Estimator"},"authors":{"value":["Ramesh Johari","Tianyi Peng","Wenqian Xing"]},"authorids":{"value":["~Ramesh_Johari1","~Tianyi_Peng1","~Wenqian_Xing1"]},"keywords":{"value":["Causal Inference","Off-policy Evaluation","Experimentation","Nonstationarity","Reinforcement Learning"]},"TLDR":{"value":"We present a simple estimator for low bias, low variance estimation of the global average treatment effect from Bernoulli randomized experiments in dynamic, nonstationary environments."},"abstract":{"value":"Randomized experiments (A/B tests) are widely used to evaluate interventions in dynamic systems such as recommendation platforms, marketplaces, and digital health. In these settings, interventions affect both current and future system states, so estimating the global average treatment effect (GATE) requires accounting for temporal dynamics. Existing estimators—including difference-in-means (DM), off-policy evaluation methods, and difference-in-Q’s (DQ)—perform poorly in nonstationary environments due to high bias and variance. We address this challenge with the truncated policy gradient (TPG) estimator, which replaces instantaneous outcomes with truncated outcome trajectories. Theoretically, it corresponds to a truncated policy gradient that approximates the GATE to first order, yielding provable bias and variance improvements in nonstationary Markovian settings. We validate our theory through a ride-sharing simulation calibrated to New York City taxi data. The results show that a well-calibrated TPG estimator achieves low bias and variance in practical nonstationary settings."},"pdf":{"value":"/pdf/2ff50051bf7955abedd64d3e46d6ffa5e18ed987.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njohari2025estimation,\\ntitle={Estimation of Treatment Effects under Nonstationarity via the Truncated Policy Gradient Estimator},\\nauthor={Ramesh Johari and Tianyi Peng and Wenqian Xing},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ZSPMKadwFT}\\n}"},"paperhash":{"value":"johari|estimation_of_treatment_effects_under_nonstationarity_via_the_truncated_policy_gradient_estimator"}},"id":"ZSPMKadwFT","forum":"ZSPMKadwFT","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission66/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission66/Authors"],"number":66,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission66/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1757000458714,"cdate":1757000458714,"tmdate":1764510124535,"mdate":1764510124535,"pdate":1764306354098,"odate":1764510124513,"version":2},{"content":{"title":{"value":"Optimality of Linear Policies in Distributionally Robust Linear Quadratic Control"},"authors":{"value":["Bahar Taskesen","Dan Andrei Iancu","Çağıl Koçyiğit","Daniel Kuhn"]},"authorids":{"value":["~Bahar_Taskesen1","~Dan_Andrei_Iancu1","~Çağıl_Koçyiğit1","~Daniel_Kuhn2"]},"keywords":{"value":["distributionally robust optimization","linear-quadratic-Gaussian control","linear policies"]},"abstract":{"value":"We study a generalization of the classical discrete-time, Linear-Quadratic-Gaussian (LQG) control problem where the noise distributions affecting the states and observations are unknown and chosen adversarially from divergence-based ambiguity sets centered around a known nominal distribution. For a finite horizon model with Gaussian nominal noise and a structural assumption on the divergence that is satisfied by many examples -- including 2-Wasserstein distance, Kullback-Leibler divergence, moment-based divergences, entropy-regularized optimal transport, or Fisher (score-matching) divergence -- we prove that a control policy that is \\\\emph{affine} in the observations is optimal and the adversary's corresponding worst-case optimal distribution is Gaussian. \\n  When the nominal means are zero (as in the classical LQG model), we show that the adversary should optimally set the distribution's mean to zero and the optimal control policy becomes \\\\emph{linear}. Moreover, the adversary should optimally \`\`inflate\\" the noise by choosing covariance matrices that dominate the nominal covariance in Loewner order. Exploiting these structural properties, we develop a Frank-Wolfe algorithm whose inner step solves standard LQG subproblems via Kalman filtering and dynamic programming and show that the implementation consistently outperforms semidefinite-programming reformulations of the problem. We then extend all structural results to an infinite-horizon, average-cost formulation, where we prove that \\\\emph{stationary} linear policies are optimal for the decision maker and \\\\emph{time-invariant}, Gaussian distributions are optimal for the adversary. Lastly, when the divergence is 2-Wasserstein, we show that the entire framework remains valid is nominal distributions are elliptical rather than Gaussian."},"pdf":{"value":"/pdf/a7958eac51948cbb925822570edfc9caaa1d3acf.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ntaskesen2025optimality,\\ntitle={Optimality of Linear Policies in Distributionally Robust Linear Quadratic Control},\\nauthor={Bahar Taskesen and Dan Andrei Iancu and {\\\\c{C}}a{\\\\u{g}}{\\\\i}l Ko{\\\\c{c}}yi{\\\\u{g}}it and Daniel Kuhn},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=x2zwy881al}\\n}"},"paperhash":{"value":"taskesen|optimality_of_linear_policies_in_distributionally_robust_linear_quadratic_control"}},"id":"x2zwy881al","forum":"x2zwy881al","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission65/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission65/Authors"],"number":65,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission65/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756999640902,"cdate":1756999640902,"tmdate":1764510124532,"mdate":1764510124532,"pdate":1764306354025,"odate":1764510124511,"version":2},{"content":{"title":{"value":"The Oversight Game: Learning AI Control and Corrigibility in Markov Games"},"authors":{"value":["William Overman","Mohsen Bayati"]},"authorids":{"value":["~William_Overman1","~Mohsen_Bayati1"]},"keywords":{"value":["scalable oversight","ai contorl","alignment","safety","markov potential games"]},"TLDR":{"value":"We cast scalable oversight as an MPG wrapper around a frozen agent, proving reduced deferral can’t harm the human and empirically eliminating violations without hurting task reward."},"abstract":{"value":"As increasingly capable agents are deployed, a central safety question is how to retain meaningful human control without modifying the underlying system. We study a minimal interface where an agent chooses autonomously (play) or defers (ask), while a human simultaneously chooses to be permissive (trust) or to engage (oversee), which can trigger a correction. We model this as a two-player Markov Game, focusing particularly on the case where it qualifies as a Markov Potential Game (MPG). We show the MPG structure yields a powerful alignment guarantee: under a structural assumption on the human's value, any decision by the agent to act more autonomously that benefits itself cannot harm the human's value. This model provides a transparent control layer where the agent learns to defer when risky and act when safe, while its pretrained policy remains untouched. Our gridworld simulation shows that through independent learning, an emergent collaboration avoids safety violations, demonstrating a practical method for making misaligned models safer after deployment."},"pdf":{"value":"/pdf/21a3e1d8192d27c96aa0e8b2b91823d433886ff8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\noverman2025the,\\ntitle={The Oversight Game: Learning {AI} Control and Corrigibility in Markov Games},\\nauthor={William Overman and Mohsen Bayati},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=IC0Qo09FxF}\\n}"},"paperhash":{"value":"overman|the_oversight_game_learning_ai_control_and_corrigibility_in_markov_games"}},"id":"IC0Qo09FxF","forum":"IC0Qo09FxF","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission64/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission64/Authors"],"number":64,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission64/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756995254269,"cdate":1756995254269,"tmdate":1764510124504,"mdate":1764510124504,"pdate":1764306353888,"odate":1764510124485,"version":2},{"content":{"title":{"value":"FairSVM: A Mixed-Integer Programming Framework for Fairness-Constrained Support Vector Machines"},"authors":{"value":["Gabriele Marchesi","Francesca Maggioni","Bismark Singh"]},"authorids":{"value":["~Gabriele_Marchesi2","francesca.maggioni@unibg.it","~Bismark_Singh1"]},"keywords":{"value":["fair machine learning","mixed-integer optimization","support vector machine"]},"abstract":{"value":"Machine learning classifiers are increasingly deployed in high-stakes domains such as credit scoring, hiring, and criminal justice, where concerns about algorithmic bias have become central. Existing approaches to algorithmic fairness often rely either on removing sensitive features (\`\`fairness through unawareness'') or on post-hoc corrections, which limit transparency and flexibility. We propose a mixed–integer programming framework, \${FairSVM}$, that embeds fairness constraints directly into the training of soft–margin Support Vector Machines. Our formulation expresses multiple group fairness notions --- including statistical parity, predictive equality, equal opportunity, equalized odds, and conditional statistical parity --- as linear constraints within the SVM model. Our approach enables explicit control over the trade-off between predictive accuracy and fairness through adjustable parameters. We evaluate \${FairSVM}$ on three widely studied datasets (German Credit, Adult Income, COMPAS) and compare it against both optimization-based (\${ FairOCT}$) and model-agnostic (\${CR}$, \${ExpG}$, \${RTO}$) benchmarks. Results show that \${FairSVM}$ substantially reduces group disparities with only limited loss in accuracy, while offering greater flexibility in navigating fairness–accuracy trade-offs. These findings highlight the potential of optimization-based formulations as a foundation for developing next-generation fairness-aware machine learning models."},"pdf":{"value":"/pdf/9e4bc8096da7f773a9040430bed73f733e0717b7.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmarchesi2025fairsvm,\\ntitle={Fair{SVM}: A Mixed-Integer Programming Framework for Fairness-Constrained Support Vector Machines},\\nauthor={Gabriele Marchesi and Francesca Maggioni and Bismark Singh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=aGtZzovQfZ}\\n}"},"paperhash":{"value":"marchesi|fairsvm_a_mixedinteger_programming_framework_for_fairnessconstrained_support_vector_machines"}},"id":"aGtZzovQfZ","forum":"aGtZzovQfZ","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission63/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission63/Authors"],"number":63,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission63/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756995251911,"cdate":1756995251911,"tmdate":1764510124429,"mdate":1764510124429,"pdate":1764306353372,"odate":1764510124413,"version":2},{"content":{"title":{"value":"Adaptive Resolving Methods for Reinforcement Learning with Function Approximations"},"authors":{"value":["Jiashuo Jiang","Yiming Zong","Yinyu Ye"]},"authorids":{"value":["~Jiashuo_Jiang1","~Yiming_Zong1","~Yinyu_Ye1"]},"keywords":{"value":["online linear programming","markov decision process","reinforcement learning","function approximation"]},"abstract":{"value":"Reinforcement learning (RL) problems are fundamental in online decision-making and have been instrumental for finding an optimal policy for Markov decision processes (MDPs). Function approximations are usually deployed to handle large or infinite state-action space. In our work, we consider the RL problems with function approximation and we develop a new algorithm to solve it efficiently. Our algorithm is based on the linear programming (LP) reformulation and it resolves the LP at each iteration improved with new data arrival. Such a resolving scheme enables our algorithm to achieve an instance-dependent sample complexity guarantee, more precisely, when we have $N$ data, the output of our algorithm enjoys an instance-dependent $\\\\tilde{O}(1/N)$ suboptimality gap. In comparison to the $O(1/\\\\sqrt{N})$ worst-case guarantee established in the previous literature, our instance-dependent guarantee is tighter when the underlying instance is favorable, and the numerical experiments also reveal the efficient empirical performances of our algorithms."},"pdf":{"value":"/pdf/e255f44cd140e018ac611cbbdb56b3aaf0e79abe.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njiang2025adaptive,\\ntitle={Adaptive Resolving Methods for Reinforcement Learning with Function Approximations},\\nauthor={Jiashuo Jiang and Yiming Zong and Yinyu Ye},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=i0qmveSo1u}\\n}"},"paperhash":{"value":"jiang|adaptive_resolving_methods_for_reinforcement_learning_with_function_approximations"}},"id":"i0qmveSo1u","forum":"i0qmveSo1u","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission61/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission61/Authors"],"number":61,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission61/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756989009719,"cdate":1756989009719,"tmdate":1764510124335,"mdate":1764510124335,"pdate":1764306353310,"odate":1764510124318,"version":2},{"content":{"title":{"value":"Contextual Pricing with Heterogeneous Buyers"},"authors":{"value":["Thodoris Lykouris","Sloan Nietert","Princewill Okoroafor","Chara Podimata","Julian Zimmert"]},"authorids":{"value":["~Thodoris_Lykouris1","~Sloan_Nietert1","~Princewill_Okoroafor1","~Chara_Podimata1","~Julian_Zimmert1"]},"keywords":{"value":["dynamic pricing","bandits","contextual"]},"TLDR":{"value":"contextual dynamic pricing with heterogenous buyers using optimistic posterior sampling"},"abstract":{"value":"We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly (over $T$ rounds) posts prices that depend on the observable $d$ dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\\\\star}$. We develop a contextual pricing algorithm based on Optimistic Posterior Sampling with regret $\\\\tilde{O}(K_{\\\\star}\\\\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware Zooming algorithm that achieves the optimal dependence on $K_{\\\\star}$."},"pdf":{"value":"/pdf/4aafef4b3f390bdd311dd599ae7e12a339e6d663.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlykouris2025contextual,\\ntitle={Contextual Pricing with Heterogeneous Buyers},\\nauthor={Thodoris Lykouris and Sloan Nietert and Princewill Okoroafor and Chara Podimata and Julian Zimmert},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=HmyCi5Hd4M}\\n}"},"paperhash":{"value":"lykouris|contextual_pricing_with_heterogeneous_buyers"}},"id":"HmyCi5Hd4M","forum":"HmyCi5Hd4M","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission60/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission60/Authors"],"number":60,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission60/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756981139421,"cdate":1756981139421,"tmdate":1764510124407,"mdate":1764510124407,"pdate":1764306353231,"odate":1764510124315,"version":2},{"content":{"title":{"value":"A Near-Optimal Control Policy for Data-driven Assemble-to-order Systems"},"authors":{"value":["Lun Yu","Zhixuan Cai","Zhaoran Wang","Tianhu Deng"]},"authorids":{"value":["yulun@cuhk.edu.cn","~Zhixuan_Cai1","~Zhaoran_Wang1","thdeng@suda.edu.cn"]},"keywords":{"value":["assemble-to-order system","deep reinforcement learning","input convex neural network","data-driven optimization"]},"abstract":{"value":"We study a data-driven assemble-to-order (ATO) control problem, aiming to synchronize component ordering and product assembly under unknown demand distributions and non-identical lead times. \\nWe address two key questions: the statistical tractability of learning a near-optimal policy from limited data and the computational complexity of obtaining it. \\nTo the best of our knowledge, our work is the first to analyze the sample efficiency for a general ATO system as a multidimensional control problem and to propose an algorithm that finds a provably near-optimal solution. \\nMethodologically, we introduce a novel asymmetric Lipschitz continuity (ALC) property to establish regularity conditions for the infinite-horizon problem. \\nSurprisingly, we prove that the data-driven ATO problem avoids the curse of dimensionality; the performance gap of our policy scales as $O(M^{-1/2}\\\\log M)$ with sample size $M$, only logarithmically worse than approximating the demand mean. \\nWe develop a specialized reinforcement learning (RL) algorithm that exploits a convex-preserving property in ATO dynamics, using input convex neural networks and interior point methods to achieve computational feasibility. \\nNumerical studies show our algorithm consistently and significantly outperforms existing heuristics and a general-purpose RL benchmark."},"pdf":{"value":"/pdf/30d5b74a3b984d26500f57956e355ecf5fbcbd39.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyu2025a,\\ntitle={A Near-Optimal Control Policy for Data-driven Assemble-to-order Systems},\\nauthor={Lun Yu and Zhixuan Cai and Zhaoran Wang and Tianhu Deng},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=YMBVTlfmGp}\\n}"},"paperhash":{"value":"yu|a_nearoptimal_control_policy_for_datadriven_assembletoorder_systems"}},"id":"YMBVTlfmGp","forum":"YMBVTlfmGp","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission59/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission59/Authors"],"number":59,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission59/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756979661624,"cdate":1756979661624,"tmdate":1764510124289,"mdate":1764510124289,"pdate":1764306353182,"odate":1764510124272,"version":2},{"content":{"title":{"value":"Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption"},"authors":{"value":["Yige Hong","Qiaomin Xie","Yudong Chen","Weina Wang"]},"authorids":{"value":["~Yige_Hong1","~Qiaomin_Xie1","~Yudong_Chen1","~Weina_Wang1"]},"keywords":{"value":["restless bandits","long-run average reward","exponential asymptotic optimality"]},"TLDR":{"value":"We propose the first policy that has exponential asymptotic optimality in the average-reward restless bandits under a set of assumptions that are weaker and more fundamental than those in the prior work."},"abstract":{"value":"We study the infinite-horizon average-reward restless bandit (RB) problem, a representative class of problems within the broader framework of weakly-coupled Markov decision processes (MDPs).\\nEach RB problem consists of $N$ MDPs coupled by a resource constraint.\\nExisting computationally efficient policies either only achieve an $O(1/\\\\sqrt{N})$ optimality gap or require a strong *global attractor assumption* to achieve an exponentially small $O(\\\\exp(-C N))$ optimality gap.\\nIn this paper, we propose a novel *two-set policy* that achieves an $O(\\\\exp(-C N))$ optimality gap under the weaker and easily verifiable assumptions of aperiodic unichain, non-degeneracy, and local stability.\\nWe further show that dropping *any* of these three assumptions precludes an exponential optimality gap, with local stability playing a particularly fundamental role as demonstrated by our lower bound.\\nFinally, our experimental results confirm that the two-set policy outperforms existing policies when our assumptions are met but not the global attractor assumption, while remaining competitive across general settings."},"pdf":{"value":"/pdf/b198df337d4a2dfe43e7e1cefa19ed409bf1e0e3.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhong2025achieving,\\ntitle={Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption},\\nauthor={Yige Hong and Qiaomin Xie and Yudong Chen and Weina Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=igPYJRM3Yi}\\n}"},"paperhash":{"value":"hong|achieving_exponential_asymptotic_optimality_in_averagereward_restless_bandits_without_global_attractor_assumption"}},"id":"igPYJRM3Yi","forum":"igPYJRM3Yi","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission58/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission58/Authors"],"number":58,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission58/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756975443908,"cdate":1756975443908,"tmdate":1764510124224,"mdate":1764510124224,"pdate":1764306353157,"odate":1764510124207,"version":2},{"content":{"title":{"value":"Almost Sure Convergence of Nonlinear Stochastic Approximation Under General Moment Conditions"},"authors":{"value":["Anh Duc Nguyen","Quang Nguyen","Hoang H Nguyen","Siva Theja Maguluri"]},"authorids":{"value":["~Anh_Duc_Nguyen1","~Quang_Nguyen7","~Hoang_H_Nguyen2","~Siva_Theja_Maguluri1"]},"keywords":{"value":["Nonlinear Stochastic Approximation","Almost Sure Convergence","Truncation Method"]},"TLDR":{"value":"We show almost sure convergence of stochastic approximation under general moment conditions using state-dependent truncation and Lyapunov drift method."},"abstract":{"value":"We study the almost sure convergence of the Stochastic Approximation algorithm with diminishing step sizes $\\\\alpha_n = \\\\mathcal{O}\\\\left(n^{-\\\\xi}\\\\right)$ for some $\\\\xi \\\\in (0,1]$ under a general noise moment assumption and a contractive operator. In particular, we show that for a martingale difference noise with $p$-th order integrability, we have almost sure convergence whenever $\\\\max ( 1/2 , 1/p) < \\\\xi < 1$. Our result generalizes (weighted) Law of Large Numbers and the almost sure convergence results in \\\\cite{neurodynamic, Borkar2008StochasticAA, zaiwei-envelope}. To establish such results, we introduce a state-dependent moving truncation coupled with a fine-grained Lyapunov drift analysis. This approach effectively manages the bias from truncated terms and addresses the challenges posed by multiplicative noise, allowing us to relax the stringent assumptions often found in the literature."},"pdf":{"value":"/pdf/ff2003c585d5ff3985823c1b986ab99c354cdb45.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nnguyen2025almost,\\ntitle={Almost Sure Convergence of Nonlinear Stochastic Approximation Under General Moment Conditions},\\nauthor={Anh Duc Nguyen and Quang Nguyen and Hoang H Nguyen and Siva Theja Maguluri},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=iTNB3Q9TKC}\\n}"},"paperhash":{"value":"nguyen|almost_sure_convergence_of_nonlinear_stochastic_approximation_under_general_moment_conditions"}},"id":"iTNB3Q9TKC","forum":"iTNB3Q9TKC","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission56/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission56/Authors"],"number":56,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission56/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756964525475,"cdate":1756964525475,"tmdate":1764510124160,"mdate":1764510124160,"pdate":1764306352913,"odate":1764510124141,"version":2},{"content":{"title":{"value":"Revisiting Follow-the-Perturbed-Leader with Unbounded Perturbations in Bandit Problems"},"authors":{"value":["Jongyeong Lee","Junya Honda","Shinji Ito","Min-hwan Oh"]},"authorids":{"value":["~Jongyeong_Lee1","~Junya_Honda1","~Shinji_Ito1","~Min-hwan_Oh1"]},"keywords":{"value":["multi-armed bandits","best-of-both-worlds","discrete choice theory","random utility model"]},"TLDR":{"value":"We aim to deepen the understanding of FTPL by establishing its connection to discrete choice theory."},"abstract":{"value":"Follow-the-Regularized-Leader (FTRL) policies have achieved Best-of-Both-Worlds (BOBW) results in various settings through hybrid regularizers, whereas analogous results for Follow-the-Perturbed-Leader (FTPL) remain limited due to inherent analytical challenges. To advance the analytical foundations of FTPL, we revisit classical FTRL-FTPL duality for unbounded perturbations and establish BOBW results for FTPL under a broad family of asymmetric unbounded Fréchet-type perturbations, including hybrid perturbations combining Gumbel-type and Fréchet-type tails. These results not only extend the BOBW results of FTPL but also offer new insights into designing alternative FTPL policies competitive with hybrid regularization approaches. Motivated by earlier observations in two-armed bandits, we further investigate the connection between the $1/2$-Tsallis entropy and a Fréchet-type perturbation. Our numerical observations suggest that it corresponds to a symmetric Fréchet-type perturbation, and based on this, we establish the first BOBW guarantee for symmetric unbounded perturbations in the two-armed setting. In contrast, in general multi-armed bandits, we find an instance in which symmetric Fréchet-type perturbations violate the key condition for standard BOBW analysis, which is a problem not observed with asymmetric or nonnegative Fréchet-type perturbations. Although this example does not rule out alternative analyses achieving BOBW results, it suggests the limitations of directly applying the relationship observed in two-armed cases to the general case and thus emphasizes the need for further investigation to fully understand the behavior of FTPL in broader settings."},"pdf":{"value":"/pdf/9c0c5d45cc1e8b68cddc064a91ed283c513dced8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlee2025revisiting,\\ntitle={Revisiting Follow-the-Perturbed-Leader with Unbounded Perturbations in Bandit Problems},\\nauthor={Jongyeong Lee and Junya Honda and Shinji Ito and Min-hwan Oh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=7NdSwhWCMx}\\n}"},"paperhash":{"value":"lee|revisiting_followtheperturbedleader_with_unbounded_perturbations_in_bandit_problems"}},"id":"7NdSwhWCMx","forum":"7NdSwhWCMx","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission54/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission54/Authors"],"number":54,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission54/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756961249794,"cdate":1756961249794,"tmdate":1764510124052,"mdate":1764510124052,"pdate":1764306352772,"odate":1764510124034,"version":2},{"content":{"title":{"value":"Fairness Is More Than Algorithms: Racial Disparities in Time-to-Recidivism"},"authors":{"value":["Jessy Xinyi Han","Kristjan Greenewald","Devavrat Shah"]},"authorids":{"value":["~Jessy_Xinyi_Han1","~Kristjan_Greenewald1","~Devavrat_Shah1"]},"keywords":{"value":["causal inference","algorithmic bias","recidivism","racial disparities"]},"TLDR":{"value":"We present a multi-stage causal framework and an empirical test to study sources of racial bias in recidivism from a time-to-event perspective–revealing that fairness requires addressing deeper socioeconomic inequalities, not just fixing algorithms."},"abstract":{"value":"Racial disparities in recidivism remain a persistent issue within the criminal justice system, increasingly exacerbated by the adoption of algorithmic risk assessment tools for decision making. Past works have primarily focused on understanding the bias induced by algorithmic tools, viewing recidivism as a binary outcome—i.e., reoffending or not. Limited attention has been given to the role of non-algorithmic factors (including socioeconomic ones) in driving the racial disparities in recidivism from a systemic perspective. Towards that end, this work presents a multi-stage causal framework to investigate the advent and extent of racial disparities by considering the time-to-recidivism rather than a simple binary outcome. The framework captures the interactions between races, the risk assessment algorithm, and contextual factors in general. This work introduces the notion of counterfactual racial disparity and offers a formal test using survival analysis that can be conducted with observational data to understand whether potential differences in recidivism rates among racial groups arise from algorithmic bias, contextual factors, or their interplay. In particular, it is formally established that if sufficient statistical evidence for differences in recidivism across racial groups is observed, it would support rejecting the null hypothesis that non-algorithmic factors (including socioeconomic ones) do not affect recidivism. An empirical study applying this framework to the COMPAS dataset reveals that short-term recidivism patterns do not exhibit racial disparities when controlling for risk scores. However, statistically significant disparities emerge with a longer follow-up period, particularly for low-risk groups. This suggests that factors beyond the algorithmic scores–possibly including structural disparities in housing, employment, and social support–may accumulate and exacerbate recidivism risks over time. Indeed, the use of survival analysis enables such nuanced analysis. This empirical analysis underscores the need for holistic policy interventions extending beyond algorithmic improvements to address the broader influences on recidivism trajectories."},"pdf":{"value":"/pdf/60d65cc587450bfabf04db49457b9ed9b2129f84.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhan2025fairness,\\ntitle={Fairness Is More Than Algorithms: Racial Disparities in Time-to-Recidivism},\\nauthor={Jessy Xinyi Han and Kristjan Greenewald and Devavrat Shah},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=v7YPtir432}\\n}"},"paperhash":{"value":"han|fairness_is_more_than_algorithms_racial_disparities_in_timetorecidivism"}},"id":"v7YPtir432","forum":"v7YPtir432","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission53/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission53/Authors"],"number":53,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission53/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756958711547,"cdate":1756958711547,"tmdate":1764510123986,"mdate":1764510123986,"pdate":1764306352624,"odate":1764510123970,"version":2},{"content":{"title":{"value":"Contextual Budget Bandit for Food Rescue Volunteer Engagement"},"authors":{"value":["Ariana Tang","Naveen Janaki Raman","Fei Fang","Zheyuan Ryan Shi"]},"authorids":{"value":["~Ariana_Tang1","~Naveen_Janaki_Raman1","~Fei_Fang1","~Zheyuan_Ryan_Shi1"]},"keywords":{"value":["food rescue","restless bandit","budget allocation"]},"TLDR":{"value":"We introduce algorithms for contextual budget allocation in restless multi-armed bandits to address reward disparity across context groups in crowdsourcing food rescue volunteer engagement."},"abstract":{"value":"Restless multi-armed bandits (RMABs) are an extension of the multi-armed bandit framework where pulling an arm results in both a reward and a Markovian state change. While RMABs are being employed in domains including public health and food insecurity, its objective of maximizing the cumulative reward comes at the expense of reward disparity across different context groups. To address this issue, we introduce contextual budget allocation, which optimizes the budget amount across different contexts, along with the traditional budget allocation within each context. This allows higher-need groups to receive larger budgets. We develop a set of novel policies: (1) COcc, an empirically fast heuristic algorithm based on the Whittle index policy, and (2) Mitosis, a provably optimal algorithm that combines a branch-and-bound search structure and no-regret algorithm framework. We conduct extensive experiments with synthetic and real food rescue datasets."},"pdf":{"value":"/pdf/445ba1b57a9f57bb570c10a32922fda958f2efbf.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ntang2025contextual,\\ntitle={Contextual Budget Bandit for Food Rescue Volunteer Engagement},\\nauthor={Ariana Tang and Naveen Janaki Raman and Fei Fang and Zheyuan Ryan Shi},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=iyuz8bnDlS}\\n}"},"paperhash":{"value":"tang|contextual_budget_bandit_for_food_rescue_volunteer_engagement"}},"id":"iyuz8bnDlS","forum":"iyuz8bnDlS","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission52/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission52/Authors"],"number":52,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission52/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756957759890,"cdate":1756957759890,"tmdate":1764510123989,"mdate":1764510123989,"pdate":1764306352555,"odate":1764510123969,"version":2},{"content":{"title":{"value":"Online Decision Making with Generative Action Sets"},"authors":{"value":["Jianyu Xu","Vidhi Jain","Bryan Wilder","Aarti Singh"]},"authorids":{"value":["~Jianyu_Xu1","~Vidhi_Jain3","~Bryan_Wilder2","~Aarti_Singh2"]},"keywords":{"value":["multi-armed bandits","contextual bandits","online facility location"]},"TLDR":{"value":"We study a contextual bandit problem with new arms being generated on the fly, proposing a doubly-optimistic algorithm that achieves a sublinear regret for expanding action spaces."},"abstract":{"value":"With advances in generative AI, decision-making agents can now dynamically create new actions during online learning, but action generation typically incurs costs that must be balanced against potential benefits. We study an online learning problem where an agent can generate new actions at any time step by paying a one-time cost, with these actions becoming permanently available for future use. The challenge lies in learning the optimal sequence of two-fold decisions: which action to take and when to generate new ones, further complicated by the triangular tradeoffs among exploitation, exploration and *creation*. To solve this problem, we propose a doubly-optimistic algorithm that employs Lower Confidence Bounds (LCB) for action selection and Upper Confidence Bounds (UCB) for action generation. Empirical evaluation on healthcare question-answering datasets demonstrates that our approach achieves favorable generation-quality tradeoffs compared to baseline strategies. From theoretical perspectives, we prove that our algorithm achieves the optimal regret of $O(T^{d/(d+2)}d^{d/(d+2)} + d\\\\sqrt{T\\\\log T})$, providing the first sublinear regret bound for online learning with expanding action spaces."},"pdf":{"value":"/pdf/e6c39e068fff8bd5e78556cc5be2b2bf4d910123.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nxu2025online,\\ntitle={Online Decision Making with Generative Action Sets},\\nauthor={Jianyu Xu and Vidhi Jain and Bryan Wilder and Aarti Singh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=DM7YhuKQvD}\\n}"},"paperhash":{"value":"xu|online_decision_making_with_generative_action_sets"}},"id":"DM7YhuKQvD","forum":"DM7YhuKQvD","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission51/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission51/Authors"],"number":51,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission51/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756953631237,"cdate":1756953631237,"tmdate":1764510123959,"mdate":1764510123959,"pdate":1764306352487,"odate":1764510123943,"version":2},{"content":{"title":{"value":"Instance-dependent Sample Complexity for Bilinear Saddle-Point Optimization with Noisy Feedback: An LP-Based Approach"},"authors":{"value":["Jiashuo Jiang"]},"authorids":{"value":["~Jiashuo_Jiang1"]},"keywords":{"value":["learning in game","instance-dependent guarantees","linear programming","zero sum game"]},"abstract":{"value":"In this work, we study the sample complexity of obtaining a Nash equilibrium (NE) estimate in two-player zero-sum matrix games with noisy feedback. Specifically, we propose a novel algorithm that repeatedly solves linear programs (LPs) to obtain an NE estimate with bias at most $\\\\epsilon$ with a sample complexity of $O(\\\\frac{m_1 m_2}{\\\\epsilon\\\\min\\\\\\\\{\\\\delta^2,\\\\sigma_0^2,\\\\sigma^3\\\\\\\\}} \\\\log\\\\frac{m_1 m_2}{\\\\epsilon})$\\nfor general $m_1 \\\\times m_2$ game matrices, where $\\\\sigma$, $\\\\sigma_0$, $\\\\delta$ are some problem-dependent constants. To our knowledge, this is the first instance-dependent sample complexity bound for finding an NE estimate with $\\\\epsilon$ bias in general-dimension matrix games with noisy feedback and potentially non-unique equilibria. Our algorithm builds on recent advances in online resource allocation and operates in two stages: (1) identifying the support set of an NE, and (2) computing the unique NE restricted to this support. Both stages rely on a careful analysis of LP solutions derived from noisy samples."},"pdf":{"value":"/pdf/b398f10119e9257a22c7525fa92edeae59fe8787.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\njiang2025instancedependent,\\ntitle={Instance-dependent Sample Complexity for Bilinear Saddle-Point Optimization with Noisy Feedback: An {LP}-Based Approach},\\nauthor={Jiashuo Jiang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=CNUPUzQOMG}\\n}"},"paperhash":{"value":"jiang|instancedependent_sample_complexity_for_bilinear_saddlepoint_optimization_with_noisy_feedback_an_lpbased_approach"}},"id":"CNUPUzQOMG","forum":"CNUPUzQOMG","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission50/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission50/Authors"],"number":50,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission50/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756953386626,"cdate":1756953386626,"tmdate":1764510123903,"mdate":1764510123903,"pdate":1764306352382,"odate":1764510123889,"version":2},{"content":{"title":{"value":"Diffusion Models for Adapted Sequential Data Generation"},"authors":{"value":["Haoyang Cao","Minshuo Chen","Yinbin Han","Renyuan Xu"]},"authorids":{"value":["~Haoyang_Cao1","~Minshuo_Chen1","~Yinbin_Han1","~Renyuan_Xu1"]},"keywords":{"value":["Diffusion models","sequential data","adaptiveness","score approximation"]},"abstract":{"value":"Generating realistic synthetic sequential data is critical in real-world applications such as operations research and finance. While diffusion models have achieved remarkable success in generating static data, their direct extensions to sequential settings often fail to capture temporal dependencies and information structure. Designing diffusion models that can simulate sequential data in an adaptive, non-anticipative manner therefore remains an open challenge.\\n\\n\\n\\nIn this work, we propose a sequential forward–backward diffusion framework for adapted time series generation. Our approach progressively injects and removes noise along the sequence, by conditioning on the previously generated history to ensure adaptiveness. We further introduce a novel score-matching objective for efficient parallel training. Finally, we establish a score approximation result using transformer networks as an early step towards a statistical estimation theory."},"pdf":{"value":"/pdf/ba64dbee343791844403db7e8f195ac2b49f359e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ncao2025diffusion,\\ntitle={Diffusion Models for Adapted Sequential Data Generation},\\nauthor={Haoyang Cao and Minshuo Chen and Yinbin Han and Renyuan Xu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=2pfnuv913O}\\n}"},"paperhash":{"value":"cao|diffusion_models_for_adapted_sequential_data_generation"}},"id":"2pfnuv913O","forum":"2pfnuv913O","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission49/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission49/Authors"],"number":49,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission49/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756945780105,"cdate":1756945780105,"tmdate":1764510123871,"mdate":1764510123871,"pdate":1764306352381,"odate":1764510123852,"version":2},{"content":{"title":{"value":"Joint Pricing and Resource Allocation: An Optimal Online-Learning Approach"},"authors":{"value":["Jianyu Xu","Xuan Wang","Yu-Xiang Wang","Jiashuo Jiang"]},"authorids":{"value":["~Jianyu_Xu1","~Xuan_Wang22","~Yu-Xiang_Wang1","~Jiashuo_Jiang1"]},"keywords":{"value":["Online learning","Dynamic Pricing","Resource Allocation"]},"TLDR":{"value":"We study a two-stage pricing-and-allocation joint decision problem,  presenting an online-learning algorithm that achieves $\\\\tilde{O}(\\\\sqrt{T})$ optimal regret."},"abstract":{"value":"We study an online learning problem on dynamic pricing and resource allocation, where we make joint pricing and inventory decisions to maximize the overall net profit. We consider the stochastic dependence of demands on the price, which complicates the resource allocation process and introduces significant non-convexity and non-smoothness to the problem. To solve this problem, we develop an efficient algorithm that utilizes a \\"Lower-Confidence Bound (LCB)\\" meta-strategy over multiple OCO agents. Our algorithm achieves $\\\\tilde{O}(\\\\sqrt{Tmn})$ regret (for $m$ suppliers and $n$ consumers), which is *optimal* with respect to the time horizon $T$. Our results illustrate an effective integration of statistical learning methodologies with complex operations research problems."},"pdf":{"value":"/pdf/7c2c944cccc6808344b991d1767fad11ee208fc0.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nxu2025joint,\\ntitle={Joint Pricing and Resource Allocation: An Optimal Online-Learning Approach},\\nauthor={Jianyu Xu and Xuan Wang and Yu-Xiang Wang and Jiashuo Jiang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Mi0QQk55GG}\\n}"},"paperhash":{"value":"xu|joint_pricing_and_resource_allocation_an_optimal_onlinelearning_approach"}},"id":"Mi0QQk55GG","forum":"Mi0QQk55GG","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission47/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission47/Authors"],"number":47,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission47/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756938650494,"cdate":1756938650494,"tmdate":1764510123816,"mdate":1764510123816,"pdate":1764306352154,"odate":1764510123795,"version":2},{"content":{"title":{"value":"Provable Reinforcement Learning from Human Feedback with an Unknown Link Function"},"authors":{"value":["Qining Zhang","Lei Ying"]},"authorids":{"value":["~Qining_Zhang2","~Lei_Ying1"]},"keywords":{"value":["reinforcement learning theory","preference feedback","link function","zeroth-order optimization"]},"TLDR":{"value":"We design an RLHF algorithm with provable convergence guarantee which does not require knowing the preference link function."},"abstract":{"value":"Link functions, which characterize how human preferences are generated from the value function of an RL problem, are a crucial component in designing RLHF algorithms. Almost all RLHF algorithms, including state-of-the-art ones in empirical studies such as DPO and PPO, assume the link function is known to the agent (e.g., a logistic function according to the Bradley-Terry model), which is arguably unrealistic considering the complex nature of human preferences. To avoid link function mis-specification, this paper studies general RLHF problems with unknown link functions. We propose a novel policy optimization algorithm called ZSPO based on a new zeroth-order policy optimization method, where the key is to use human preference to construct a parameter update direction that is positively correlated with the true policy gradient direction. ZSPO achieves it by estimating the sign of the value function difference instead of estimating the gradient from the value function difference, so it does not require knowing the link function. Under mild conditions, ZSPO converges to a stationary policy with a polynomial convergence rate depending on the number of policy iterations and trajectories per iteration. Numerical results also show the superiority of ZSPO under link function mismatch."},"pdf":{"value":"/pdf/24ffbab805aa1899d562af17192d3344d7115b79.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nzhang2025provable,\\ntitle={Provable Reinforcement Learning from Human Feedback with an Unknown Link Function},\\nauthor={Qining Zhang and Lei Ying},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=fPPypKWsur}\\n}"},"paperhash":{"value":"zhang|provable_reinforcement_learning_from_human_feedback_with_an_unknown_link_function"}},"id":"fPPypKWsur","forum":"fPPypKWsur","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission46/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission46/Authors"],"number":46,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission46/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756931102739,"cdate":1756931102739,"tmdate":1764510123778,"mdate":1764510123778,"pdate":1764306352137,"odate":1764510123761,"version":2},{"content":{"title":{"value":"Robust Offline Reinforcement Learning with Linearly Structured f-Divergence Regularization"},"authors":{"value":["Cheng Tang","Zhishuai Liu","Pan Xu"]},"authorids":{"value":["~Cheng_Tang11","~Zhishuai_Liu1","~Pan_Xu1"]},"keywords":{"value":["robust MDP","regularized MDP","offline RL"]},"abstract":{"value":"The Robust Regularized Markov Decision Process (RRMDP) is proposed to learn policies robust to dynamics shifts by adding regularization to the transition dynamics in the value function. Existing methods mostly use unstructured regularization, potentially leading to conservative policies under unrealistic transitions. To address this limitation, we propose a novel framework, the $d$-rectangular linear RRMDP ($d$-RRMDP), which introduces latent structures into both transition kernels and regularization. We focus on offline reinforcement learning, where an agent learns policies from a precollected dataset in the nominal environment. We develop the Robust Regularized Pessimistic Value Iteration (R2PVI) algorithm that employs linear function approximation for robust policy learning in $d$-RRMDPs with $f$-divergence based regularization terms on transition kernels. We provide instance-dependent upper bounds on the suboptimality gap of R2PVI policies, demonstrating that these bounds are influenced by how well the dataset covers state-action spaces visited by the optimal robust policy under robustly admissible transitions. We establish information-theoretic lower bounds to verify that our algorithm is near-optimal. Finally, numerical experiments validate that R2PVI learns robust policies and exhibits superior computational efficiency compared to baseline methods."},"pdf":{"value":"/pdf/e5dc635c4fe79fe549f2d5f0b59fa2b04eda464b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ntang2025robust,\\ntitle={Robust Offline Reinforcement Learning with Linearly Structured f-Divergence Regularization},\\nauthor={Cheng Tang and Zhishuai Liu and Pan Xu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=MymU5Dn6GT}\\n}"},"paperhash":{"value":"tang|robust_offline_reinforcement_learning_with_linearly_structured_fdivergence_regularization"}},"id":"MymU5Dn6GT","forum":"MymU5Dn6GT","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission45/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission45/Authors"],"number":45,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission45/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756928552032,"cdate":1756928552032,"tmdate":1764510123747,"mdate":1764510123747,"pdate":1764306352074,"odate":1764510123733,"version":2},{"content":{"title":{"value":"Neural Decision Rule for Constrained Contextual Stochastic Optimization"},"authors":{"value":["Zhangyi Liu","Zhongling Xu","Feng Liu","Rui Gao","Shuang Li"]},"authorids":{"value":["~Zhangyi_Liu1","~Zhongling_Xu1","~Feng_Liu32","~Rui_Gao3","~Shuang_Li3"]},"keywords":{"value":["Contextual Stochastic Optimization","Decision rule","Suboptimality gap"]},"abstract":{"value":"Contextual stochastic optimization is a powerful paradigm for data-driven decision-making under uncertainty, where decisions are tailored to contextual information revealed prior to decision making. Recent advances leverage neural networks to learn expressive decision rules mapping contexts to decisions. However, enforcing feasibility under complex constraints remains a core challenge, as neural architectures do not inherently satisfy constraints in general. \\n  Existing approaches often incur significant computational overhead and lack theoretical guarantees. \\n  In this paper, we propose a principled framework for training neural decision rules under general constraints via a single-loop algorithm that solves the augmented Lagrangian minimax problem. \\n  Our method eliminates the need for iterative projection layers or nested optimization loops, and provides provable guarantees on generalization, constraint violation, and suboptimality. \\n  Empirical results on constrained contextual decision tasks demonstrate that our approach outperforms state-of-the-art baselines in both efficiency and solution quality."},"pdf":{"value":"/pdf/319deca233792738bdf139f62f72d93b3e963c6c.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nliu2025neural,\\ntitle={Neural Decision Rule for Constrained Contextual Stochastic Optimization},\\nauthor={Zhangyi Liu and Zhongling Xu and Feng Liu and Rui Gao and Shuang Li},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=FLD5JWpR67}\\n}"},"paperhash":{"value":"liu|neural_decision_rule_for_constrained_contextual_stochastic_optimization"}},"id":"FLD5JWpR67","forum":"FLD5JWpR67","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission42/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission42/Authors"],"number":42,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission42/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756911543017,"cdate":1756911543017,"tmdate":1764510123615,"mdate":1764510123615,"pdate":1764306351699,"odate":1764510123594,"version":2},{"content":{"title":{"value":"Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing"},"authors":{"value":["Davin Choo","Yuqi Pan","Tonghan Wang","Milind Tambe","Alastair van Heerden","Cheryl Johnson"]},"authorids":{"value":["~Davin_Choo1","~Yuqi_Pan1","~Tonghan_Wang1","~Milind_Tambe1","~Alastair_van_Heerden2","~Cheryl_Johnson1"]},"keywords":{"value":["sequential decision making","graphs","branching bandits","gittins index","network-based testing","public health"]},"TLDR":{"value":"We develop a policy for adaptive exploration on a graph under frontier constraint that is optimal for trees based on Gittins index, and show how we can apply it to network-based testing in public health settings"},"abstract":{"value":"We study a sequential decision-making problem on a $n$-node graph $\\\\mathcal{G}$ where each node has an unknown label from a finite set $\\\\mathbf{\\\\Omega}$, drawn from a joint distribution $\\\\mathcal{P}$ that is Markov with respect to $\\\\mathcal{G}$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $\\\\mathcal{G}$ is a forest. Our implementation runs in $\\\\mathcal{O}(n^2 \\\\cdot |\\\\mathbf{\\\\Omega}|^2)$ time while using $\\\\mathcal{O}(n \\\\cdot |\\\\mathbf{\\\\Omega}|^2)$ oracle calls to $\\\\mathcal{P}$ and $\\\\mathcal{O}(n^2 \\\\cdot |\\\\mathbf{\\\\Omega}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines. Please see https://arxiv.org/abs/2505.21671 for the full version."},"pdf":{"value":"/pdf/9073fc3d95c860b72285e559df643587a8160f49.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nchoo2025adaptive,\\ntitle={Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing},\\nauthor={Davin Choo and Yuqi Pan and Tonghan Wang and Milind Tambe and Alastair van Heerden and Cheryl Johnson},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=XvBgbv3K1W}\\n}"},"paperhash":{"value":"choo|adaptive_frontier_exploration_on_graphs_with_applications_to_networkbased_disease_testing"}},"id":"XvBgbv3K1W","forum":"XvBgbv3K1W","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission40/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission40/Authors"],"number":40,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission40/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756909400573,"cdate":1756909400573,"tmdate":1764510123658,"mdate":1764510123658,"pdate":1764306351459,"odate":1764510123379,"version":2},{"content":{"title":{"value":"Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options"},"authors":{"value":["Joongkyu Lee","Seouh-won Yi","Min-hwan Oh"]},"authorids":{"value":["~Joongkyu_Lee1","~Seouh-won_Yi1","~Min-hwan_Oh1"]},"keywords":{"value":["Preference-based Reinforcement Learning","Ranking Feedback","Plackett–Luce Model","Reinforcement Learning from Human Feedback","Dueling Bandit"]},"TLDR":{"value":"We present the first theoretical analysis of PbRL with ranking feedback, showing that longer ranking feedback can provably improve sample efficiency."},"abstract":{"value":"We study online preference-based reinforcement learning (PbRL) with the goal of improving sample efficiency. While a growing body of theoretical work has emerged—motivated by PbRL’s recent empirical success, particularly in aligning large language models (LLMs)—most existing studies focus only on pairwise comparisons. A few recent works  [Zhu et al., 2023, Mukherjee et al., 2024, Thekumparampil et al., 2024]  have explored using multiple comparisons and ranking feedback, but their performance guarantees fail to improve—and can even deteriorate—as the feedback length increases, despite the richer information available. To address this gap, we adopt the Plackett–Luce (PL) model for ranking feedback over action subsets and propose **M-AUPO**, an algorithm that selects multiple actions by maximizing the average uncertainty within the offered subset. We prove that **M-AUPO** achieves a suboptimality gap of $\\\\tilde{\\\\mathcal O}\\\\left( \\\\frac{d}{T} \\\\sqrt{ \\\\sum_{t=1}^T \\\\frac{1}{|S_t|}} \\\\right)$, where $T$ is the total number of rounds, $d$ is the feature dimension, and $|S_t|$ is the size of the subset at round $t$. This result shows that larger subsets directly lead to improved performance and, notably, the bound avoids the exponential dependence on the unknown parameter’s norm, which was a fundamental limitation in most previous works. Moreover, we establish a near-matching lower bound of $\\\\Omega \\\\left( \\\\frac{d}{K \\\\sqrt{T}} \\\\right)$, where $K$ is the maximum subset size. To the best of our knowledge, this is the first theoretical result in PbRL with ranking feedback that explicitly shows improved sample efficiency as a function of the subset size."},"pdf":{"value":"/pdf/b1716951da0218ac635c75fddc86d33ad814d7e3.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlee2025preferencebased,\\ntitle={Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options},\\nauthor={Joongkyu Lee and Seouh-won Yi and Min-hwan Oh},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=TDrHTzof2G}\\n}"},"paperhash":{"value":"lee|preferencebased_reinforcement_learning_beyond_pairwise_comparisons_benefits_of_multiple_options"}},"id":"TDrHTzof2G","forum":"TDrHTzof2G","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission39/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission39/Authors"],"number":39,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission39/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756909398286,"cdate":1756909398286,"tmdate":1764510123395,"mdate":1764510123395,"pdate":1764306351368,"odate":1764510123377,"version":2},{"content":{"title":{"value":"Reinforcement Learning for Intensity Control: An Application to Choice-Based Network Revenue Management"},"authors":{"value":["Huiling Meng","Ningyuan Chen","Xuefeng Gao"]},"authorids":{"value":["~Huiling_Meng1","~Ningyuan_Chen1","~Xuefeng_Gao1"]},"keywords":{"value":["reinforcement learning","continuous time","discretization","revenue management"]},"abstract":{"value":"Intensity control is a type of continuous-time dynamic optimization problems with important applications in Operations Research. In this study, we adapt the reinforcement learning framework to intensity control using choice-based network revenue management as a case study, which is a classical problem in revenue management that features a large state space, a large action space and a continuous time horizon. We show that the inherent discretization from jump points, a key feature of intensity control, eliminates the need to discretize the time horizon upfront, which was believed to be necessary because most reinforcement learning algorithms are designed for discrete-time problems. This facilitates computation and significantly reduces discretization error. We lay the theoretical foundation for policy evaluation and develop policy-gradient-based actor-critic algorithms for intensity control. A comprehensive numerical study demonstrates the benefit of our approach versus state-of-the-art benchmarks."},"pdf":{"value":"/pdf/29d6e8ab013d16d4ee881f22cef8bebc57f06beb.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmeng2025reinforcement,\\ntitle={Reinforcement Learning for Intensity Control: An Application to Choice-Based Network Revenue Management},\\nauthor={Huiling Meng and Ningyuan Chen and Xuefeng Gao},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=AMgAd1mKTp}\\n}"},"paperhash":{"value":"meng|reinforcement_learning_for_intensity_control_an_application_to_choicebased_network_revenue_management"}},"id":"AMgAd1mKTp","forum":"AMgAd1mKTp","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission37/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission37/Authors"],"number":37,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission37/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756884292061,"cdate":1756884292061,"tmdate":1764510123293,"mdate":1764510123293,"pdate":1764306351028,"odate":1764510123275,"version":2},{"content":{"title":{"value":"Policy Gradient Optimization for Markov Decision Processes with Epistemic Uncertainty and General Loss Functions"},"authors":{"value":["Xiaoshuang Wang","Yifan Lin","Enlu Zhou"]},"authorids":{"value":["~Xiaoshuang_Wang1","~Yifan_Lin1","~Enlu_Zhou1"]},"keywords":{"value":["Reinforcement Learning","Convex RL","Policy Gradient","Bayesian Method"]},"abstract":{"value":"Motivated by many application problems, we consider Markov decision processes (MDPs) with a general loss function and unknown parameters. To mitigate the epistemic uncertainty associated with unknown parameters, we take a Bayesian approach to estimate the parameters from data and impose a coherent risk functional (with respect to the Bayesian posterior distribution) on the loss. Since this formulation usually does not satisfy the interchangeability principle, it does not admit Bellman equations and cannot be solved by approaches based on dynamic programming. Therefore, We propose a policy gradient optimization method, leveraging the dual representation of coherent risk measures and extending the envelope theorem to continuous cases. We then show the stationary analysis of the algorithm with a convergence rate of  $\\\\mathcal{O}(T^{-1/2}+r^{-1/2})$, where $T$  is the number of  policy gradient iterations and $r$ is the sample size of the gradient estimator. We further extend our algorithm to an episodic setting, and establish the global convergence of the extended algorithm and provide bounds on the number of iterations needed to achieve an error bound $\\\\mathcal{O}(\\\\epsilon)$  in each episode."},"pdf":{"value":"/pdf/6d72225d38c11281c5f34edfb967e023e4356fd7.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwang2025policy,\\ntitle={Policy Gradient Optimization for Markov Decision Processes with Epistemic Uncertainty and General Loss Functions},\\nauthor={Xiaoshuang Wang and Yifan Lin and Enlu Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=UPOkMlT7qY}\\n}"},"paperhash":{"value":"wang|policy_gradient_optimization_for_markov_decision_processes_with_epistemic_uncertainty_and_general_loss_functions"}},"id":"UPOkMlT7qY","forum":"UPOkMlT7qY","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission35/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission35/Authors"],"number":35,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission35/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756863953296,"cdate":1756863953296,"tmdate":1764510123269,"mdate":1764510123269,"pdate":1764306350807,"odate":1764510123252,"version":2},{"content":{"title":{"value":"Learning Fair And Effective Points-Based Rewards Programs"},"authors":{"value":["Chamsi Hssaine","Yichun Hu","Ciara Pike-Burke"]},"authorids":{"value":["~Chamsi_Hssaine1","~Yichun_Hu1","~Ciara_Pike-Burke2"]},"keywords":{"value":["revenue management","rewards programs","fairness","online learning"]},"abstract":{"value":"Points-based rewards programs are a prevalent way to incentivize customer loyalty. In these programs, customers who make repeated purchases from a seller accumulate points, working toward eventual redemption of a free reward. While they can generate significant revenue gains for the seller if implemented correctly, these programs have come under scrutiny of late due to accusations of unfair practices in their implementation. Motivated by these real-world concerns, this paper studies the problem of {\\\\it fairly} designing points-based rewards programs, with a special focus on two major obstacles that put fairness at odds with their effectiveness: (i) the incentive to exploit customer heterogeneity by personalizing programs to customers' purchase behavior, and (ii) risks of devaluing customers' previously earned points when sellers need to experiment in uncertain environments. To study this problem, we focus on the popular \\"Buy $N$, Get One Free\\" (BNGO) rewards programs. We first show that the optimal \\\\emph{individually fair} program that uses the same redemption threshold for all customers suffers from a constant factor loss in revenue of at most $1+\\\\ln 2$, compared to the optimal personalized strategy which may unfairly offer different customers different thresholds. We then tackle the problem of designing {\\\\it temporally fair} learning algorithms in the presence of demand uncertainty.\\nToward this goal, we design a \\"stable\\" learning algorithm that limits the risk of point devaluation due to experimentation by only changing the redemption threshold $O(\\\\log T)$ times, over a learning horizon of length $T$. We prove that this algorithm incurs $\\\\widetilde{O}(\\\\sqrt{T})$ regret in expectation; this guarantee is optimal, up to polylogarithmic factors. We then modify this algorithm to ever only decrease redemption thresholds, leading to improved fairness at a cost of only a constant factor in regret. Finally, we conduct extensive numerical experiments to show the limited value of personalization in average-case settings, in addition to demonstrating the strong practical performance of our proposed learning algorithms."},"pdf":{"value":"/pdf/8e6df605b6810337098ff472fef7073c079f697a.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhssaine2025learning,\\ntitle={Learning Fair And Effective Points-Based Rewards Programs},\\nauthor={Chamsi Hssaine and Yichun Hu and Ciara Pike-Burke},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=RPvRCt4UdL}\\n}"},"paperhash":{"value":"hssaine|learning_fair_and_effective_pointsbased_rewards_programs"}},"id":"RPvRCt4UdL","forum":"RPvRCt4UdL","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission33/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission33/Authors"],"number":33,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission33/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756845152659,"cdate":1756845152659,"tmdate":1764510123157,"mdate":1764510123157,"pdate":1764306350476,"odate":1764510123139,"version":2},{"content":{"title":{"value":"Data-Driven Sequential Search"},"authors":{"value":["David Brown","Cagin Uru"]},"authorids":{"value":["~David_Brown1","~Cagin_Uru1"]},"keywords":{"value":["Sequential Search","Robust Search","Prior-Free Search","Competitive Ratio","Maximin Ratio"]},"abstract":{"value":"We consider a sequential search problem where the distribution of alternative values is unknown. In our data-driven setting, feasible policies are based solely on the history of explored alternative values. We seek to identify a policy that maximizes the worst-case ratio of expected reward compared to an oracle (referred to as \\\\emph{Pandora}) with full knowledge of the value distribution. We design static policies that commit to a prespecified number of explorations. We show that these policies guarantee a competitive ratio of at least $1/e \\\\approx 37$% of the Pandora benchmark for any arbitrary value distribution. Our approach involves studying nature's problem to select a distribution to counter a policy and identifying worst-case distributions. Moreover, we study how the structure of the unknown value distribution influences achievable performance guarantees by considering a setting where feasible distributions belong to the class of monotone hazard rate distributions, where we improve our guarantee to $(e/(e+1))^2 \\\\approx 53$% of the Pandora benchmark. We show that static policies are especially effective against smaller classes of unknown distributions, guaranteeing at least $e/(e+1) \\\\approx 73$% against exponential distributions with an unknown rate and $9/(8(4-\\\\sqrt{7})) \\\\approx 83$% against uniform distributions with an unknown maximum. In the latter case, we show that static policies achieve the best possible performance among all feasible policies, including the dynamic ones. Finally, we derive performance limits for all feasible policies to further highlight the efficiency and robustness of our static policies for data-driven search problems."},"pdf":{"value":"/pdf/ea3847e9a329d70b9dc9190cb203b8a9673dccd9.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbrown2025datadriven,\\ntitle={Data-Driven Sequential Search},\\nauthor={David Brown and Cagin Uru},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=5praJBdTKf}\\n}"},"paperhash":{"value":"brown|datadriven_sequential_search"}},"id":"5praJBdTKf","forum":"5praJBdTKf","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission32/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission32/Authors"],"number":32,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission32/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756840952827,"cdate":1756840952827,"tmdate":1764510123133,"mdate":1764510123133,"pdate":1764306350377,"odate":1764510123107,"version":2},{"content":{"title":{"value":"Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow"},"authors":{"value":["Andrew W. Rosemberg","Michael Klamkin","Pascal Van Hentenryck"]},"authorids":{"value":["~Andrew_W._Rosemberg1","~Michael_Klamkin1","~Pascal_Van_Hentenryck2"]},"keywords":{"value":["differentiable optimization","optimization learning","optimal power flow"]},"abstract":{"value":"The growing scale of power systems and the increasing uncertainty introduced by renewable energy sources necessitates novel optimization techniques that are significantly faster and more accurate than existing methods. The AC Optimal Power Flow (AC-OPF) problem, a core component of power grid optimization, is often approximated using linearized DC Optimal Power Flow (DC-OPF) models for computational tractability, albeit at the cost of suboptimal and inefficient decisions. To address these limitations, we propose a novel deep learning-based framework for network equivalency that enhances DC-OPF to more closely mimic the behavior of AC-OPF. The approach utilizes recent advances in differentiable optimization, incorporating a neural network trained to predict adjusted nodal shunt conductances and branch susceptances in order to account for nonlinear power flow behavior. The model can be trained end-to-end using modern deep learning frameworks by leveraging the implicit function theorem. Results demonstrate the framework's ability to significantly improve prediction accuracy."},"pdf":{"value":"/pdf/731fb45b5c3985f11bf7eb374e7f7caa0528cefc.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nrosemberg2025differentiable,\\ntitle={Differentiable Optimization for Deep Learning-Enhanced {DC} Approximation of {AC} Optimal Power Flow},\\nauthor={Andrew W. Rosemberg and Michael Klamkin and Pascal Van Hentenryck},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Htn3s8yUOg}\\n}"},"paperhash":{"value":"rosemberg|differentiable_optimization_for_deep_learningenhanced_dc_approximation_of_ac_optimal_power_flow"}},"id":"Htn3s8yUOg","forum":"Htn3s8yUOg","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission31/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission31/Authors"],"number":31,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission31/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756838566125,"cdate":1756838566125,"tmdate":1764510123131,"mdate":1764510123131,"pdate":1764306350307,"odate":1764510123061,"version":2},{"content":{"title":{"value":"Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction"},"authors":{"value":["Yiting He","Zhishuai Liu","Weixin Wang","Pan Xu"]},"authorids":{"value":["~Yiting_He1","~Zhishuai_Liu1","~Weixin_Wang2","~Pan_Xu1"]},"keywords":{"value":["robust mdp","online interaction"]},"abstract":{"value":"Off-dynamics reinforcement learning (RL), where training and deployment transition dynamics are different, can be formulated as learning in a robust Markov decision process (RMDP) where uncertainties in transition dynamics are imposed. Existing literature mostly assumes access to generative models allowing arbitrary state-action queries or pre-collected datasets with a good state coverage of the deployment environment, bypassing the challenge of exploration. In this work, we study a more realistic and challenging setting where the agent is limited to online interaction with the training environment. To capture the intrinsic difficulty of exploration in online RMDPs, we introduce the supremal visitation ratio, a novel quantity that measures the mismatch between the training dynamics and the deployment dynamics. We show that if this ratio is unbounded, online learning becomes exponentially hard. We propose the first computationally efficient algorithm that achieves sublinear regret in online RMDPs with $f$-divergence based transition uncertainties. We also establish matching regret lower bounds, demonstrating that our algorithm achieves optimal dependence on both the supremal visitation ratio and the number of interaction episodes. Finally, we validate our theoretical results through comprehensive numerical experiments."},"pdf":{"value":"/pdf/32392060b06453354f3976c2ea741a05950def9c.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nhe2025sample,\\ntitle={Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction},\\nauthor={Yiting He and Zhishuai Liu and Weixin Wang and Pan Xu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=E6SF0NGwlr}\\n}"},"paperhash":{"value":"he|sample_complexity_of_distributionally_robust_offdynamics_reinforcement_learning_with_online_interaction"}},"id":"E6SF0NGwlr","forum":"E6SF0NGwlr","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission30/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission30/Authors"],"number":30,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission30/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756837971034,"cdate":1756837971034,"tmdate":1764510123059,"mdate":1764510123059,"pdate":1764306350234,"odate":1764510123040,"version":2},{"content":{"title":{"value":"Heterogeneous Treatment Effects in Panel Data"},"authors":{"value":["Retsef Levi","Elisabeth Paulson","Georgia Perakis","Emily Yi Zhang"]},"authorids":{"value":["~Retsef_Levi1","~Elisabeth_Paulson1","~Georgia_Perakis1","~Emily_Yi_Zhang1"]},"keywords":{"value":["Causal Inference","Heterogeneous Treatment Effects","Low-Rank Matrix Completion","Panel Data"]},"TLDR":{"value":"A novel estimator for heterogeneous treatment effects in panel data with general treatment patterns."},"abstract":{"value":"We address a core problem in causal inference: estimating heterogeneous treatment effects (HTEs) using panel data with general treatment patterns. Many existing methods either do not utilize the potential underlying structure in panel data or have limitations in the allowable treatment patterns. In this work, we propose and evaluate a new method that first partitions observations into disjoint clusters with similar treatment effects using a regression tree, and then leverages the underlying structure of the panel data to estimate the average treatment effect (ATE) for each cluster. Computation experiments with semi-synthetic data show that our method achieves superior accuracy for ATE and HTE estimation compared to alternative approaches. This performance was achieved using a regression tree with no more than 40 leaves, making the method both accurate and interpretable, and a strong candidate for practical applications."},"pdf":{"value":"/pdf/5ac621a121c722ca97a1bef501b5895e2426f253.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlevi2025heterogeneous,\\ntitle={Heterogeneous Treatment Effects in Panel Data},\\nauthor={Retsef Levi and Elisabeth Paulson and Georgia Perakis and Emily Yi Zhang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=z0zw9yWl32}\\n}"},"paperhash":{"value":"levi|heterogeneous_treatment_effects_in_panel_data"}},"id":"z0zw9yWl32","forum":"z0zw9yWl32","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission28/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission28/Authors"],"number":28,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission28/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756823192897,"cdate":1756823192897,"tmdate":1764510122954,"mdate":1764510122954,"pdate":1764306350101,"odate":1764510122933,"version":2},{"content":{"title":{"value":"Data-driven generative simulation of SDEs using diffusion models"},"authors":{"value":["Xuefeng Gao","Jiale Zha","XUNYU ZHOU"]},"authorids":{"value":["~Xuefeng_Gao1","~Jiale_Zha1","~XUNYU_ZHOU1"]},"keywords":{"value":["Conditional diffusion model","SDE simulation","mean–variance portfolio selection"]},"abstract":{"value":"This paper introduces a new approach to generating sample paths of stochastic differential equations (SDEs) using diffusion models, a class of generative AI models commonly employed in image and video applications. Unlike traditional Monte Carlo methods, which require explicit specification of the drift and diffusion coefficients of the SDE, our method takes a model-free approach. Given a finite set of sample paths from an unknown SDE, we propose a data-driven framework that utilizes conditional diffusion models to generate new, synthetic paths of the same SDE. To demonstrate the effectiveness of our approach, we conduct comprehensive experiments on various SDEs and compare its performance with alternative benchmark methods including neural SDEs. Furthermore, we explore the potential of leveraging these synthetically generated sample paths to enhance the performance of reinforcement learning algorithms in continuous-time mean-variance portfolio selection, hinting at promising applications of diffusion models in financial analysis and decision-making."},"pdf":{"value":"/pdf/795ecd9e09490f7e91bb14beb3d5f409809c9db8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ngao2025datadriven,\\ntitle={Data-driven generative simulation of {SDE}s using diffusion models},\\nauthor={Xuefeng Gao and Jiale Zha and XUNYU ZHOU},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Zajo3qeoIu}\\n}"},"paperhash":{"value":"gao|datadriven_generative_simulation_of_sdes_using_diffusion_models"}},"id":"Zajo3qeoIu","forum":"Zajo3qeoIu","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission27/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission27/Authors"],"number":27,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission27/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756820545600,"cdate":1756820545600,"tmdate":1764510122952,"mdate":1764510122952,"pdate":1764306350060,"odate":1764510122931,"version":2},{"content":{"title":{"value":"A Variance-Adaptive Lower Bound for Simulation Optimization in Continuous Space"},"authors":{"value":["Jianzhong Du","L. Jeff Hong"]},"authorids":{"value":["~Jianzhong_Du1","~L._Jeff_Hong1"]},"keywords":{"value":["simulation optimization","black-box optimization","complexity analysis"]},"abstract":{"value":"This paper considers the simulation optimization with continuous decision variables. Under certain reasonable assumptions, we provide a worst-case lower bound on the optimization error for any algorithms. The lower bound can incorporate the noiseless and noisy problems in an unified framework. The result highlights that the optimization error of noisy problems can be very close to that of noiseless problems when the observation's variance is small and the budget is not very large."},"pdf":{"value":"/pdf/01ea8d7a766d249cec5c0fc022c407e669fdf803.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndu2025a,\\ntitle={A Variance-Adaptive Lower Bound for Simulation Optimization in Continuous Space},\\nauthor={Jianzhong Du and L. Jeff Hong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=AToWZd92yY}\\n}"},"paperhash":{"value":"du|a_varianceadaptive_lower_bound_for_simulation_optimization_in_continuous_space"}},"id":"AToWZd92yY","forum":"AToWZd92yY","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission26/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission26/Authors"],"number":26,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission26/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756818911366,"cdate":1756818911366,"tmdate":1764510122924,"mdate":1764510122924,"pdate":1764306349968,"odate":1764510122909,"version":2},{"content":{"title":{"value":"Gala: Global LLM Agents for Text-to-Model Translation"},"authors":{"value":["Junyang Cai","Serdar Kadioglu","Bistra Dilkina"]},"authorids":{"value":["~Junyang_Cai1","~Serdar_Kadioglu1","~Bistra_Dilkina2"]},"keywords":{"value":["language model","constraint programming"]},"abstract":{"value":"Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce Gala, a framework that addresses this challenge with a global agentic approach: multiple specialized large language model (LLM) agents decompose the modeling task by global constraint type. Each agent is dedicated to detecting and generating code for a specific class of global constraint, while a final assembler agent integrates these constraint snippets into a complete MiniZinc model. By dividing the problem into smaller, well-defined sub-tasks, each LLM handles a simpler reasoning challenge, potentially reducing overall complexity. We conduct initial experiments with several LLMs and show better performance against baselines such as one-shot prompting and chain-of-thought prompting. Finally, we outline a comprehensive roadmap for future work, highlighting potential enhancements and directions for improvement."},"pdf":{"value":"/pdf/e21ad3cb670621ac0ee3c1220afe131c1e8de482.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ncai2025gala,\\ntitle={Gala: Global {LLM} Agents for Text-to-Model Translation},\\nauthor={Junyang Cai and Serdar Kadioglu and Bistra Dilkina},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=VD59fu9pEE}\\n}"},"paperhash":{"value":"cai|gala_global_llm_agents_for_texttomodel_translation"}},"id":"VD59fu9pEE","forum":"VD59fu9pEE","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission25/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission25/Authors"],"number":25,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission25/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756760758599,"cdate":1756760758599,"tmdate":1764510122784,"mdate":1764510122784,"pdate":1764306349902,"odate":1764510122744,"version":2},{"content":{"title":{"value":"Algorithmic Aspects of Strategic Trading"},"authors":{"value":["Michael Kearns","Mirah Shi"]},"authorids":{"value":["~Michael_Kearns2","~Mirah_Shi1"]},"keywords":{"value":["algorithmic trading","position building","algorithmic game theory","equilibrium computation"]},"abstract":{"value":"Algorithmic trading in modern financial markets is widely acknowledged to exhibit strategic, game-theoretic behaviors whose complexity can be difficult to model. A recent series of papers (Chriss, 2024b,c,a, 2025) has made progress in the setting of trading for position building. Here parties wish to buy or sell a fixed number of shares in a fixed time period in the presence of both temporary and permanent market impact, resulting in exponentially large strategy spaces. While these papers primarily consider the existence and structural properties of equilibrium strategies, in this work we focus on the algorithmic aspects of the proposed model. We give an efficient algorithm for computing best responses, and show that while the temporary impact only setting yields a potential game, best response dynamics do not generally converge for the general setting, for which no fast algorithm for (Nash) equilibrium computation is known. This leads us to consider the broader notion of Coarse Correlated Equilibria (CCE), which we show can be computed efficiently via an implementation of Follow the Perturbed Leader (FTPL). We illustrate the model and our results with an experimental investigation, where FTPL exhibits interesting behavior in different regimes of the relative weighting between temporary and permanent market impact."},"pdf":{"value":"/pdf/fd78871d6934a5430a928b6f4e3dd99ee26d7b0d.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nkearns2025algorithmic,\\ntitle={Algorithmic Aspects of Strategic Trading},\\nauthor={Michael Kearns and Mirah Shi},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=EcETTQXyJJ}\\n}"},"paperhash":{"value":"kearns|algorithmic_aspects_of_strategic_trading"}},"id":"EcETTQXyJJ","forum":"EcETTQXyJJ","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission23/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission23/Authors"],"number":23,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission23/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756742614096,"cdate":1756742614096,"tmdate":1764510122744,"mdate":1764510122744,"pdate":1764306349833,"odate":1764510122724,"version":2},{"content":{"title":{"value":"Landmark-Based Node Representations for Shortest Path Distance Approximations in Random Graphs"},"authors":{"value":["My Le","Luana Ruiz","Souvik Dhara"]},"authorids":{"value":["~My_Le1","~Luana_Ruiz1","~Souvik_Dhara1"]},"keywords":{"value":["graph embedding","node embedding","random graphs","Erdős–Rényi","shortest path","landmark algorithms","graph neural networks","global distance","graph distortion"]},"TLDR":{"value":"Landmark-based embeddings preserve global distances in graphs more efficiently; on Erdős–Rényi random graphs they need lower dimensions, and GNNs generalize these embeddings to large real-world networks."},"abstract":{"value":"Learning node representations is a fundamental problem in graph machine learning. While existing embedding methods effectively preserve local similarity measures, they often fail to capture global functions like graph distances. Inspired by Bourgain's seminal work on Hilbert space embeddings of metric spaces (1985), we study the performance of local distance-preserving node embeddings. Known as landmark-based algorithms, these embeddings approximate pairwise distances by computing shortest paths from a small subset of reference nodes called landmarks. Our main theoretical contribution shows that random graphs, such as Erdős–Rényi random graphs, require lower dimensions in landmark-based embeddings compared to worst-case graphs. Empirically, we demonstrate that the GNN-based approximations for the distances to landmarks generalize well to larger real-world networks, offering a scalable and transferable alternative for graph representation learning."},"pdf":{"value":"/pdf/82a6ed1bd9c7278a394a111c2d3fef7fdf10d078.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nle2025landmarkbased,\\ntitle={Landmark-Based Node Representations for Shortest Path Distance Approximations in Random Graphs},\\nauthor={My Le and Luana Ruiz and Souvik Dhara},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=kVGRUNs8F0}\\n}"},"paperhash":{"value":"le|landmarkbased_node_representations_for_shortest_path_distance_approximations_in_random_graphs"}},"id":"kVGRUNs8F0","forum":"kVGRUNs8F0","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission22/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission22/Authors"],"number":22,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission22/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756739650716,"cdate":1756739650716,"tmdate":1764510122738,"mdate":1764510122738,"pdate":1764306349737,"odate":1764510122713,"version":2},{"content":{"title":{"value":"Learning to Handle Constraints in Routing Problems via a Construct-and-Refine Framework"},"authors":{"value":["Jieyi Bi","Zhiguang Cao","Jianan Zhou","Wen Song","Yaoxin Wu","Jie Zhang","Yining Ma","Cathy Wu"]},"authorids":{"value":["~Jieyi_Bi1","~Zhiguang_Cao1","~Jianan_Zhou1","~Wen_Song1","~Yaoxin_Wu2","~Jie_Zhang9","~Yining_Ma1","~Cathy_Wu1"]},"keywords":{"value":["Neural combinatorial optimization","Vehicle Routing Problems","Constraint Handling","Deep Reinforcement Learning"]},"TLDR":{"value":"We present Construct-and-Refine (CaR), a simple, efficient, and general neural framework to handle complex constraints in Vehicle Routing Problems."},"abstract":{"value":"Neural solvers have achieved impressive progress on simple routing problems via data-driven training, but often struggle with complex constraints. We rethink the popular single-paradigm neural solvers and identify paradigm-inherent limitations: construction solvers suffer from inflexible stepwise feasibility, and improvement solvers easily get stuck in infeasible searches with long runtimes. However, these paradigms are naturally complementary: construction efficiently provides strong initial solutions that help improvement rapidly reach feasible, high-quality solutions. Motivated by this, we propose Construct-and-Refine (CaR), the first generic neural framework for efficient constraint handling, compatible with existing construction and improvement solvers. To promote synergistic paradigm integration, we introduce a joint training framework with bespoke losses to generate diverse, high-quality, (near)-feasible solutions that are refined by a light improvement process (e.g., only 10 steps down from 5k). We also present the first study of a shared encoder for cross-paradigm representation learning in handling complex constraints. Extensive experiments on hard-constrained TSPTW and CVRPBLTW demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both traditional and neural state-of-the-art solvers."},"pdf":{"value":"/pdf/fa4186dc599b3bacddf1ac52b18a07372b709722.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbi2025learning,\\ntitle={Learning to Handle Constraints in Routing Problems via a Construct-and-Refine Framework},\\nauthor={Jieyi Bi and Zhiguang Cao and Jianan Zhou and Wen Song and Yaoxin Wu and Jie Zhang and Yining Ma and Cathy Wu},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Rs6OoGgUIM}\\n}"},"paperhash":{"value":"bi|learning_to_handle_constraints_in_routing_problems_via_a_constructandrefine_framework"}},"id":"Rs6OoGgUIM","forum":"Rs6OoGgUIM","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission21/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission21/Authors"],"number":21,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission21/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756709632853,"cdate":1756709632853,"tmdate":1764510122626,"mdate":1764510122626,"pdate":1764306349734,"odate":1764510122610,"version":2},{"content":{"title":{"value":"Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain"},"authors":{"value":["Shengbo Wang","Nian Si"]},"authorids":{"value":["~Shengbo_Wang1","~Nian_Si1"]},"keywords":{"value":["robust Markov decision processes","long-run average reward","dynamic programming","Bellman equation"]},"abstract":{"value":"Learning and optimal control under robust Markov decision processes (MDPs) have received increasing attention, yet most existing theory, algorithms, and applications focus on finite-horizon or discounted models. The average-reward formulation, while natural in many operations research and management contexts, remains underexplored. This is primarily because the dynamic programming foundations are technically challenging and only partially understood, with several fundamental questions remaining open. This paper steps toward a general framework for average-reward robust MDPs by analyzing the constant-gain setting. We study the average-reward robust control problem with possible information asymmetries between the controller and an S-rectangular adversary. Our analysis centers on the constant-gain robust Bellman equation, examining both the existence of solutions and their relationship to the optimal average reward. Specifically, we identify when solutions to the robust Bellman equation characterize the optimal average reward and stationary policies, and we provide sufficient conditions ensuring solutions' existence. These findings expand the dynamic programming theory for average-reward robust MDPs and lay a foundation for robust dynamic decision making under long-run average criteria in operational environments."},"pdf":{"value":"/pdf/d0f44be7db4b7eb0f7aaffd3c4be84866fa9d681.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nwang2025bellman,\\ntitle={Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain},\\nauthor={Shengbo Wang and Nian Si},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=D8TYyKjCnK}\\n}"},"paperhash":{"value":"wang|bellman_optimality_of_averagereward_robust_markov_decision_processes_with_a_constant_gain"}},"id":"D8TYyKjCnK","forum":"D8TYyKjCnK","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission19/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission19/Authors"],"number":19,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756587961712,"cdate":1756587961712,"tmdate":1764510122593,"mdate":1764510122593,"pdate":1764306349500,"odate":1764510122573,"version":2},{"content":{"title":{"value":"Contextual Value Iteration and Deep Approximation for Bayesian Contextual Bandits"},"authors":{"value":["Kevin Duijndam","Ger Koole","Rob van der Mei"]},"authorids":{"value":["~Kevin_Duijndam1","~Ger_Koole1","~Rob_van_der_Mei1"]},"keywords":{"value":["Contextual Multi-Armed Bandit","Bayesian Belief MDP","Value Iteration","Deep Value Function Approximation","Online Learning"]},"TLDR":{"value":"We formulate contextual bandit problems as Bayesian belief-MDPs and solve them by value iteration—exactly on small grids, and via a dual-stream neural network value function for scale—achieving low regret on pricing and arm-uncertainty benchmarks."},"abstract":{"value":"We present a Bayesian value-iteration framework for contextual multi-armed bandit problems that treats the agent’s posterior distribution for the pay-off as the state of the Markov Decision Process. We apply finite-dimensional priors on the unknown reward parameters, and the exogenous context transition kernel. Value iteration on the belief-MDP yields an optimal policy. We illustrate the approach in an airline seat-pricing simulation. To address the curse of dimensionality, we approximate the value function with a dual-stream deep learning network and benchmark our deep value iteration algorithm on a standard contextual bandit instance."},"pdf":{"value":"/pdf/7e2ec762cc79aae38f7f8716fcf2d372d6d5c583.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nduijndam2025contextual,\\ntitle={Contextual Value Iteration and Deep Approximation for Bayesian Contextual Bandits},\\nauthor={Kevin Duijndam and Ger Koole and Rob van der Mei},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=WUCH2MsovX}\\n}"},"paperhash":{"value":"duijndam|contextual_value_iteration_and_deep_approximation_for_bayesian_contextual_bandits"}},"id":"WUCH2MsovX","forum":"WUCH2MsovX","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission18/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission18/Authors"],"number":18,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission18/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756557374972,"cdate":1756557374972,"tmdate":1764510122552,"mdate":1764510122552,"pdate":1764306349497,"odate":1764510122535,"version":2},{"content":{"title":{"value":"Optimizing LLM Inference: Fluid-Based Online Scheduling under Memory Constraints"},"authors":{"value":["Ruicheng Ao","Gan Luo","David Simchi-Levi","Xinshang Wang"]},"authorids":{"value":["~Ruicheng_Ao1","~Gan_Luo1","~David_Simchi-Levi2","~Xinshang_Wang1"]},"keywords":{"value":["Large Lanugage Model","Key-value cache","Memory Constraint","Online scheduling"]},"TLDR":{"value":"LLM inference scheduling with KV-cache memory constraints"},"abstract":{"value":"Large Language Model (LLM) inference faces unique scheduling challenges due to the dynamically growing Key-Value (KV) cache during token generation, making traditional scheduling algorithms ineffective. We develop a fluid dynamics approximation to establish an optimal throughput benchmark and propose the WAIT (Waiting for Accumulated Inference Threshold) algorithm that achieves near-optimal performance with near-optimal throughput gap. For practical scenarios with unknown output lengths, we introduce Nested WAIT that maintains asymptotic optimality through hierarchical segmentation. Experiments on Llama-7B demonstrate 20-30\\\\% throughput improvements over state-of-the-art systems like vLLM."},"pdf":{"value":"/pdf/a057e2e9f64d93251ecad067be8014c4e9a4366b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nao2025optimizing,\\ntitle={Optimizing {LLM} Inference: Fluid-Based Online Scheduling under Memory Constraints},\\nauthor={Ruicheng Ao and Gan Luo and David Simchi-Levi and Xinshang Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=LFlsYLfkM8}\\n}"},"paperhash":{"value":"ao|optimizing_llm_inference_fluidbased_online_scheduling_under_memory_constraints"}},"id":"LFlsYLfkM8","forum":"LFlsYLfkM8","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission17/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission17/Authors"],"number":17,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission17/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756495351722,"cdate":1756495351722,"tmdate":1764510122468,"mdate":1764510122468,"pdate":1764306349480,"odate":1764510122454,"version":2},{"content":{"title":{"value":"Post-Estimation Adjustments in Data-Driven Decision-Making with Applications in Pricing"},"authors":{"value":["Michael Albert","Max Biggs","Ningyuan Chen","Guan Wang"]},"authorids":{"value":["~Michael_Albert1","biggsm@darden.virginia.edu","~Ningyuan_Chen1","~Guan_Wang12"]},"keywords":{"value":["predict-then-optimize","data-driven decision making","pricing"]},"TLDR":{"value":"We propose a systematic post-estimation adjustment correcting PTO’s asymmetric bias, with a closed form under a simple curvature condition."},"abstract":{"value":"The predict-then-optimize (PTO) framework is a standard approach in data-driven decision-making, where a decision-maker first estimates an unknown parameter from historical data and then uses this estimate to solve an optimization problem. While widely used for its simplicity and modularity, PTO can lead to suboptimal decisions because the estimation step does not account for the structure of the downstream optimization problem. We study a class of problems where the objective function, evaluated at the PTO decision, is asymmetric with respect to estimation errors. This asymmetry causes the expected outcome to be systematically degraded by noise in the parameter estimate, as the penalty for underestimation differs from that of overestimation. To address this, we develop a data-driven post-estimation adjustment that improves decision quality while preserving the practicality and modularity of PTO. We show that when the objective function satisfies a particular curvature condition, based on the ratio of its third and second derivatives, the adjustment simplifies to a closed-form expression. This condition holds for a broad range of pricing problems, including those with linear, log-linear, and power-law demand models. Under this condition, we establish theoretical guarantees that our adjustment uniformly and asymptotically outperforms standard PTO, and we precisely characterize the resulting improvement. Additionally, we extend our framework to multi-parameter optimization settings. Numerical pricing experiments demonstrate that our method consistently improves revenue, particularly in small-sample regimes where estimation uncertainty is most pronounced. This makes our approach especially well-suited for pricing new products or in settings with limited historical price variation."},"pdf":{"value":"/pdf/18344c30958cf19e7545df98ab5a5990487aac95.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nalbert2025postestimation,\\ntitle={Post-Estimation Adjustments in Data-Driven Decision-Making with Applications in Pricing},\\nauthor={Michael Albert and Max Biggs and Ningyuan Chen and Guan Wang},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=BgG7j4mQUY}\\n}"},"paperhash":{"value":"albert|postestimation_adjustments_in_datadriven_decisionmaking_with_applications_in_pricing"}},"id":"BgG7j4mQUY","forum":"BgG7j4mQUY","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission14/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission14/Authors"],"number":14,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission14/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756252264555,"cdate":1756252264555,"tmdate":1764510122336,"mdate":1764510122336,"pdate":1764306349262,"odate":1764510122321,"version":2},{"content":{"title":{"value":"Structure-Informed Deep Reinforcement Learning for Inventory Management"},"authors":{"value":["Alvaro Maggiar","Sohrab Andaz","Akhil Bagaria","Carson Eisenach","Dean Foster","Omer Gottesman","Dominique Perrault-Joncas"]},"authorids":{"value":["~Alvaro_Maggiar1","~Sohrab_Andaz1","~Akhil_Bagaria1","~Carson_Eisenach1","~Dean_Foster1","~Omer_Gottesman1","~Dominique_Perrault-Joncas1"]},"keywords":{"value":["Inventory Management","Reinforcement Learning"]},"abstract":{"value":"This paper explores the application of deep reinforcement learning (DRL) to classical inventory management problems while incorporating theoretical insights from traditional operations research. We demonstrate that a simple DRL implementation using DirectBackprop can effectively handle diverse scenarios including multi-period systems with lost sales, lead times, perishability, dual sourcing, and joint procurement-removal decisions. Through extensive experiments, we show that our approach performs competitively against established benchmarks while naturally learning many structural properties of optimal policies that were previously derived analytically. We introduce a Structure-Informed Policy Network technique that explicitly incorporates these analytical insights into the learning process, enhancing generalization and robustness. Using realistic retail demand data, we demonstrate how this approach helps with extrapolation and provides robustness on out-of-sample data."},"pdf":{"value":"/pdf/73ba3bacbf3e4416033a83d856f67ccc4af36947.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nmaggiar2025structureinformed,\\ntitle={Structure-Informed Deep Reinforcement Learning for Inventory Management},\\nauthor={Alvaro Maggiar and Sohrab Andaz and Akhil Bagaria and Carson Eisenach and Dean Foster and Omer Gottesman and Dominique Perrault-Joncas},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=asKybwTGUt}\\n}"},"paperhash":{"value":"maggiar|structureinformed_deep_reinforcement_learning_for_inventory_management"}},"id":"asKybwTGUt","forum":"asKybwTGUt","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission13/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission13/Authors"],"number":13,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756241156310,"cdate":1756241156310,"tmdate":1764510122360,"mdate":1764510122360,"pdate":1764306349145,"odate":1764510122256,"version":2},{"content":{"title":{"value":"Reusing Historical Trajectories in Natural Policy Gradient via Importance Sampling: Convergence and Convergence Rate"},"authors":{"value":["Yifan Lin","Yuhao Wang","Enlu Zhou"]},"authorids":{"value":["~Yifan_Lin1","~Yuhao_Wang6","~Enlu_Zhou1"]},"keywords":{"value":["Importance sampling","reinforcement learning","policy gradient"]},"abstract":{"value":"We study trajectory reuse in natural policy gradient methods. \\nClassical policy gradient algorithms require large amounts of fresh data, which limits their sample efficiency. \\nWe propose RNPG, a reuse-based natural policy gradient algorithm that incorporates past trajectories through importance weighting of both the gradient and the Fisher information matrix estimators. \\nWe establish asymptotic convergence and a weak convergence rate for RNPG, showing that reuse improves efficiency without altering the limiting behavior. \\nExperiments on the Cartpole benchmark demonstrate that RNPG achieves faster convergence and smoother performance than VPG and VNPG, with additional gains from larger reuse sizes. \\nOur results highlight the theoretical and empirical benefits of reusing trajectories in policy optimization."},"pdf":{"value":"/pdf/707e2385df075c69f58afe692c94b4ba5d672f5b.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlin2025reusing,\\ntitle={Reusing Historical Trajectories in Natural Policy Gradient via Importance Sampling: Convergence and Convergence Rate},\\nauthor={Yifan Lin and Yuhao Wang and Enlu Zhou},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=ITpRpWqBdj}\\n}"},"paperhash":{"value":"lin|reusing_historical_trajectories_in_natural_policy_gradient_via_importance_sampling_convergence_and_convergence_rate"}},"id":"ITpRpWqBdj","forum":"ITpRpWqBdj","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission12/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission12/Authors"],"number":12,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission12/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756143417096,"cdate":1756143417096,"tmdate":1764510122268,"mdate":1764510122268,"pdate":1764306349141,"odate":1764510122251,"version":2},{"content":{"title":{"value":"Estimate to Decide: Matrix Completion driven Smoothed Online Quadratic Optimization"},"authors":{"value":["Neelkamal Bhuyan","Debankur Mukherjee","Adam Wierman"]},"authorids":{"value":["~Neelkamal_Bhuyan1","~Debankur_Mukherjee1","~Adam_Wierman1"]},"keywords":{"value":["Online Algorithms","Matrix Estimation","Sequential Decision Making"]},"abstract":{"value":"This work tackles the problem of **blind online optimization with movement costs**, where a player must make sequential decisions to balance an unknown dynamic hitting cost $f_t(x)$ against a metric penalty $c(x_t,x_{t-1})$ for changing actions between consecutive rounds, while requiring to estimate $f_t$'s structure. We study this problem for general quadratic costs under a restrictive, noisy bandit feedback model. In this setting, the player only observes the location of the hitting cost before taking an action and receives a single, noisy value of the cost it suffers post-action. To address this challenge, we provide the first algorithm for this setting that provably achieves a **sub-linear dynamic regret**, by combining online matrix estimation and the dynamic balancing of hitting and switching costs, within a principled exploration-exploitation framework."},"pdf":{"value":"/pdf/0d270a4afaef0f79fdfe3ab517dded0192beb8ef.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nbhuyan2025estimate,\\ntitle={Estimate to Decide: Matrix Completion driven Smoothed Online Quadratic Optimization},\\nauthor={Neelkamal Bhuyan and Debankur Mukherjee and Adam Wierman},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=CHglLRbEGO}\\n}"},"paperhash":{"value":"bhuyan|estimate_to_decide_matrix_completion_driven_smoothed_online_quadratic_optimization"}},"id":"CHglLRbEGO","forum":"CHglLRbEGO","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission11/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission11/Authors"],"number":11,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission11/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1756142515742,"cdate":1756142515742,"tmdate":1764510122246,"mdate":1764510122246,"pdate":1764306349080,"odate":1764510122228,"version":2},{"content":{"title":{"value":"Online Statistical Inference of Constrained Stochastic Optimization via Random Scaling"},"authors":{"value":["Xinchen Du","Wanrong Zhu","Wei Biao Wu","Sen Na"]},"authorids":{"value":["~Xinchen_Du1","~Wanrong_Zhu2","~Wei_Biao_Wu2","~Sen_Na1"]},"keywords":{"value":["Stochastic Optimization; online statistical inference; constrained optimization; stochastic sequential quadratic programming"]},"TLDR":{"value":"Purpose an efficient online statistical inference procedure for constrained stochastic optimization problems."},"abstract":{"value":"Constrained stochastic nonlinear optimization problems have attracted significant attention for their ability to model complex machine learning phenomena. As datasets continue to grow, online inference methods have become crucial for enabling real-time decision-making without the need to store historical data. In this work, we develop an online inference procedure for constrained stochastic optimization by leveraging a method called Adaptive Inexact Stochastic Sequential Quadratic Programming (AI-SSQP), which can be considered as a generalization of (sketched) Newton methods to constrained problems. We first establish the asymptotic normality of averaged AI-SSQP iterates. Then we propose a random scaling method that constructs parameter-free pivotal statistics through appropriate normalization. Our online inference approach offers two key advantages: (i) it enables the construction of asymptotically valid and statistically efficient confidence intervals, while existing work based on last iterates are less efficient and rely on a covariance estimator that is inconsistent; and (ii) it is matrix-free, i.e., the computation involves only primal-dual iterates without any matrix inversions, making its computational cost match that of first-order methods for unconstrained problems."},"pdf":{"value":"/pdf/64fab3fa9b678aad097da8f536cbed218a8c4bd0.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\ndu2025online,\\ntitle={Online Statistical Inference of Constrained Stochastic Optimization via Random Scaling},\\nauthor={Xinchen Du and Wanrong Zhu and Wei Biao Wu and Sen Na},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=hL4o9ylDjm}\\n}"},"paperhash":{"value":"du|online_statistical_inference_of_constrained_stochastic_optimization_via_random_scaling"}},"id":"hL4o9ylDjm","forum":"hL4o9ylDjm","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission7/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission7/Authors"],"number":7,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission7/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1755825763620,"cdate":1755825763620,"tmdate":1764510122146,"mdate":1764510122146,"pdate":1764306348967,"odate":1764510122121,"version":2},{"content":{"title":{"value":"Federated Calculation of the Transportation Barycenter by a Dual Subgradient Method"},"authors":{"value":["Zhengqi Lin","Andrzej Ruszczynski"]},"authorids":{"value":["~Zhengqi_Lin1","~Andrzej_Ruszczynski1"]},"keywords":{"value":["Wasserstein Barycenter","Subgradient Method","Federated Computing","Privacy"]},"TLDR":{"value":"A dual decomposition algorithm calculates the Wasserstein barycenter of several distributions without access to local data and without repeated solutions of mass transportation problems."},"abstract":{"value":"We propose an efficient federated dual decomposition algorithm for calculating the free-support Wasserstein barycenter of several distributions. The algorithm does not have access to local data and uses only highly aggregated information. It avoids repeated solutions of mass transportation problems. Owing to the absence of any matrix-vector operations, the algorithm exhibits very low complexity of each iteration and significant scalability. We illustrate its virtues on mixture models."},"pdf":{"value":"/pdf/094bedd6ae575f19262f2d53395b83bda07ac1a8.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nlin2025federated,\\ntitle={Federated Calculation of the Transportation Barycenter by a Dual Subgradient Method},\\nauthor={Zhengqi Lin and Andrzej Ruszczynski},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=9pW4gLrIsF}\\n}"},"paperhash":{"value":"lin|federated_calculation_of_the_transportation_barycenter_by_a_dual_subgradient_method"}},"id":"9pW4gLrIsF","forum":"9pW4gLrIsF","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission6/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission6/Authors"],"number":6,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission6/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1755807421520,"cdate":1755807421520,"tmdate":1764510122131,"mdate":1764510122131,"pdate":1764306348873,"odate":1764510122106,"version":2},{"content":{"title":{"value":"Probabilistic Soundness Guarantees in LLM Reasoning Chains"},"authors":{"value":["Weiqiu You","Anton Xue","Shreya Havaldar","Delip Rao","Helen Jin","Chris Callison-Burch","Eric Wong"]},"authorids":{"value":["~Weiqiu_You1","~Anton_Xue1","~Shreya_Havaldar1","~Delip_Rao1","~Helen_Jin1","~Chris_Callison-Burch1","~Eric_Wong1"]},"keywords":{"value":["reasoning","error detection","probabilistic guarantees","uncertainty quantification"]},"TLDR":{"value":"We certify whether LLMs reason correctly."},"abstract":{"value":"In reasoning chains generated by large language models (LLMs), initial errors often propagate and undermine the reliability of the final conclusion. Current LLM-based error detection methods often fail to detect propagated errors because earlier errors can corrupt judgments of downstream reasoning. To better detect such errors, we introduce Autoregressive Reasoning Entailment Stability (ARES), a probabilistic framework that evaluates each reasoning step based solely on previously-verified premises. We find that ARES can reliably detect propagated reasoning errors that other baselines fail to find with probabilistic guarantees."},"pdf":{"value":"/pdf/f26be6be2d1bb80377c48a6743e12cf13261b28e.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nyou2025probabilistic,\\ntitle={Probabilistic Soundness Guarantees in {LLM} Reasoning Chains},\\nauthor={Weiqiu You and Anton Xue and Shreya Havaldar and Delip Rao and Helen Jin and Chris Callison-Burch and Eric Wong},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=rlNn397KA2}\\n}"},"paperhash":{"value":"you|probabilistic_soundness_guarantees_in_llm_reasoning_chains"}},"id":"rlNn397KA2","forum":"rlNn397KA2","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission3/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission3/Authors"],"number":3,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission3/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1755501234957,"cdate":1755501234957,"tmdate":1764510121917,"mdate":1764510121917,"pdate":1764306348520,"odate":1764510121561,"version":2},{"content":{"title":{"value":"Non‑Asymptotic Guarantees for Average‑Reward Q‑Learning with Adaptive Stepsizes"},"authors":{"value":["Zaiwei Chen"]},"authorids":{"value":["~Zaiwei_Chen1"]},"keywords":{"value":["Average-reward Q-learning","adaptive stepsizes","non-asymptotic analysis","non-Markovian stochastic approximation."]},"TLDR":{"value":"This work presents the first finite-time analysis of average-reward Q-learning with asynchronous updates based on a single trajectory of Markovian samples."},"abstract":{"value":"This work presents the first finite-time analysis of average-reward $Q$-learning with an asynchronous implementation. A key feature of the algorithm we study is the use of adaptive stepsizes that act as local clocks for each state-action pair. We show that the mean-square error of this $Q$-learning algorithm, measured in the span seminorm, converges at a rate of $\\\\tilde{\\\\mathcal O}(1/k)$. Technically, the use of adaptive stepsizes causes each $Q$-learning update to depend on the full sample history, introducing strong correlations and making the algorithm a non-Markovian stochastic approximation (SA) scheme. Our approach to overcoming this challenge involves (1) a time-inhomogeneous Markovian reformulation of non-Markovian SA, and (2) a combination of almost-sure time-varying bounds, conditioning arguments, and Markov chain concentration inequalities to break the strong correlations between the adaptive stepsizes and the iterates."},"pdf":{"value":"/pdf/ca1ef721fa3f7624b31ba7f15621bd8bfe5735d3.pdf"},"venue":{"value":"NeurIPS 2025 Workshop MLxOR"},"venueid":{"value":"NeurIPS.cc/2025/Workshop/MLxOR"},"_bibtex":{"value":"@inproceedings{\\nchen2025nonasymptotic,\\ntitle={Non\\\\nobreakdash-Asymptotic Guarantees for Average\\\\nobreakdash-Reward Q\\\\nobreakdash-Learning with Adaptive Stepsizes},\\nauthor={Zaiwei Chen},\\nbooktitle={NeurIPS 2025 Workshop MLxOR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making},\\nyear={2025},\\nurl={https://openreview.net/forum?id=Xs456bQ4Jw}\\n}"},"paperhash":{"value":"chen|nonasymptotic_guarantees_for_averagereward_qlearning_with_adaptive_stepsizes"}},"id":"Xs456bQ4Jw","forum":"Xs456bQ4Jw","license":"CC BY 4.0","signatures":["NeurIPS.cc/2025/Workshop/MLxOR/Submission1/Authors"],"readers":["everyone"],"writers":["NeurIPS.cc/2025/Workshop/MLxOR","NeurIPS.cc/2025/Workshop/MLxOR/Submission1/Authors"],"number":1,"invitations":["NeurIPS.cc/2025/Workshop/MLxOR/-/Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Post_Submission","NeurIPS.cc/2025/Workshop/MLxOR/Submission1/-/Camera_Ready_Submission","NeurIPS.cc/2025/Workshop/MLxOR/-/Edit","NeurIPS.cc/2025/Workshop/MLxOR/-/PC_Revision"],"domain":"NeurIPS.cc/2025/Workshop/MLxOR","tcdate":1753974838235,"cdate":1753974838235,"tmdate":1764510121976,"mdate":1764510121976,"pdate":1764306348518,"odate":1764510121559,"version":2}]`),Pa={notes:Ra};var _a=_('<div class="rounded-xl border border-gray-200 p-6 transition hover:border-blue-500/10 hover:shadow-blue-500/10"><h3 class="text-lg font-semibold text-gray-800"><a target="_blank" rel="noreferrer" class="hover:underline"> </a></h3> <p class="mt-2 text-sm text-gray-600"> </p></div>'),Oa=_('<div class="space-y-6"></div>');function Wa(e,a){ye(a,!1);const i=Pa.notes;pe();var n=Oa();ra(n,5,()=>i,ta,(t,o)=>{var s=_a(),p=b(s),d=b(p),k=b(d,!0);v(d),v(p);var r=c(p,2),x=b(r,!0);v(r),v(s),X(u=>{V(d,"href",`https://openreview.net/forum?id=${Q(o).forum}`),ae(k,Q(o).content.title.value),ae(x,u)},[()=>Q(o).content.authors.value.join(", ")],ge),M(t,s)}),v(n),M(e,n),Se()}var Ia=_(`<h1 class="mb-6 text-2xl font-bold" id="schedule">Schedule</h1> <div class="mb-6 text-sm"><p><strong>Location:</strong> Upper Level Room 26AB, San Diego Convention Center</p></div> <div><table class="w-full border-collapse border border-gray-300 text-sm"><thead><tr class="bg-gray-100"><th class="border border-gray-300 px-4 py-2 text-left whitespace-nowrap">Time</th><th class="w-full border border-gray-300 px-4 py-2 text-left">Event</th></tr></thead><tbody><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">8:00 - 8:20</td><td class="w-full border border-gray-300 px-4 py-2">Morning Coffee</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">8:20 - 8:30</td><td class="w-full border border-gray-300 px-4 py-2">Introduction and Opening Remark</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">8:30 - 9:00</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Keynote Talk:</strong> <a href="https://neurips.cc/virtual/2025/loc/san-diego/136366" target="_blank" rel="noopener noreferrer" class="hover:underline">Can Large Language Models Make Decisions? Mathematical Formulations and Open Problems</a> <br>Speaker: R. Srikant (UIUC)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">9:00 - 9:30</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Spotlight Presentations</strong> <br>1. <a href="https://openreview.net/forum?id=IC0Qo09FxF" target="_blank" rel="noopener noreferrer" class="hover:underline">The Oversight Game: Learning AI Control &amp; Corrigibility in Markov Games</a>, <br>&nbsp;&nbsp;&nbsp; William Overman, Mohsen Bayati <br>2. <a href="https://openreview.net/forum?id=FLD5JWpR67" target="_blank" rel="noopener noreferrer" class="hover:underline">Neural Decision Rule for Constrained Contextual Stochastic Optimization</a>, <br>&nbsp;&nbsp;&nbsp; Zhangyi Liu, Zhongling Xu, Feng Liu, Rui Gao, Shuang Li <br>3. <a href="https://openreview.net/forum?id=ToUWDGP0st" target="_blank" rel="noopener noreferrer" class="hover:underline">Accelerating Diffusion via Compressed Sensing: Applications to Imaging and Finance</a>,
            Zhengyi Guo, Jiatu Li, Wenpin Tang, David Yao</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">9:30 - 09:45</td><td class="w-full border border-gray-300 px-4 py-2">Coffee Break (and Poster Setup)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">09:45 - 10:30</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Poster Session 1</strong> (Paper ID: 1-71)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">10:30 - 11:15</td><td class="w-full border border-gray-300 px-4 py-2"><strong>MLxOR Theory-Geared Panel:</strong> Peter Glynn (Stanford), Daniel Russo (Columbia), Masashi Sugiyama (U.of Tokyo, RIKEN), Renyuan Xu (NYU) <br>Moderator: Assaf Zeevi (Columbia)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">11:15 - 12:25</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Spotlight Presentations</strong> <br>4. <a href="https://openreview.net/forum?id=xufNFlDoKj" target="_blank" rel="noopener noreferrer" class="hover:underline">Achieving O(1/N) Optimality Gap in Weakly-Coupled Markov Decision Processes through Gaussian Approximation</a>, <br>&nbsp;&nbsp&nbsp; Chen Yan, Weina Wang, Lei Ying <br>5. <a href="https://openreview.net/forum?id=v7YPtir432" target="_blank" rel="noopener noreferrer" class="hover:underline">Fairness Is More Than Algorithms: Racial Disparities in Time-to-Recidivism</a>, <br>&nbsp;&nbsp;&nbsp; Jessy Xinyi Han, Kristjan Greenewald, Devavrat Shah <br>6. <a href="https://openreview.net/forum?id=zxaMZHF1JW" target="_blank" rel="noopener noreferrer" class="hover:underline">Human-Centric Perishable Inventory Management with AI-Assistance</a>, <br>&nbsp;&nbsp;&nbsp; Yu Nu, Meng Qi, Karan Girotra, Elena Belavina <br>7. <a href="https://openreview.net/forum?id=XMZgZfBTwv" target="_blank" rel="noopener noreferrer" class="hover:underline">Ensuring Fairness in Priority-Based Admissions with Uncertain Scores</a>, <br>&nbsp;&nbsp;&nbsp; Zhiqiang Zhang, Pengyi Shi, Amy R. Ward <br>8. <a href="https://openreview.net/forum?id=HUkPaXsB3s" target="_blank" rel="noopener noreferrer" class="hover:underline">Scalable First-order Method for Certifying Optimal k-Sparse GLMs</a>, <br>&nbsp;&nbsp;&nbsp; Jiachang Liu, Soroosh Shafiee, Andrea Lodi <br>9. <a href="https://openreview.net/forum?id=CTGNVLAqgQ" target="_blank" rel="noopener noreferrer" class="hover:underline">Model-Free Assessment of Simulator Fidelity via Quantile Curves</a>, <br>&nbsp;&nbsp;&nbsp; Yu-Shiou Willy Lin, Garud Iyengar, Kaizheng Wang <br>10. <a href="https://openreview.net/forum?id=tQgfqyT6If" target="_blank" rel="noopener noreferrer" class="hover:underline">Autoregressive Learning under Joint KL Analysis: Horizon-Free Approximation and Computational-Statistical Tradeoffs</a>, <br>&nbsp;&nbsp;&nbsp; Yunbei Xu, Yuzhe Yuan, Ruohan Zhan</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">12:25 - 12:55</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Keynote Talk:</strong> <a href="https://neurips.cc/virtual/2025/loc/san-diego/136382" target="_blank" rel="noopener noreferrer" class="hover:underline">The AI-XR Scientist that Sees and Works with Humans</a> <br>Speaker: Mengdi Wang (Princeton)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">12:55 - 13:25</td><td class="w-full border border-gray-300 px-4 py-2">Lunch Break (and Poster Setup)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">13:25 - 14:10</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Poster Session 2</strong> (Paper ID: 72-161)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">14:10 - 14:40</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Keynote Talk:</strong> <a href="https://neurips.cc/virtual/2025/loc/san-diego/136385" target="_blank" rel="noopener noreferrer" class="hover:underline">Learning What to Optimize: ML Methods for Accessible Operations Research</a> <br>Speaker: Peter Frazier (Cornell)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">14:40 - 15:10</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Keynote Talk:</strong> <a href="https://neurips.cc/virtual/2025/loc/san-diego/136386" target="_blank" rel="noopener noreferrer" class="hover:underline">OR and ML in Amazon’s Middle Mile Freight Capacity Marketplace</a> <br>Speaker: Phil Kaminsky (Amazon)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">15:10 - 15:25</td><td class="w-full border border-gray-300 px-4 py-2">Coffee Break (and Poster Setup)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">15:25 - 16:10</td><td class="w-full border border-gray-300 px-4 py-2"><strong>Poster Session 3</strong> (Paper ID: 162-245)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">16:10 - 16:55</td><td class="w-full border border-gray-300 px-4 py-2"><strong>ML×OR Industry-Geared Panel:</strong> Hongseok Namkoong (Columbia), Sanjay Shakkottai (UT Austin), Dawn Woodard (LinkedIn), Kuang Xu (Stanford) <br>Moderator: Jose Blanchet (Stanford)</td></tr><tr class="odd:bg-white even:bg-gray-50"><td class="border border-gray-300 px-4 py-2 whitespace-nowrap">16:55 - 17:00</td><td class="w-full border border-gray-300 px-4 py-2">Closing Remark</td></tr></tbody></table></div> <div class="mt-4 text-sm text-gray-600 italic"><p>All times are in Pacific Time (PT).</p></div>`,1),Na=_('<h1 class="mb-4 text-2xl font-bold" id="speakers">Speakers & Panelists</h1>'),Aa=_('<div class="flex flex-col items-center justify-center"><div class="flex flex-wrap justify-center"><!> <!> <!> <!> <!> <!> <!> <!> <!> <!> <!> <!></div></div>'),Ca=_('<h1 class="mb-4 text-2xl font-bold" id="organizers">Organizers</h1>'),Da=_('<div class="flex flex-col items-center justify-center"><div class="flex flex-wrap justify-center"><!> <!> <!> <!> <!> <!> <!> <!></div></div>'),za=_('<h1 class="mb-4 text-2xl font-bold" id="program_committee">Program Committee Members</h1> <div class="text-base"><!></div>',1),Ta=_('<h1 class="mb-4 text-2xl font-bold" id="call">Call For Papers</h1> <div class="text-base"><!></div>',1),Ba=_('<h1 class="mb-4 text-2xl font-bold" id="papers">Accepted Papers</h1> <!>',1),Fa=_(`<div class="text-lg"><div class="flex w-full items-end justify-center font-serif"><div class="mx-8 w-full max-w-2xl pt-8 pb-8 text-black md:pt-28"><div class="mb-4 text-sm"><div class="inline-block rounded-md border border-black px-2 py-1 font-mono">NeurIPS 2025 WORKSHOP</div></div> <div class="inline-block text-4xl"><strong>ML×OR Workshop:</strong><br>Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making</div> <div class="mt-8 flex flex-wrap items-center gap-2 text-sm"><div class="font-mono text-sm text-gray-500 mr-2">Supported by</div> <a href="https://connect.informs.org/aps/home" target="_blank" rel="noreferrer" class="hover:underline">INFORMS Applied Probability Society</a> <span>/</span> <a href="https://connect.informs.org/simulation/home" target="_blank" rel="noreferrer" class="hover:underline">INFORMS Simulation Society</a> <span>/</span> <a href="https://galux.co.kr/" target="_blank" rel="noreferrer" class="hover:underline">Galux</a> <span>/</span> <a href="https://www.columbia.edu/" target="_blank" rel="noreferrer" class="hover:underline">Columbia University</a></div> <div class="text-md mt-8 text-gray-800">December 6, 2025</div> <div class="mt-2 text-sm text-gray-500">Upper Level Room 26AB</div> <div class="text-sm text-gray-500">San Diego Convention Center</div></div></div> <div class="sticky top-0 z-10 my-2 flex w-full items-start justify-center bg-gray-100/70 backdrop-blur-md md:py-1.5"><div class="mx-8 w-full max-w-2xl select-none"><div class="my-2 flex flex-row flex-wrap items-center justify-start font-mono text-sm md:text-base"><!> <div class="mx-2 text-gray-400">/</div> <!> <div class="mx-2 text-gray-400">/</div> <!> <div class="mx-2 text-gray-400">/</div> <!> <div class="mx-2 text-gray-400">/</div> <!></div></div></div> <!> <!> <!> <!> <!> <!> <!> <!> <!> <div class="mt-8 flex w-full justify-center bg-gray-100 pt-4 font-sans"><div class="mx-8 w-full max-w-3xl"><div class="flex w-full flex-col items-center justify-start"><div class="mt-4 mb-8 text-2xl text-gray-500"><a href="https://github.com/pr4al-workshop/pr4al-workshop.github.io" target="_blank" rel="noreferrer" class="mr-2"><!></a></div></div> <div class="mb-24 text-sm text-gray-600">This website is licensed under a <a class="underline" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noreferrer">Creative Commons Attribution-ShareAlike 4.0 International License</a> and is based on the <a class="underline" href="https://leela-interp.github.io/" target="_blank" rel="noreferrer">Leela Interp</a> project. That means you're free to borrow the source code of this website with attribution.</div></div></div></div>`);function $a(e){var a=Fa();ea(m=>{je.title=`NeurIPS 2025 ML×OR Workshop: Mathematical Foundations and
Operational Integration of Machine Learning for
Uncertainty-Aware Decision-Making`});var i=c(b(a),2),n=b(i),t=b(n),o=b(t);J(o,{href:"#schedule",children:(m,W)=>{z();var h=Z("Schedule");M(m,h)},$$slots:{default:!0}});var s=c(o,4);J(s,{href:"#speakers",children:(m,W)=>{z();var h=Z("Speakers");M(m,h)},$$slots:{default:!0}});var p=c(s,4);J(p,{href:"#organizers",children:(m,W)=>{z();var h=Z("Organizers & PC Members");M(m,h)},$$slots:{default:!0}});var d=c(p,4);J(d,{href:"#call",children:(m,W)=>{z();var h=Z("Call for Papers");M(m,h)},$$slots:{default:!0}});var k=c(d,4);J(k,{href:"#papers",children:(m,W)=>{z();var h=Z("Accepted Papers");M(m,h)},$$slots:{default:!0}}),v(t),v(n),v(i);var r=c(i,2);D(r,{padding:"py-8",class:"md:text-justify",children:(m,W)=>{xa(m)},$$slots:{default:!0}});var x=c(r,2);D(x,{children:(m,W)=>{var h=Ia();z(6),M(m,h)},$$slots:{default:!0}});var u=c(x,2);D(u,{padding:"pb-4",children:(m,W)=>{var h=Na();M(m,h)},$$slots:{default:!0}});var y=c(u,2);D(y,{children:(m,W)=>{var h=Aa(),N=b(h),C=b(N);R(C,{name:"Peter Frazier",affiliation:"Cornell University",link:"https://people.orie.cornell.edu/pfrazier/",image:"./imgs/pfrazier.jpg"});var Y=c(C,2);R(Y,{name:"Peter Glynn",affiliation:"Stanford University",link:"https://web.stanford.edu/~glynn/",image:"./imgs/pglynn.jpg"});var q=c(Y,2);R(q,{name:"Hongseok Namkoong",affiliation:"Columbia Universisty",link:"https://hsnamkoong.github.io/",image:"./imgs/hong.jpg"});var U=c(q,2);R(U,{name:"Phil Kaminsky",affiliation:"Amazon",link:"https://kaminsky.ieor.berkeley.edu/",image:"./imgs/phil.jpg"});var G=c(U,2);R(G,{name:"Daniel Russo",affiliation:"Columbia Universisty",link:"https://djrusso.github.io/",image:"./imgs/drusso.jpg"});var $=c(G,2);R($,{name:"Sanjay Shakkottai",affiliation:"UT Austin",link:"https://sites.google.com/view/sanjay-shakkottai/",image:"./imgs/sanjay.jpg"});var H=c($,2);R(H,{name:"Rayadurgam Srikant",affiliation:"UIUC",link:"https://sites.google.com/a/illinois.edu/srikant/",image:"./imgs/rsrikant.jpg"});var ee=c(H,2);R(ee,{name:"Masashi Sugiyama",affiliation:"University of Tokyo, RIKEN",link:"https://www.ms.k.u-tokyo.ac.jp/sugi/profile.html",image:"./imgs/masashi.jpg"});var oe=c(ee,2);R(oe,{name:"Mengdi Wang",affiliation:"Princeton University",link:"https://mwang.princeton.edu/",image:"./imgs/mengdi.jpg"});var re=c(oe,2);R(re,{name:"Dawn Woodard",affiliation:"LinkedIn",link:"https://woodardscience.com/",image:"./imgs/dawn.jpg"});var se=c(re,2);R(se,{name:"Kuang Xu",affiliation:"Stanford University",link:"https://gsb-faculty.stanford.edu/kuang-xu/",image:"./imgs/kuang.jpg"});var Le=c(se,2);R(Le,{name:"Renyuan Xu",affiliation:"New York University",link:"https://renyuanxu.github.io/",image:"./imgs/renyuan.jpg"}),v(N),v(h),M(m,h)},$$slots:{default:!0}});var g=c(y,2);D(g,{padding:"pb-4",children:(m,W)=>{var h=Ca();M(m,h)},$$slots:{default:!0}});var I=c(g,2);D(I,{children:(m,W)=>{var h=Da(),N=b(h),C=b(N);R(C,{name:"Jose Blanchet",affiliation:"Stanford University",link:"https://joseblanchet.com/",image:"https://joseblanchet.com/wp-content/uploads/2024/06/blanchet-800x800.jpg"});var Y=c(C,2);R(Y,{name:"Jing Dong",affiliation:"Columbia University",link:"https://www.columbia.edu/~jd2736/",image:"https://www.columbia.edu/~jd2736/index_files/image004.jpg"});var q=c(Y,2);R(q,{name:"Henry Lam",affiliation:"Columbia University",link:"https://www.columbia.edu/~khl2114/",image:"http://www.columbia.edu/~khl2114/files/pic_updated.jpg"});var U=c(q,2);R(U,{name:"Min-hwan Oh",affiliation:"Seoul National University",link:"https://minoh.io/",image:"https://minoh.io/assets/img/mho.webp"});var G=c(U,2);R(G,{name:"Qiaomin Xie",affiliation:"University of Wisconsin-Madison",link:"https://qiaominxie.github.io/",image:"https://qiaominxie.github.io/assets/img/prof_pic.jpg"});var $=c(G,2);R($,{name:"Yao Xie",affiliation:"Georgia Institute of Technology",link:"https://www2.isye.gatech.edu/~yxie77/",image:"./imgs/yao.jpg"});var H=c($,2);R(H,{name:"Assaf Zeevi",affiliation:"Columbia University",link:"https://business.columbia.edu/faculty/people/assaf-zeevi",image:"https://business.columbia.edu/sites/default/files-efs/styles/default_content_image_cinema/public/person/photos/assaf-pic-19.jpg?h=6ef299b7&itok=09SgCMLG"});var ee=c(H,2);R(ee,{name:"Enlu Zhou",affiliation:"Georgia Institute of Technology",link:"https://www.enluzhou.gatech.edu/",image:"https://enluzhou.gatech.edu/images/Enlu2017.jpg"}),v(N),v(h),M(m,h)},$$slots:{default:!0}});var w=c(I,2);D(w,{padding:"pb-4",children:(m,W)=>{var h=za(),N=c(te(h),2),C=b(N);La(C),v(N),M(m,h)},$$slots:{default:!0}});var f=c(w,2);D(f,{padding:"py-8",children:(m,W)=>{var h=Ta(),N=c(te(h),2),C=b(N);ka(C),v(N),M(m,h)},$$slots:{default:!0}});var l=c(f,2);D(l,{children:(m,W)=>{var h=Ba(),N=c(te(h),2);Wa(N,{}),M(m,h)},$$slots:{default:!0}});var S=c(l,2),L=b(S),P=b(L),O=b(P),T=b(O),F=b(T);va(F,{class:"inline-block hover:text-black"}),v(T),v(O),v(P),z(2),v(L),v(S),v(a),M(e,a)}export{$a as component};
